{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoming150ty/Personal-Portfolio/blob/main/Assignment_02_Haoming_Zhang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment 02: Improving Deep Learning Models (100 pts)**\n",
        "- Instructor: [Jaeung Sim](https://jaeungs.github.io/) (University of Connecticut)\n",
        "- Course: OPIM 5512 Data Science Using Python\n",
        "- Release Date: March 13 (Thu), 2025\n",
        "- Submission Due: March 28 (Fri), 2025"
      ],
      "metadata": {
        "id": "RF54h03umOdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objectives**\n",
        "1. Experiment with hyperparameters and observe how model performances change.\n",
        "1. Improve the model performance by tuning hyperparameters.\n",
        "1. Obtain the loss as low as possible."
      ],
      "metadata": {
        "id": "_KUR42ZEmxPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "* You're going to experiment with hyperparameters discussed in class. There could be several unexpected consequences of changing hyperparameters, so you need to be open-minded to find breakthroughs.\n",
        "\n",
        "* You will follow each step, run your own code, and submit the notebook file on HuskyCT. The maximum score is 100, and you don't have extra points in this assignment.\n",
        "\n",
        "* At this time, **you can't get help from your friends.** You're on your own. You may still use online documents and artificial intelligence (e.g., ChatGPT). **Importantly, the instructor will receive clarification only.** I will not review and comment on your Python codes."
      ],
      "metadata": {
        "id": "K-F7MQQFuxdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1. Data Processing**"
      ],
      "metadata": {
        "id": "sNoKE8Ua0nhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **A. Setup and Data Loading**\n",
        "\n",
        "You may change the codes here to adapt your environment. **But you should not change the name of the DataFrame.**"
      ],
      "metadata": {
        "id": "zcshUHhtxJWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Google Drive directory\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/My Drive/OPIM 5512') # You may need to change this directory"
      ],
      "metadata": {
        "id": "6seNeVv0xe4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfb3aea-3eed-41f9-c642-1813009e0e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "TV5_HPHH6gTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45b4bec-9b6e-43eb-b118-2b78eec41333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please download `dataset_assignment_02.csv` from HuskyCT and place it in your working directory. This dataset, generated by the instructor (**Jaeung Sim**), includes one target variable (\"Y\") and 15 input variables. Due to its data generation process, you may not have to either standardize or normalize input variables."
      ],
      "metadata": {
        "id": "O-Y_scbmx9hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading\n",
        "df = pd.read_csv('dataset_assignment_02.csv')"
      ],
      "metadata": {
        "id": "MgVbYuNy6ccp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the head of the dataset\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "jq1Lp9Ybx1-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "37eb82ea-47ce-4b85-f36b-c0f0000ed7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             y        x1        x2        x3        x4  x5        x6  \\\n",
              "0    59.064028  0.092627 -0.616344  1.010230  2.174466   1  0.997493   \n",
              "1  -104.243187  0.360192 -0.398255  0.255686  0.965165   1 -0.551480   \n",
              "2    92.456510  0.351240  0.440209  0.391802  0.996526   1 -0.995572   \n",
              "3    10.851567  0.680396  0.235624  1.303907  1.103386   0  0.547052   \n",
              "4   210.625565  0.369461 -0.825356  2.781261  1.701670   1  0.827293   \n",
              "5   108.686823  0.606444 -1.056586  0.032153  1.842594   1 -0.985843   \n",
              "6    74.479498  0.449913  1.052614  0.375435  1.452903   1 -0.976122   \n",
              "7   -18.320115  0.634891 -0.310191  1.433664  0.931551   1  0.976391   \n",
              "8    11.955305  0.412335 -0.281695  1.528866  1.068423   0  0.809005   \n",
              "9    82.472151  0.256528 -1.114048  0.245172  1.116120   1  0.870437   \n",
              "10    2.310362  0.958307 -0.647693  0.213040  0.988086   0  0.286589   \n",
              "11 -116.255240  0.065210 -0.510044  0.548068  1.794773   0  0.632307   \n",
              "12  175.004299  0.096103  0.007558  1.246126  1.049476   1 -0.358396   \n",
              "13  160.292073  0.419866 -0.912781  1.169069  1.730921   1 -0.600411   \n",
              "14  116.470989  0.234300  2.790688  4.499028  1.896799   1 -0.130692   \n",
              "15    8.427468  0.499939 -0.705544  0.146236  1.149944   1 -0.593306   \n",
              "16  -23.963509  0.466347  0.948074  0.151304  1.051230   1 -0.999691   \n",
              "17   34.998016  0.844703 -1.855467  0.410616  1.893215   1 -0.870970   \n",
              "18   25.208372  0.099806  1.186955  0.149279  1.814665   1  0.180369   \n",
              "19   12.545404  0.609515 -1.419995  1.461228  0.802081   1  0.983229   \n",
              "\n",
              "          x7        x8        x9  x10       x11       x12       x13       x14  \\\n",
              "0  -0.536556  0.714396  0.485646    1  0.218922  0.022818  0.344689  0.088160   \n",
              "1   0.904158  0.489067  0.069215    1  0.072969  0.049336 -0.385529  0.031542   \n",
              "2   0.724013  0.280797  0.069975    0  0.041180  0.154431  0.259341 -0.002101   \n",
              "3   0.995900  0.367699 -0.886281    0  0.269877  0.098021 -0.938547  0.042472   \n",
              "4  -0.947857  0.207226  0.039131    1  0.435014  0.275365  0.100224  0.049743   \n",
              "5  -0.808329  0.893509  0.565457    0  0.290238  0.024151 -0.751336  0.087975   \n",
              "6  -0.425896  0.289792  0.661508    0  0.047633  0.034497  0.496091  0.031193   \n",
              "7  -0.989620  0.602963 -0.305327    0  0.346582  0.022114 -0.610197  0.078646   \n",
              "8  -0.378763  0.251986  0.372649    0  0.535455  0.197533 -0.307524  0.097250   \n",
              "9  -0.891208  0.904717  0.881962    1  0.346526  0.002445 -0.417299  0.086395   \n",
              "10  0.218776  0.125343  1.021801    0  0.137173  0.118697  0.055203  0.033541   \n",
              "11  0.773410  0.017388 -1.718671    1  0.076269  0.318866 -0.751415 -0.012974   \n",
              "12 -0.913729  0.228570 -1.515762    1  0.520565  0.068509 -0.786404  0.123636   \n",
              "13 -0.679988  0.779694 -0.275000    1  0.252765  0.269468 -0.812795  0.018513   \n",
              "14  0.915099  0.687621  0.274696    1  0.272874  0.012096  0.485871  0.076013   \n",
              "15 -0.903743  0.580087 -0.460971    0  0.095082  0.082479 -0.612751  0.035292   \n",
              "16  0.974986  0.684183 -0.837565    1  0.605870  0.249046 -0.897708  0.112392   \n",
              "17  0.137163  0.287585 -0.493303    0  0.200751  0.231835 -0.971567  0.021805   \n",
              "18 -0.036386  0.092638 -0.412913    1  0.134442  0.336222  0.242847 -0.028761   \n",
              "19 -0.405656  0.200601  0.727770    1  0.083958  0.077749  0.882407  0.047874   \n",
              "\n",
              "         x15  \n",
              "0   0.083429  \n",
              "1   0.391962  \n",
              "2   0.354800  \n",
              "3   0.266599  \n",
              "4   0.034647  \n",
              "5   0.143585  \n",
              "6   0.347720  \n",
              "7   0.082520  \n",
              "8   0.097163  \n",
              "9   0.373682  \n",
              "10  0.364214  \n",
              "11  0.048322  \n",
              "12  0.415623  \n",
              "13  0.958902  \n",
              "14  0.032830  \n",
              "15  0.558888  \n",
              "16  0.049665  \n",
              "17  0.146980  \n",
              "18  0.370477  \n",
              "19  0.000028  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2350d6b5-126a-4d49-80c6-b4e3b5d41bdd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.064028</td>\n",
              "      <td>0.092627</td>\n",
              "      <td>-0.616344</td>\n",
              "      <td>1.010230</td>\n",
              "      <td>2.174466</td>\n",
              "      <td>1</td>\n",
              "      <td>0.997493</td>\n",
              "      <td>-0.536556</td>\n",
              "      <td>0.714396</td>\n",
              "      <td>0.485646</td>\n",
              "      <td>1</td>\n",
              "      <td>0.218922</td>\n",
              "      <td>0.022818</td>\n",
              "      <td>0.344689</td>\n",
              "      <td>0.088160</td>\n",
              "      <td>0.083429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-104.243187</td>\n",
              "      <td>0.360192</td>\n",
              "      <td>-0.398255</td>\n",
              "      <td>0.255686</td>\n",
              "      <td>0.965165</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.551480</td>\n",
              "      <td>0.904158</td>\n",
              "      <td>0.489067</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>1</td>\n",
              "      <td>0.072969</td>\n",
              "      <td>0.049336</td>\n",
              "      <td>-0.385529</td>\n",
              "      <td>0.031542</td>\n",
              "      <td>0.391962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92.456510</td>\n",
              "      <td>0.351240</td>\n",
              "      <td>0.440209</td>\n",
              "      <td>0.391802</td>\n",
              "      <td>0.996526</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.995572</td>\n",
              "      <td>0.724013</td>\n",
              "      <td>0.280797</td>\n",
              "      <td>0.069975</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041180</td>\n",
              "      <td>0.154431</td>\n",
              "      <td>0.259341</td>\n",
              "      <td>-0.002101</td>\n",
              "      <td>0.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.851567</td>\n",
              "      <td>0.680396</td>\n",
              "      <td>0.235624</td>\n",
              "      <td>1.303907</td>\n",
              "      <td>1.103386</td>\n",
              "      <td>0</td>\n",
              "      <td>0.547052</td>\n",
              "      <td>0.995900</td>\n",
              "      <td>0.367699</td>\n",
              "      <td>-0.886281</td>\n",
              "      <td>0</td>\n",
              "      <td>0.269877</td>\n",
              "      <td>0.098021</td>\n",
              "      <td>-0.938547</td>\n",
              "      <td>0.042472</td>\n",
              "      <td>0.266599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>210.625565</td>\n",
              "      <td>0.369461</td>\n",
              "      <td>-0.825356</td>\n",
              "      <td>2.781261</td>\n",
              "      <td>1.701670</td>\n",
              "      <td>1</td>\n",
              "      <td>0.827293</td>\n",
              "      <td>-0.947857</td>\n",
              "      <td>0.207226</td>\n",
              "      <td>0.039131</td>\n",
              "      <td>1</td>\n",
              "      <td>0.435014</td>\n",
              "      <td>0.275365</td>\n",
              "      <td>0.100224</td>\n",
              "      <td>0.049743</td>\n",
              "      <td>0.034647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>108.686823</td>\n",
              "      <td>0.606444</td>\n",
              "      <td>-1.056586</td>\n",
              "      <td>0.032153</td>\n",
              "      <td>1.842594</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.985843</td>\n",
              "      <td>-0.808329</td>\n",
              "      <td>0.893509</td>\n",
              "      <td>0.565457</td>\n",
              "      <td>0</td>\n",
              "      <td>0.290238</td>\n",
              "      <td>0.024151</td>\n",
              "      <td>-0.751336</td>\n",
              "      <td>0.087975</td>\n",
              "      <td>0.143585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>74.479498</td>\n",
              "      <td>0.449913</td>\n",
              "      <td>1.052614</td>\n",
              "      <td>0.375435</td>\n",
              "      <td>1.452903</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.976122</td>\n",
              "      <td>-0.425896</td>\n",
              "      <td>0.289792</td>\n",
              "      <td>0.661508</td>\n",
              "      <td>0</td>\n",
              "      <td>0.047633</td>\n",
              "      <td>0.034497</td>\n",
              "      <td>0.496091</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.347720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-18.320115</td>\n",
              "      <td>0.634891</td>\n",
              "      <td>-0.310191</td>\n",
              "      <td>1.433664</td>\n",
              "      <td>0.931551</td>\n",
              "      <td>1</td>\n",
              "      <td>0.976391</td>\n",
              "      <td>-0.989620</td>\n",
              "      <td>0.602963</td>\n",
              "      <td>-0.305327</td>\n",
              "      <td>0</td>\n",
              "      <td>0.346582</td>\n",
              "      <td>0.022114</td>\n",
              "      <td>-0.610197</td>\n",
              "      <td>0.078646</td>\n",
              "      <td>0.082520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11.955305</td>\n",
              "      <td>0.412335</td>\n",
              "      <td>-0.281695</td>\n",
              "      <td>1.528866</td>\n",
              "      <td>1.068423</td>\n",
              "      <td>0</td>\n",
              "      <td>0.809005</td>\n",
              "      <td>-0.378763</td>\n",
              "      <td>0.251986</td>\n",
              "      <td>0.372649</td>\n",
              "      <td>0</td>\n",
              "      <td>0.535455</td>\n",
              "      <td>0.197533</td>\n",
              "      <td>-0.307524</td>\n",
              "      <td>0.097250</td>\n",
              "      <td>0.097163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>82.472151</td>\n",
              "      <td>0.256528</td>\n",
              "      <td>-1.114048</td>\n",
              "      <td>0.245172</td>\n",
              "      <td>1.116120</td>\n",
              "      <td>1</td>\n",
              "      <td>0.870437</td>\n",
              "      <td>-0.891208</td>\n",
              "      <td>0.904717</td>\n",
              "      <td>0.881962</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346526</td>\n",
              "      <td>0.002445</td>\n",
              "      <td>-0.417299</td>\n",
              "      <td>0.086395</td>\n",
              "      <td>0.373682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.310362</td>\n",
              "      <td>0.958307</td>\n",
              "      <td>-0.647693</td>\n",
              "      <td>0.213040</td>\n",
              "      <td>0.988086</td>\n",
              "      <td>0</td>\n",
              "      <td>0.286589</td>\n",
              "      <td>0.218776</td>\n",
              "      <td>0.125343</td>\n",
              "      <td>1.021801</td>\n",
              "      <td>0</td>\n",
              "      <td>0.137173</td>\n",
              "      <td>0.118697</td>\n",
              "      <td>0.055203</td>\n",
              "      <td>0.033541</td>\n",
              "      <td>0.364214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-116.255240</td>\n",
              "      <td>0.065210</td>\n",
              "      <td>-0.510044</td>\n",
              "      <td>0.548068</td>\n",
              "      <td>1.794773</td>\n",
              "      <td>0</td>\n",
              "      <td>0.632307</td>\n",
              "      <td>0.773410</td>\n",
              "      <td>0.017388</td>\n",
              "      <td>-1.718671</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076269</td>\n",
              "      <td>0.318866</td>\n",
              "      <td>-0.751415</td>\n",
              "      <td>-0.012974</td>\n",
              "      <td>0.048322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>175.004299</td>\n",
              "      <td>0.096103</td>\n",
              "      <td>0.007558</td>\n",
              "      <td>1.246126</td>\n",
              "      <td>1.049476</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.358396</td>\n",
              "      <td>-0.913729</td>\n",
              "      <td>0.228570</td>\n",
              "      <td>-1.515762</td>\n",
              "      <td>1</td>\n",
              "      <td>0.520565</td>\n",
              "      <td>0.068509</td>\n",
              "      <td>-0.786404</td>\n",
              "      <td>0.123636</td>\n",
              "      <td>0.415623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>160.292073</td>\n",
              "      <td>0.419866</td>\n",
              "      <td>-0.912781</td>\n",
              "      <td>1.169069</td>\n",
              "      <td>1.730921</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.600411</td>\n",
              "      <td>-0.679988</td>\n",
              "      <td>0.779694</td>\n",
              "      <td>-0.275000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.252765</td>\n",
              "      <td>0.269468</td>\n",
              "      <td>-0.812795</td>\n",
              "      <td>0.018513</td>\n",
              "      <td>0.958902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>116.470989</td>\n",
              "      <td>0.234300</td>\n",
              "      <td>2.790688</td>\n",
              "      <td>4.499028</td>\n",
              "      <td>1.896799</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.130692</td>\n",
              "      <td>0.915099</td>\n",
              "      <td>0.687621</td>\n",
              "      <td>0.274696</td>\n",
              "      <td>1</td>\n",
              "      <td>0.272874</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>0.485871</td>\n",
              "      <td>0.076013</td>\n",
              "      <td>0.032830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.427468</td>\n",
              "      <td>0.499939</td>\n",
              "      <td>-0.705544</td>\n",
              "      <td>0.146236</td>\n",
              "      <td>1.149944</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.593306</td>\n",
              "      <td>-0.903743</td>\n",
              "      <td>0.580087</td>\n",
              "      <td>-0.460971</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.082479</td>\n",
              "      <td>-0.612751</td>\n",
              "      <td>0.035292</td>\n",
              "      <td>0.558888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-23.963509</td>\n",
              "      <td>0.466347</td>\n",
              "      <td>0.948074</td>\n",
              "      <td>0.151304</td>\n",
              "      <td>1.051230</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.999691</td>\n",
              "      <td>0.974986</td>\n",
              "      <td>0.684183</td>\n",
              "      <td>-0.837565</td>\n",
              "      <td>1</td>\n",
              "      <td>0.605870</td>\n",
              "      <td>0.249046</td>\n",
              "      <td>-0.897708</td>\n",
              "      <td>0.112392</td>\n",
              "      <td>0.049665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>34.998016</td>\n",
              "      <td>0.844703</td>\n",
              "      <td>-1.855467</td>\n",
              "      <td>0.410616</td>\n",
              "      <td>1.893215</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.870970</td>\n",
              "      <td>0.137163</td>\n",
              "      <td>0.287585</td>\n",
              "      <td>-0.493303</td>\n",
              "      <td>0</td>\n",
              "      <td>0.200751</td>\n",
              "      <td>0.231835</td>\n",
              "      <td>-0.971567</td>\n",
              "      <td>0.021805</td>\n",
              "      <td>0.146980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>25.208372</td>\n",
              "      <td>0.099806</td>\n",
              "      <td>1.186955</td>\n",
              "      <td>0.149279</td>\n",
              "      <td>1.814665</td>\n",
              "      <td>1</td>\n",
              "      <td>0.180369</td>\n",
              "      <td>-0.036386</td>\n",
              "      <td>0.092638</td>\n",
              "      <td>-0.412913</td>\n",
              "      <td>1</td>\n",
              "      <td>0.134442</td>\n",
              "      <td>0.336222</td>\n",
              "      <td>0.242847</td>\n",
              "      <td>-0.028761</td>\n",
              "      <td>0.370477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>12.545404</td>\n",
              "      <td>0.609515</td>\n",
              "      <td>-1.419995</td>\n",
              "      <td>1.461228</td>\n",
              "      <td>0.802081</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983229</td>\n",
              "      <td>-0.405656</td>\n",
              "      <td>0.200601</td>\n",
              "      <td>0.727770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.083958</td>\n",
              "      <td>0.077749</td>\n",
              "      <td>0.882407</td>\n",
              "      <td>0.047874</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2350d6b5-126a-4d49-80c6-b4e3b5d41bdd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2350d6b5-126a-4d49-80c6-b4e3b5d41bdd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2350d6b5-126a-4d49-80c6-b4e3b5d41bdd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0db4ebd-315c-45ad-b67d-efe9c5fa98f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0db4ebd-315c-45ad-b67d-efe9c5fa98f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0db4ebd-315c-45ad-b67d-efe9c5fa98f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72.28806329248005,\n        \"min\": -499.1133552,\n        \"max\": 395.4755536,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          164.1338703,\n          102.2237396,\n          -7.409135146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2879313748054277,\n        \"min\": 1.48749e-05,\n        \"max\": 0.999976428,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.545206872,\n          0.602514959,\n          0.901697254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.998408417766524,\n        \"min\": -4.522028416,\n        \"max\": 4.037208171,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.171289275,\n          -0.677831535,\n          -0.357404392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9907986415440954,\n        \"min\": 7.53437e-07,\n        \"max\": 11.36809509,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.601967198,\n          2.144063243,\n          3.815197569\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49998103088156465,\n        \"min\": 0.079708146,\n        \"max\": 2.974074819,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          1.030162543,\n          1.837636953,\n          1.374850933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7086343704966596,\n        \"min\": -1.0,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.151939192,\n          -0.489172815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7047771608960102,\n        \"min\": -0.999999979,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          -0.861901433,\n          -0.8171272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28984701558844134,\n        \"min\": 0.00013006,\n        \"max\": 0.999984054,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.539204071,\n          0.882769802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7049342899948611,\n        \"min\": -1.947248598,\n        \"max\": 1.889904128,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.286078102,\n          -0.399553347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23598861565443008,\n        \"min\": 1.93574e-05,\n        \"max\": 0.99527619,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          0.238895962,\n          0.588655652\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10053767803298874,\n        \"min\": 9.00286e-06,\n        \"max\": 0.779610711,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.079482944,\n          0.654553046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5788084023225075,\n        \"min\": -0.999982888,\n        \"max\": 0.999958689,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.701971397,\n          0.281066721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06747507170551137,\n        \"min\": -0.146993875,\n        \"max\": 0.304092882,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.059224938,\n          -0.098244472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30230025545767136,\n        \"min\": 1.11224e-10,\n        \"max\": 0.999988691,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          0.745863626,\n          0.005537826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the tail of the dataset\n",
        "df.tail(20)"
      ],
      "metadata": {
        "id": "UXgjj4RVx3Ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "e56bc9c9-dd86-44d0-ea43-e43c9e9f2bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                y        x1        x2        x3        x4  x5        x6  \\\n",
              "29980 -122.702466  0.397840  0.900086  0.314850  2.156017   1  0.967307   \n",
              "29981  -57.365211  0.457710 -1.287472  1.781938  1.937985   1  0.708915   \n",
              "29982   44.435817  0.515160 -0.833970  0.669078  1.428992   1 -0.391362   \n",
              "29983   -8.196866  0.646681 -0.747360  0.226113  1.562260   0  0.773139   \n",
              "29984   -3.291102  0.163411  0.630628  0.827184  2.078133   0 -0.990036   \n",
              "29985   52.195376  0.952352  0.759569  1.061226  2.111333   1  0.094293   \n",
              "29986   51.846094  0.177249 -0.327842  2.434835  1.538540   0  0.375706   \n",
              "29987   11.326324  0.425648  0.023454  2.750629  1.973477   1  0.179919   \n",
              "29988    2.390723  0.850333 -0.979980  0.728154  1.288590   1 -0.855222   \n",
              "29989   -3.363532  0.054815 -0.194828  0.398727  1.180171   1  0.447602   \n",
              "29990   34.862700  0.171636  0.944881  2.922862  1.742322   1  0.970315   \n",
              "29991 -185.189840  0.314684 -0.706094  2.594834  0.720296   1  0.851014   \n",
              "29992   65.952758  0.576610  0.922107  1.011640  1.842569   1 -0.179713   \n",
              "29993   77.430603  0.504471 -1.269860  0.874657  1.388685   1 -0.288305   \n",
              "29994  123.139214  0.845702 -0.142637  1.470988  1.255567   1  0.972481   \n",
              "29995  119.097917  0.682372  1.181348  1.002310  2.141294   0 -0.894601   \n",
              "29996  -13.577414  0.441985  0.210855  0.626278  1.364052   0 -0.954581   \n",
              "29997   88.986861  0.890115  1.652265  0.258011  1.145487   0 -0.811441   \n",
              "29998   44.554191  0.123513  0.482803  0.564734  1.439070   0 -0.364648   \n",
              "29999   39.746683  0.978126  1.700043  0.658233  1.162529   0  0.133358   \n",
              "\n",
              "             x7        x8        x9  x10       x11       x12       x13  \\\n",
              "29980  0.938976  0.632114 -0.449977    1  0.234712  0.055163  0.604103   \n",
              "29981  0.974994  0.790703  1.133278    1  0.642051  0.513329 -0.619176   \n",
              "29982  0.979343  0.951212  0.278342    0  0.210977  0.298946 -0.612391   \n",
              "29983 -0.632539  0.503871  1.117907    0  0.592148  0.236186 -0.960458   \n",
              "29984  0.760767  0.286843  0.024226    1  0.832941  0.072299  0.458910   \n",
              "29985  0.699820  0.505316 -0.460673    0  0.507760  0.073371 -0.238914   \n",
              "29986  0.523736  0.462695 -1.000520    0  0.307139  0.025370  0.139249   \n",
              "29987  0.992137  0.395314 -0.930661    1  0.095678  0.074353 -0.674701   \n",
              "29988 -0.019404  0.315912 -0.552394    0  0.568589  0.040785  0.345126   \n",
              "29989  0.115843  0.148251 -1.240882    1  0.767536  0.009179 -0.388533   \n",
              "29990  0.416199  0.308035 -0.933736    1  0.004331  0.049545 -0.919865   \n",
              "29991  0.842348  0.107446 -1.342728    1  0.193303  0.107558 -0.315954   \n",
              "29992  0.414428  0.667949  0.940533    1  0.481614  0.350730 -0.635268   \n",
              "29993  0.144563  0.013746  0.490516    0  0.004414  0.043393  0.834491   \n",
              "29994 -0.971277  0.719694  1.103845    0  0.654029  0.157868 -0.163065   \n",
              "29995 -0.918162  0.309426 -0.595277    0  0.456331  0.315299 -0.013728   \n",
              "29996  0.997034  0.064649  0.404951    1  0.126409  0.077912 -0.131121   \n",
              "29997 -0.511596  0.364253 -0.121384    0  0.036219  0.042292  0.739291   \n",
              "29998 -0.473517  0.170413  0.177105    0  0.113555  0.112393 -0.580274   \n",
              "29999 -0.558424  0.619307  0.418237    0  0.380468  0.033610 -0.169482   \n",
              "\n",
              "            x14       x15  \n",
              "29980  0.061053  0.529036  \n",
              "29981  0.040939  0.093820  \n",
              "29982  0.003103  0.527915  \n",
              "29983  0.096208  0.133148  \n",
              "29984  0.223716  0.609670  \n",
              "29985  0.118022  0.000673  \n",
              "29986  0.106558  0.210370  \n",
              "29987  0.042879  0.828106  \n",
              "29988  0.153801  0.014149  \n",
              "29989  0.197059  0.599797  \n",
              "29990  0.006929  0.221086  \n",
              "29991  0.040358  0.508633  \n",
              "29992  0.044926  0.001578  \n",
              "29993  0.039435  0.500422  \n",
              "29994  0.147853  0.596017  \n",
              "29995  0.072217  0.296694  \n",
              "29996  0.016440  0.036783  \n",
              "29997  0.045795  0.904232  \n",
              "29998  0.050031  0.797004  \n",
              "29999  0.126901  0.737527  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6ce4e8-4ead-46dd-82c2-58e96b727aed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29980</th>\n",
              "      <td>-122.702466</td>\n",
              "      <td>0.397840</td>\n",
              "      <td>0.900086</td>\n",
              "      <td>0.314850</td>\n",
              "      <td>2.156017</td>\n",
              "      <td>1</td>\n",
              "      <td>0.967307</td>\n",
              "      <td>0.938976</td>\n",
              "      <td>0.632114</td>\n",
              "      <td>-0.449977</td>\n",
              "      <td>1</td>\n",
              "      <td>0.234712</td>\n",
              "      <td>0.055163</td>\n",
              "      <td>0.604103</td>\n",
              "      <td>0.061053</td>\n",
              "      <td>0.529036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29981</th>\n",
              "      <td>-57.365211</td>\n",
              "      <td>0.457710</td>\n",
              "      <td>-1.287472</td>\n",
              "      <td>1.781938</td>\n",
              "      <td>1.937985</td>\n",
              "      <td>1</td>\n",
              "      <td>0.708915</td>\n",
              "      <td>0.974994</td>\n",
              "      <td>0.790703</td>\n",
              "      <td>1.133278</td>\n",
              "      <td>1</td>\n",
              "      <td>0.642051</td>\n",
              "      <td>0.513329</td>\n",
              "      <td>-0.619176</td>\n",
              "      <td>0.040939</td>\n",
              "      <td>0.093820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29982</th>\n",
              "      <td>44.435817</td>\n",
              "      <td>0.515160</td>\n",
              "      <td>-0.833970</td>\n",
              "      <td>0.669078</td>\n",
              "      <td>1.428992</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.391362</td>\n",
              "      <td>0.979343</td>\n",
              "      <td>0.951212</td>\n",
              "      <td>0.278342</td>\n",
              "      <td>0</td>\n",
              "      <td>0.210977</td>\n",
              "      <td>0.298946</td>\n",
              "      <td>-0.612391</td>\n",
              "      <td>0.003103</td>\n",
              "      <td>0.527915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29983</th>\n",
              "      <td>-8.196866</td>\n",
              "      <td>0.646681</td>\n",
              "      <td>-0.747360</td>\n",
              "      <td>0.226113</td>\n",
              "      <td>1.562260</td>\n",
              "      <td>0</td>\n",
              "      <td>0.773139</td>\n",
              "      <td>-0.632539</td>\n",
              "      <td>0.503871</td>\n",
              "      <td>1.117907</td>\n",
              "      <td>0</td>\n",
              "      <td>0.592148</td>\n",
              "      <td>0.236186</td>\n",
              "      <td>-0.960458</td>\n",
              "      <td>0.096208</td>\n",
              "      <td>0.133148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29984</th>\n",
              "      <td>-3.291102</td>\n",
              "      <td>0.163411</td>\n",
              "      <td>0.630628</td>\n",
              "      <td>0.827184</td>\n",
              "      <td>2.078133</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.990036</td>\n",
              "      <td>0.760767</td>\n",
              "      <td>0.286843</td>\n",
              "      <td>0.024226</td>\n",
              "      <td>1</td>\n",
              "      <td>0.832941</td>\n",
              "      <td>0.072299</td>\n",
              "      <td>0.458910</td>\n",
              "      <td>0.223716</td>\n",
              "      <td>0.609670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29985</th>\n",
              "      <td>52.195376</td>\n",
              "      <td>0.952352</td>\n",
              "      <td>0.759569</td>\n",
              "      <td>1.061226</td>\n",
              "      <td>2.111333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.094293</td>\n",
              "      <td>0.699820</td>\n",
              "      <td>0.505316</td>\n",
              "      <td>-0.460673</td>\n",
              "      <td>0</td>\n",
              "      <td>0.507760</td>\n",
              "      <td>0.073371</td>\n",
              "      <td>-0.238914</td>\n",
              "      <td>0.118022</td>\n",
              "      <td>0.000673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29986</th>\n",
              "      <td>51.846094</td>\n",
              "      <td>0.177249</td>\n",
              "      <td>-0.327842</td>\n",
              "      <td>2.434835</td>\n",
              "      <td>1.538540</td>\n",
              "      <td>0</td>\n",
              "      <td>0.375706</td>\n",
              "      <td>0.523736</td>\n",
              "      <td>0.462695</td>\n",
              "      <td>-1.000520</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307139</td>\n",
              "      <td>0.025370</td>\n",
              "      <td>0.139249</td>\n",
              "      <td>0.106558</td>\n",
              "      <td>0.210370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29987</th>\n",
              "      <td>11.326324</td>\n",
              "      <td>0.425648</td>\n",
              "      <td>0.023454</td>\n",
              "      <td>2.750629</td>\n",
              "      <td>1.973477</td>\n",
              "      <td>1</td>\n",
              "      <td>0.179919</td>\n",
              "      <td>0.992137</td>\n",
              "      <td>0.395314</td>\n",
              "      <td>-0.930661</td>\n",
              "      <td>1</td>\n",
              "      <td>0.095678</td>\n",
              "      <td>0.074353</td>\n",
              "      <td>-0.674701</td>\n",
              "      <td>0.042879</td>\n",
              "      <td>0.828106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29988</th>\n",
              "      <td>2.390723</td>\n",
              "      <td>0.850333</td>\n",
              "      <td>-0.979980</td>\n",
              "      <td>0.728154</td>\n",
              "      <td>1.288590</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.855222</td>\n",
              "      <td>-0.019404</td>\n",
              "      <td>0.315912</td>\n",
              "      <td>-0.552394</td>\n",
              "      <td>0</td>\n",
              "      <td>0.568589</td>\n",
              "      <td>0.040785</td>\n",
              "      <td>0.345126</td>\n",
              "      <td>0.153801</td>\n",
              "      <td>0.014149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29989</th>\n",
              "      <td>-3.363532</td>\n",
              "      <td>0.054815</td>\n",
              "      <td>-0.194828</td>\n",
              "      <td>0.398727</td>\n",
              "      <td>1.180171</td>\n",
              "      <td>1</td>\n",
              "      <td>0.447602</td>\n",
              "      <td>0.115843</td>\n",
              "      <td>0.148251</td>\n",
              "      <td>-1.240882</td>\n",
              "      <td>1</td>\n",
              "      <td>0.767536</td>\n",
              "      <td>0.009179</td>\n",
              "      <td>-0.388533</td>\n",
              "      <td>0.197059</td>\n",
              "      <td>0.599797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29990</th>\n",
              "      <td>34.862700</td>\n",
              "      <td>0.171636</td>\n",
              "      <td>0.944881</td>\n",
              "      <td>2.922862</td>\n",
              "      <td>1.742322</td>\n",
              "      <td>1</td>\n",
              "      <td>0.970315</td>\n",
              "      <td>0.416199</td>\n",
              "      <td>0.308035</td>\n",
              "      <td>-0.933736</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004331</td>\n",
              "      <td>0.049545</td>\n",
              "      <td>-0.919865</td>\n",
              "      <td>0.006929</td>\n",
              "      <td>0.221086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29991</th>\n",
              "      <td>-185.189840</td>\n",
              "      <td>0.314684</td>\n",
              "      <td>-0.706094</td>\n",
              "      <td>2.594834</td>\n",
              "      <td>0.720296</td>\n",
              "      <td>1</td>\n",
              "      <td>0.851014</td>\n",
              "      <td>0.842348</td>\n",
              "      <td>0.107446</td>\n",
              "      <td>-1.342728</td>\n",
              "      <td>1</td>\n",
              "      <td>0.193303</td>\n",
              "      <td>0.107558</td>\n",
              "      <td>-0.315954</td>\n",
              "      <td>0.040358</td>\n",
              "      <td>0.508633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29992</th>\n",
              "      <td>65.952758</td>\n",
              "      <td>0.576610</td>\n",
              "      <td>0.922107</td>\n",
              "      <td>1.011640</td>\n",
              "      <td>1.842569</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.179713</td>\n",
              "      <td>0.414428</td>\n",
              "      <td>0.667949</td>\n",
              "      <td>0.940533</td>\n",
              "      <td>1</td>\n",
              "      <td>0.481614</td>\n",
              "      <td>0.350730</td>\n",
              "      <td>-0.635268</td>\n",
              "      <td>0.044926</td>\n",
              "      <td>0.001578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29993</th>\n",
              "      <td>77.430603</td>\n",
              "      <td>0.504471</td>\n",
              "      <td>-1.269860</td>\n",
              "      <td>0.874657</td>\n",
              "      <td>1.388685</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.288305</td>\n",
              "      <td>0.144563</td>\n",
              "      <td>0.013746</td>\n",
              "      <td>0.490516</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004414</td>\n",
              "      <td>0.043393</td>\n",
              "      <td>0.834491</td>\n",
              "      <td>0.039435</td>\n",
              "      <td>0.500422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29994</th>\n",
              "      <td>123.139214</td>\n",
              "      <td>0.845702</td>\n",
              "      <td>-0.142637</td>\n",
              "      <td>1.470988</td>\n",
              "      <td>1.255567</td>\n",
              "      <td>1</td>\n",
              "      <td>0.972481</td>\n",
              "      <td>-0.971277</td>\n",
              "      <td>0.719694</td>\n",
              "      <td>1.103845</td>\n",
              "      <td>0</td>\n",
              "      <td>0.654029</td>\n",
              "      <td>0.157868</td>\n",
              "      <td>-0.163065</td>\n",
              "      <td>0.147853</td>\n",
              "      <td>0.596017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>119.097917</td>\n",
              "      <td>0.682372</td>\n",
              "      <td>1.181348</td>\n",
              "      <td>1.002310</td>\n",
              "      <td>2.141294</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.894601</td>\n",
              "      <td>-0.918162</td>\n",
              "      <td>0.309426</td>\n",
              "      <td>-0.595277</td>\n",
              "      <td>0</td>\n",
              "      <td>0.456331</td>\n",
              "      <td>0.315299</td>\n",
              "      <td>-0.013728</td>\n",
              "      <td>0.072217</td>\n",
              "      <td>0.296694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>-13.577414</td>\n",
              "      <td>0.441985</td>\n",
              "      <td>0.210855</td>\n",
              "      <td>0.626278</td>\n",
              "      <td>1.364052</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.954581</td>\n",
              "      <td>0.997034</td>\n",
              "      <td>0.064649</td>\n",
              "      <td>0.404951</td>\n",
              "      <td>1</td>\n",
              "      <td>0.126409</td>\n",
              "      <td>0.077912</td>\n",
              "      <td>-0.131121</td>\n",
              "      <td>0.016440</td>\n",
              "      <td>0.036783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>88.986861</td>\n",
              "      <td>0.890115</td>\n",
              "      <td>1.652265</td>\n",
              "      <td>0.258011</td>\n",
              "      <td>1.145487</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.811441</td>\n",
              "      <td>-0.511596</td>\n",
              "      <td>0.364253</td>\n",
              "      <td>-0.121384</td>\n",
              "      <td>0</td>\n",
              "      <td>0.036219</td>\n",
              "      <td>0.042292</td>\n",
              "      <td>0.739291</td>\n",
              "      <td>0.045795</td>\n",
              "      <td>0.904232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>44.554191</td>\n",
              "      <td>0.123513</td>\n",
              "      <td>0.482803</td>\n",
              "      <td>0.564734</td>\n",
              "      <td>1.439070</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.364648</td>\n",
              "      <td>-0.473517</td>\n",
              "      <td>0.170413</td>\n",
              "      <td>0.177105</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113555</td>\n",
              "      <td>0.112393</td>\n",
              "      <td>-0.580274</td>\n",
              "      <td>0.050031</td>\n",
              "      <td>0.797004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>39.746683</td>\n",
              "      <td>0.978126</td>\n",
              "      <td>1.700043</td>\n",
              "      <td>0.658233</td>\n",
              "      <td>1.162529</td>\n",
              "      <td>0</td>\n",
              "      <td>0.133358</td>\n",
              "      <td>-0.558424</td>\n",
              "      <td>0.619307</td>\n",
              "      <td>0.418237</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380468</td>\n",
              "      <td>0.033610</td>\n",
              "      <td>-0.169482</td>\n",
              "      <td>0.126901</td>\n",
              "      <td>0.737527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6ce4e8-4ead-46dd-82c2-58e96b727aed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b6ce4e8-4ead-46dd-82c2-58e96b727aed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b6ce4e8-4ead-46dd-82c2-58e96b727aed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-594329bd-2304-4bbe-8d96-0043e6ee1530\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-594329bd-2304-4bbe-8d96-0043e6ee1530')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-594329bd-2304-4bbe-8d96-0043e6ee1530 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74.78602010415605,\n        \"min\": -185.1898396,\n        \"max\": 123.1392143,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -122.7024655,\n          88.98686106,\n          119.0979167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2908949315040136,\n        \"min\": 0.054814947,\n        \"max\": 0.978125723,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.397840049,\n          0.890114994,\n          0.682371516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9331566392637066,\n        \"min\": -1.287471666,\n        \"max\": 1.700042742,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.900085697,\n          1.652265061,\n          1.181348061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8691213245538136,\n        \"min\": 0.22611252,\n        \"max\": 2.922861867,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.31484954,\n          0.258010803,\n          1.002309817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4061822687852657,\n        \"min\": 0.720296159,\n        \"max\": 2.156017021,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2.156017021,\n          1.145486568,\n          2.141294356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.707233431151425,\n        \"min\": -0.990036019,\n        \"max\": 0.972480834,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.967307377,\n          -0.811441041\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6910879791994196,\n        \"min\": -0.971276657,\n        \"max\": 0.997033594,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.938976157,\n          -0.511596226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25687901371384964,\n        \"min\": 0.01374571,\n        \"max\": 0.951211979,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.632114254,\n          0.364253349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8071473248741426,\n        \"min\": -1.342727751,\n        \"max\": 1.133278412,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -0.449976609,\n          -0.121383997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26266981449711135,\n        \"min\": 0.004331267,\n        \"max\": 0.832940577,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.234711808,\n          0.036218822\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1363845446438933,\n        \"min\": 0.009179432,\n        \"max\": 0.513328877,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.055163431,\n          0.042292393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5387599551464216,\n        \"min\": -0.960458411,\n        \"max\": 0.834490558,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.604102616,\n          0.739290806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0624471508884364,\n        \"min\": 0.003102989,\n        \"max\": 0.223716017,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.061052506,\n          0.045795071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3015569293617836,\n        \"min\": 0.000673498,\n        \"max\": 0.904231817,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.529035788,\n          0.904231817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the shape of the dataset\n",
        "print(\"Shape of Raw Dataset: \", df.shape)"
      ],
      "metadata": {
        "id": "fIBz5Jz9ycgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad7fa13-9382-4e96-df21-a9c25f3ff621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Raw Dataset:  (30000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **B. Data Partition**\n",
        "\n",
        "In this part, you will divide the raw dataset into training and test sets. To ensure trackability and replicability, **you should run the codes in this section without revision.**"
      ],
      "metadata": {
        "id": "RYy1s-do0j7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import 'sklearn' functions\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AEMFpz1X1Ul1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Y variable\n",
        "Y = df[\"y\"]\n",
        "Y"
      ],
      "metadata": {
        "id": "49p_zkHPzrZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "06f2731d-62b3-4bda-fc0f-40f83e61a52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         59.064028\n",
              "1       -104.243187\n",
              "2         92.456510\n",
              "3         10.851567\n",
              "4        210.625565\n",
              "            ...    \n",
              "29995    119.097917\n",
              "29996    -13.577414\n",
              "29997     88.986861\n",
              "29998     44.554191\n",
              "29999     39.746683\n",
              "Name: y, Length: 30000, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.064028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-104.243187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>92.456510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.851567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>210.625565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>119.097917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>-13.577414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>88.986861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>44.554191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>39.746683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows  1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set X variable\n",
        "X = df\n",
        "X.pop(\"y\")\n",
        "X"
      ],
      "metadata": {
        "id": "uMiE4U8Kz-Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6b0d1aed-a63e-435f-bc82-b28f92b7a5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x1        x2        x3        x4  x5        x6        x7  \\\n",
              "0      0.092627 -0.616344  1.010230  2.174466   1  0.997493 -0.536556   \n",
              "1      0.360192 -0.398255  0.255686  0.965165   1 -0.551480  0.904158   \n",
              "2      0.351240  0.440209  0.391802  0.996526   1 -0.995572  0.724013   \n",
              "3      0.680396  0.235624  1.303907  1.103386   0  0.547052  0.995900   \n",
              "4      0.369461 -0.825356  2.781261  1.701670   1  0.827293 -0.947857   \n",
              "...         ...       ...       ...       ...  ..       ...       ...   \n",
              "29995  0.682372  1.181348  1.002310  2.141294   0 -0.894601 -0.918162   \n",
              "29996  0.441985  0.210855  0.626278  1.364052   0 -0.954581  0.997034   \n",
              "29997  0.890115  1.652265  0.258011  1.145487   0 -0.811441 -0.511596   \n",
              "29998  0.123513  0.482803  0.564734  1.439070   0 -0.364648 -0.473517   \n",
              "29999  0.978126  1.700043  0.658233  1.162529   0  0.133358 -0.558424   \n",
              "\n",
              "             x8        x9  x10       x11       x12       x13       x14  \\\n",
              "0      0.714396  0.485646    1  0.218922  0.022818  0.344689  0.088160   \n",
              "1      0.489067  0.069215    1  0.072969  0.049336 -0.385529  0.031542   \n",
              "2      0.280797  0.069975    0  0.041180  0.154431  0.259341 -0.002101   \n",
              "3      0.367699 -0.886281    0  0.269877  0.098021 -0.938547  0.042472   \n",
              "4      0.207226  0.039131    1  0.435014  0.275365  0.100224  0.049743   \n",
              "...         ...       ...  ...       ...       ...       ...       ...   \n",
              "29995  0.309426 -0.595277    0  0.456331  0.315299 -0.013728  0.072217   \n",
              "29996  0.064649  0.404951    1  0.126409  0.077912 -0.131121  0.016440   \n",
              "29997  0.364253 -0.121384    0  0.036219  0.042292  0.739291  0.045795   \n",
              "29998  0.170413  0.177105    0  0.113555  0.112393 -0.580274  0.050031   \n",
              "29999  0.619307  0.418237    0  0.380468  0.033610 -0.169482  0.126901   \n",
              "\n",
              "            x15  \n",
              "0      0.083429  \n",
              "1      0.391962  \n",
              "2      0.354800  \n",
              "3      0.266599  \n",
              "4      0.034647  \n",
              "...         ...  \n",
              "29995  0.296694  \n",
              "29996  0.036783  \n",
              "29997  0.904232  \n",
              "29998  0.797004  \n",
              "29999  0.737527  \n",
              "\n",
              "[30000 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67bf6db6-ef5f-4a67-85f4-d8f36b1ca0e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.092627</td>\n",
              "      <td>-0.616344</td>\n",
              "      <td>1.010230</td>\n",
              "      <td>2.174466</td>\n",
              "      <td>1</td>\n",
              "      <td>0.997493</td>\n",
              "      <td>-0.536556</td>\n",
              "      <td>0.714396</td>\n",
              "      <td>0.485646</td>\n",
              "      <td>1</td>\n",
              "      <td>0.218922</td>\n",
              "      <td>0.022818</td>\n",
              "      <td>0.344689</td>\n",
              "      <td>0.088160</td>\n",
              "      <td>0.083429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.360192</td>\n",
              "      <td>-0.398255</td>\n",
              "      <td>0.255686</td>\n",
              "      <td>0.965165</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.551480</td>\n",
              "      <td>0.904158</td>\n",
              "      <td>0.489067</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>1</td>\n",
              "      <td>0.072969</td>\n",
              "      <td>0.049336</td>\n",
              "      <td>-0.385529</td>\n",
              "      <td>0.031542</td>\n",
              "      <td>0.391962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.351240</td>\n",
              "      <td>0.440209</td>\n",
              "      <td>0.391802</td>\n",
              "      <td>0.996526</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.995572</td>\n",
              "      <td>0.724013</td>\n",
              "      <td>0.280797</td>\n",
              "      <td>0.069975</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041180</td>\n",
              "      <td>0.154431</td>\n",
              "      <td>0.259341</td>\n",
              "      <td>-0.002101</td>\n",
              "      <td>0.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.680396</td>\n",
              "      <td>0.235624</td>\n",
              "      <td>1.303907</td>\n",
              "      <td>1.103386</td>\n",
              "      <td>0</td>\n",
              "      <td>0.547052</td>\n",
              "      <td>0.995900</td>\n",
              "      <td>0.367699</td>\n",
              "      <td>-0.886281</td>\n",
              "      <td>0</td>\n",
              "      <td>0.269877</td>\n",
              "      <td>0.098021</td>\n",
              "      <td>-0.938547</td>\n",
              "      <td>0.042472</td>\n",
              "      <td>0.266599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.369461</td>\n",
              "      <td>-0.825356</td>\n",
              "      <td>2.781261</td>\n",
              "      <td>1.701670</td>\n",
              "      <td>1</td>\n",
              "      <td>0.827293</td>\n",
              "      <td>-0.947857</td>\n",
              "      <td>0.207226</td>\n",
              "      <td>0.039131</td>\n",
              "      <td>1</td>\n",
              "      <td>0.435014</td>\n",
              "      <td>0.275365</td>\n",
              "      <td>0.100224</td>\n",
              "      <td>0.049743</td>\n",
              "      <td>0.034647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>0.682372</td>\n",
              "      <td>1.181348</td>\n",
              "      <td>1.002310</td>\n",
              "      <td>2.141294</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.894601</td>\n",
              "      <td>-0.918162</td>\n",
              "      <td>0.309426</td>\n",
              "      <td>-0.595277</td>\n",
              "      <td>0</td>\n",
              "      <td>0.456331</td>\n",
              "      <td>0.315299</td>\n",
              "      <td>-0.013728</td>\n",
              "      <td>0.072217</td>\n",
              "      <td>0.296694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>0.441985</td>\n",
              "      <td>0.210855</td>\n",
              "      <td>0.626278</td>\n",
              "      <td>1.364052</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.954581</td>\n",
              "      <td>0.997034</td>\n",
              "      <td>0.064649</td>\n",
              "      <td>0.404951</td>\n",
              "      <td>1</td>\n",
              "      <td>0.126409</td>\n",
              "      <td>0.077912</td>\n",
              "      <td>-0.131121</td>\n",
              "      <td>0.016440</td>\n",
              "      <td>0.036783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>0.890115</td>\n",
              "      <td>1.652265</td>\n",
              "      <td>0.258011</td>\n",
              "      <td>1.145487</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.811441</td>\n",
              "      <td>-0.511596</td>\n",
              "      <td>0.364253</td>\n",
              "      <td>-0.121384</td>\n",
              "      <td>0</td>\n",
              "      <td>0.036219</td>\n",
              "      <td>0.042292</td>\n",
              "      <td>0.739291</td>\n",
              "      <td>0.045795</td>\n",
              "      <td>0.904232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>0.123513</td>\n",
              "      <td>0.482803</td>\n",
              "      <td>0.564734</td>\n",
              "      <td>1.439070</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.364648</td>\n",
              "      <td>-0.473517</td>\n",
              "      <td>0.170413</td>\n",
              "      <td>0.177105</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113555</td>\n",
              "      <td>0.112393</td>\n",
              "      <td>-0.580274</td>\n",
              "      <td>0.050031</td>\n",
              "      <td>0.797004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>0.978126</td>\n",
              "      <td>1.700043</td>\n",
              "      <td>0.658233</td>\n",
              "      <td>1.162529</td>\n",
              "      <td>0</td>\n",
              "      <td>0.133358</td>\n",
              "      <td>-0.558424</td>\n",
              "      <td>0.619307</td>\n",
              "      <td>0.418237</td>\n",
              "      <td>0</td>\n",
              "      <td>0.380468</td>\n",
              "      <td>0.033610</td>\n",
              "      <td>-0.169482</td>\n",
              "      <td>0.126901</td>\n",
              "      <td>0.737527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows  15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67bf6db6-ef5f-4a67-85f4-d8f36b1ca0e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67bf6db6-ef5f-4a67-85f4-d8f36b1ca0e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67bf6db6-ef5f-4a67-85f4-d8f36b1ca0e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4de69ed3-ce9c-4439-b49e-842f122c8467\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4de69ed3-ce9c-4439-b49e-842f122c8467')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4de69ed3-ce9c-4439-b49e-842f122c8467 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_31d164ea-ecf8-435c-8891-815554b30d0e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_31d164ea-ecf8-435c-8891-815554b30d0e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2879313748054277,\n        \"min\": 1.48749e-05,\n        \"max\": 0.999976428,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.545206872,\n          0.602514959,\n          0.901697254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.998408417766524,\n        \"min\": -4.522028416,\n        \"max\": 4.037208171,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.171289275,\n          -0.677831535,\n          -0.357404392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9907986415440954,\n        \"min\": 7.53437e-07,\n        \"max\": 11.36809509,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.601967198,\n          2.144063243,\n          3.815197569\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49998103088156465,\n        \"min\": 0.079708146,\n        \"max\": 2.974074819,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          1.030162543,\n          1.837636953,\n          1.374850933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7086343704966596,\n        \"min\": -1.0,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.151939192,\n          -0.489172815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7047771608960102,\n        \"min\": -0.999999979,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          -0.861901433,\n          -0.8171272\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28984701558844134,\n        \"min\": 0.00013006,\n        \"max\": 0.999984054,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.539204071,\n          0.882769802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7049342899948611,\n        \"min\": -1.947248598,\n        \"max\": 1.889904128,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.286078102,\n          -0.399553347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23598861565443008,\n        \"min\": 1.93574e-05,\n        \"max\": 0.99527619,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          0.238895962,\n          0.588655652\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10053767803298874,\n        \"min\": 9.00286e-06,\n        \"max\": 0.779610711,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.079482944,\n          0.654553046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5788084023225075,\n        \"min\": -0.999982888,\n        \"max\": 0.999958689,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          0.701971397,\n          0.281066721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06747507170551137,\n        \"min\": -0.146993875,\n        \"max\": 0.304092882,\n        \"num_unique_values\": 29998,\n        \"samples\": [\n          0.059224938,\n          -0.098244472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30230025545767136,\n        \"min\": 1.11224e-10,\n        \"max\": 0.999988691,\n        \"num_unique_values\": 29999,\n        \"samples\": [\n          0.745863626,\n          0.005537826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a training set while holding out 30% of the data for testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
      ],
      "metadata": {
        "id": "W0kPw0bu0kNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the matrix shapes\n",
        "print(\"Shape of Train Set (X, Y):\", X_train.shape, Y_train.shape)\n",
        "print(\"Shape of Test Set (X, Y):\", X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "dGLNy2FN090V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a796fecb-7466-4395-e6c9-14cebb042eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train Set (X, Y): (21000, 15) (21000,)\n",
            "Shape of Test Set (X, Y): (9000, 15) (9000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the DataFrames\n",
        "X_train.head(10)"
      ],
      "metadata": {
        "id": "UHphBiJU6D54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "7fb7a44e-a41d-40f8-faab-1935dc128f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x1        x2        x3        x4  x5        x6        x7  \\\n",
              "5030   0.830337 -1.348630  1.505998  1.243940   0 -0.063637  0.298929   \n",
              "4239   0.175136 -0.830026  1.172230  2.864480   1  0.694790  1.000000   \n",
              "14120  0.310286 -1.399365  0.655200  2.101705   0 -0.671872 -0.450896   \n",
              "13866  0.545079  0.740424  0.010513  1.768809   0 -0.545971  0.542386   \n",
              "20220  0.078898  0.456369  0.154300  0.874005   0 -0.884583  0.971968   \n",
              "15724  0.522498  0.976123  0.837396  1.897550   1  0.017280  0.688607   \n",
              "26058  0.309874  0.153299  0.038736  1.916747   1  0.769164  0.550701   \n",
              "26665  0.235744  1.018249  2.002586  2.201617   1  0.108409  0.408213   \n",
              "21059  0.948247  0.342384  1.187768  2.080069   0 -0.562353  0.991227   \n",
              "7788   0.886802  0.502829  0.347040  1.070620   0 -0.227978  0.500825   \n",
              "\n",
              "             x8        x9  x10       x11       x12       x13       x14  \\\n",
              "5030   0.547228  0.980524    0  0.351949  0.134515  0.405376  0.080053   \n",
              "4239   0.511635 -1.026502    0  0.253371  0.020200 -0.487660  0.068492   \n",
              "14120  0.127184 -0.317015    0  0.045418  0.121070 -0.999891 -0.015662   \n",
              "13866  0.139906  0.064852    1  0.411732  0.034865 -0.127736  0.106032   \n",
              "20220  0.962437 -0.786529    1  0.296597  0.061989 -0.332989  0.061222   \n",
              "15724  0.075104  0.054994    1  0.015088  0.160762 -0.364310 -0.005234   \n",
              "26058  0.371760 -0.878779    1  0.193955  0.005066  0.195670  0.089964   \n",
              "26665  0.828896 -0.473336    1  0.868925  0.295895 -0.864794  0.163245   \n",
              "21059  0.294229  1.018352    0  0.328291  0.004610 -0.534615  0.099731   \n",
              "7788   0.441789 -0.386195    0  0.628746  0.015683 -0.266532  0.165394   \n",
              "\n",
              "            x15  \n",
              "5030   0.433474  \n",
              "4239   0.767384  \n",
              "14120  0.178232  \n",
              "13866  0.303804  \n",
              "20220  0.566569  \n",
              "15724  0.118435  \n",
              "26058  0.094089  \n",
              "26665  0.340676  \n",
              "21059  0.000199  \n",
              "7788   0.892846  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-392da8f2-b245-4568-ae57-a3a2cf4a572d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5030</th>\n",
              "      <td>0.830337</td>\n",
              "      <td>-1.348630</td>\n",
              "      <td>1.505998</td>\n",
              "      <td>1.243940</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.063637</td>\n",
              "      <td>0.298929</td>\n",
              "      <td>0.547228</td>\n",
              "      <td>0.980524</td>\n",
              "      <td>0</td>\n",
              "      <td>0.351949</td>\n",
              "      <td>0.134515</td>\n",
              "      <td>0.405376</td>\n",
              "      <td>0.080053</td>\n",
              "      <td>0.433474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>0.175136</td>\n",
              "      <td>-0.830026</td>\n",
              "      <td>1.172230</td>\n",
              "      <td>2.864480</td>\n",
              "      <td>1</td>\n",
              "      <td>0.694790</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.511635</td>\n",
              "      <td>-1.026502</td>\n",
              "      <td>0</td>\n",
              "      <td>0.253371</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>-0.487660</td>\n",
              "      <td>0.068492</td>\n",
              "      <td>0.767384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14120</th>\n",
              "      <td>0.310286</td>\n",
              "      <td>-1.399365</td>\n",
              "      <td>0.655200</td>\n",
              "      <td>2.101705</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.671872</td>\n",
              "      <td>-0.450896</td>\n",
              "      <td>0.127184</td>\n",
              "      <td>-0.317015</td>\n",
              "      <td>0</td>\n",
              "      <td>0.045418</td>\n",
              "      <td>0.121070</td>\n",
              "      <td>-0.999891</td>\n",
              "      <td>-0.015662</td>\n",
              "      <td>0.178232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13866</th>\n",
              "      <td>0.545079</td>\n",
              "      <td>0.740424</td>\n",
              "      <td>0.010513</td>\n",
              "      <td>1.768809</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.545971</td>\n",
              "      <td>0.542386</td>\n",
              "      <td>0.139906</td>\n",
              "      <td>0.064852</td>\n",
              "      <td>1</td>\n",
              "      <td>0.411732</td>\n",
              "      <td>0.034865</td>\n",
              "      <td>-0.127736</td>\n",
              "      <td>0.106032</td>\n",
              "      <td>0.303804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20220</th>\n",
              "      <td>0.078898</td>\n",
              "      <td>0.456369</td>\n",
              "      <td>0.154300</td>\n",
              "      <td>0.874005</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.884583</td>\n",
              "      <td>0.971968</td>\n",
              "      <td>0.962437</td>\n",
              "      <td>-0.786529</td>\n",
              "      <td>1</td>\n",
              "      <td>0.296597</td>\n",
              "      <td>0.061989</td>\n",
              "      <td>-0.332989</td>\n",
              "      <td>0.061222</td>\n",
              "      <td>0.566569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15724</th>\n",
              "      <td>0.522498</td>\n",
              "      <td>0.976123</td>\n",
              "      <td>0.837396</td>\n",
              "      <td>1.897550</td>\n",
              "      <td>1</td>\n",
              "      <td>0.017280</td>\n",
              "      <td>0.688607</td>\n",
              "      <td>0.075104</td>\n",
              "      <td>0.054994</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015088</td>\n",
              "      <td>0.160762</td>\n",
              "      <td>-0.364310</td>\n",
              "      <td>-0.005234</td>\n",
              "      <td>0.118435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26058</th>\n",
              "      <td>0.309874</td>\n",
              "      <td>0.153299</td>\n",
              "      <td>0.038736</td>\n",
              "      <td>1.916747</td>\n",
              "      <td>1</td>\n",
              "      <td>0.769164</td>\n",
              "      <td>0.550701</td>\n",
              "      <td>0.371760</td>\n",
              "      <td>-0.878779</td>\n",
              "      <td>1</td>\n",
              "      <td>0.193955</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.195670</td>\n",
              "      <td>0.089964</td>\n",
              "      <td>0.094089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26665</th>\n",
              "      <td>0.235744</td>\n",
              "      <td>1.018249</td>\n",
              "      <td>2.002586</td>\n",
              "      <td>2.201617</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108409</td>\n",
              "      <td>0.408213</td>\n",
              "      <td>0.828896</td>\n",
              "      <td>-0.473336</td>\n",
              "      <td>1</td>\n",
              "      <td>0.868925</td>\n",
              "      <td>0.295895</td>\n",
              "      <td>-0.864794</td>\n",
              "      <td>0.163245</td>\n",
              "      <td>0.340676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21059</th>\n",
              "      <td>0.948247</td>\n",
              "      <td>0.342384</td>\n",
              "      <td>1.187768</td>\n",
              "      <td>2.080069</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.562353</td>\n",
              "      <td>0.991227</td>\n",
              "      <td>0.294229</td>\n",
              "      <td>1.018352</td>\n",
              "      <td>0</td>\n",
              "      <td>0.328291</td>\n",
              "      <td>0.004610</td>\n",
              "      <td>-0.534615</td>\n",
              "      <td>0.099731</td>\n",
              "      <td>0.000199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7788</th>\n",
              "      <td>0.886802</td>\n",
              "      <td>0.502829</td>\n",
              "      <td>0.347040</td>\n",
              "      <td>1.070620</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.227978</td>\n",
              "      <td>0.500825</td>\n",
              "      <td>0.441789</td>\n",
              "      <td>-0.386195</td>\n",
              "      <td>0</td>\n",
              "      <td>0.628746</td>\n",
              "      <td>0.015683</td>\n",
              "      <td>-0.266532</td>\n",
              "      <td>0.165394</td>\n",
              "      <td>0.892846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-392da8f2-b245-4568-ae57-a3a2cf4a572d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-392da8f2-b245-4568-ae57-a3a2cf4a572d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-392da8f2-b245-4568-ae57-a3a2cf4a572d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-140617db-749b-46cc-b4d8-934ef2bc5693\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-140617db-749b-46cc-b4d8-934ef2bc5693')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-140617db-749b-46cc-b4d8-934ef2bc5693 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 21000,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28805234828180704,\n        \"min\": 1.48749e-05,\n        \"max\": 0.999976428,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          0.572756438,\n          0.01995317,\n          0.741500144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9994649093671328,\n        \"min\": -4.522028416,\n        \"max\": 4.037208171,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          1.400152156,\n          0.601849284,\n          -0.58868853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9934902297655039,\n        \"min\": 7.53437e-07,\n        \"max\": 9.314938761,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          2.023129301,\n          0.702895412,\n          0.223981378\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5002492990880978,\n        \"min\": 0.079708146,\n        \"max\": 2.963010812,\n        \"num_unique_values\": 20999,\n        \"samples\": [\n          1.619296479,\n          1.915219713,\n          0.944431354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7074903637689541,\n        \"min\": -1.0,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 20999,\n        \"samples\": [\n          0.360439509,\n          -0.332571282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7044007068236083,\n        \"min\": -0.999999979,\n        \"max\": 0.999999999,\n        \"num_unique_values\": 20998,\n        \"samples\": [\n          -0.041821801,\n          0.155944573\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2902157545821685,\n        \"min\": 0.00013006,\n        \"max\": 0.999984054,\n        \"num_unique_values\": 20999,\n        \"samples\": [\n          0.202908363,\n          0.917207644\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7055702232394856,\n        \"min\": -1.947248598,\n        \"max\": 1.889904128,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          -0.814311972,\n          -0.799599222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23592277487432917,\n        \"min\": 3.29425e-05,\n        \"max\": 0.99527619,\n        \"num_unique_values\": 20999,\n        \"samples\": [\n          0.119636768,\n          0.544429849\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10039411367996091,\n        \"min\": 1.96578e-05,\n        \"max\": 0.779610711,\n        \"num_unique_values\": 20998,\n        \"samples\": [\n          0.134482316,\n          0.042576176\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5783019043262609,\n        \"min\": -0.999982888,\n        \"max\": 0.999958689,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          0.011652662,\n          0.774995589\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06774261335981592,\n        \"min\": -0.144550038,\n        \"max\": 0.304092882,\n        \"num_unique_values\": 20998,\n        \"samples\": [\n          0.031954014,\n          0.022071493\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30242946852055935,\n        \"min\": 1.11224e-10,\n        \"max\": 0.999593201,\n        \"num_unique_values\": 21000,\n        \"samples\": [\n          0.544788884,\n          0.388098264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.head(10)"
      ],
      "metadata": {
        "id": "9zF_Nsbl40in",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "b19dba74-1027-4258-bb39-4296e9c3d89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5030     34.735132\n",
              "4239     44.291555\n",
              "14120    31.491459\n",
              "13866    -8.683834\n",
              "20220   -89.197741\n",
              "15724    38.673130\n",
              "26058   -74.111956\n",
              "26665    89.157506\n",
              "21059    62.137223\n",
              "7788     41.608962\n",
              "Name: y, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5030</th>\n",
              "      <td>34.735132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>44.291555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14120</th>\n",
              "      <td>31.491459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13866</th>\n",
              "      <td>-8.683834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20220</th>\n",
              "      <td>-89.197741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15724</th>\n",
              "      <td>38.673130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26058</th>\n",
              "      <td>-74.111956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26665</th>\n",
              "      <td>89.157506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21059</th>\n",
              "      <td>62.137223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7788</th>\n",
              "      <td>41.608962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head(10)"
      ],
      "metadata": {
        "id": "V0nQ9hlq47Gf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "4ddc1e82-2000-4903-8566-d4f917856c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x1        x2        x3        x4  x5        x6        x7  \\\n",
              "13125  0.986433  0.101937  0.159031  1.970251   0  0.974038 -0.131043   \n",
              "14635  0.767478 -0.431052  3.135878  1.933838   1 -0.249632  0.948764   \n",
              "19429  0.352949  0.842864  1.671222  1.438546   0 -0.693327  0.892089   \n",
              "4381   0.237681 -0.685494  1.914837  1.570059   1 -0.264918  0.496601   \n",
              "7659   0.141268  0.058747  3.025678  1.935007   1  0.653290  0.198428   \n",
              "10637  0.186597  0.445117  1.101864  0.869283   1 -0.091805  0.999073   \n",
              "17045  0.523210  0.371765  0.315079  2.038442   1  0.954960 -0.342773   \n",
              "24978  0.287102 -0.635989  0.032661  1.495410   1  0.489368 -0.478478   \n",
              "13639  0.675054 -0.472454  0.210905  1.562585   1 -0.997666  0.881135   \n",
              "9468   0.493854  0.209625  1.295365  1.864519   1 -0.401776 -0.984597   \n",
              "\n",
              "             x8        x9  x10       x11       x12       x13       x14  \\\n",
              "13125  0.164420  0.653012    0  0.265201  0.043620 -0.782142  0.077630   \n",
              "14635  0.005937 -0.751717    0  0.110173  0.067072  0.154542  0.030345   \n",
              "19429  0.123208 -1.294293    0  0.856533  0.055441  0.775242  0.258909   \n",
              "4381   0.232770 -0.116019    0  0.486070  0.029283 -0.320918  0.148097   \n",
              "7659   0.296989 -1.250158    1  0.033149  0.351685  0.175874 -0.045462   \n",
              "10637  0.761553  0.232988    1  0.322511  0.356911  0.296305  0.036260   \n",
              "17045  0.968143  0.838122    1  0.317342  0.344666 -0.474761  0.039049   \n",
              "24978  0.446252 -1.130273    1  0.092086  0.081887 -0.496986  0.004575   \n",
              "13639  0.969532  0.109907    0  0.847673  0.079667 -0.168957  0.215391   \n",
              "9468   0.057949 -1.037027    1  0.332311  0.141056 -0.909323  0.067077   \n",
              "\n",
              "            x15  \n",
              "13125  0.033281  \n",
              "14635  0.016297  \n",
              "19429  0.577208  \n",
              "4381   0.025689  \n",
              "7659   0.522686  \n",
              "10637  0.088549  \n",
              "17045  0.296147  \n",
              "24978  0.097796  \n",
              "13639  0.622419  \n",
              "9468   0.368561  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-541fcad0-d730-4d0b-820c-47e05eb4b9fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13125</th>\n",
              "      <td>0.986433</td>\n",
              "      <td>0.101937</td>\n",
              "      <td>0.159031</td>\n",
              "      <td>1.970251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.974038</td>\n",
              "      <td>-0.131043</td>\n",
              "      <td>0.164420</td>\n",
              "      <td>0.653012</td>\n",
              "      <td>0</td>\n",
              "      <td>0.265201</td>\n",
              "      <td>0.043620</td>\n",
              "      <td>-0.782142</td>\n",
              "      <td>0.077630</td>\n",
              "      <td>0.033281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>0.767478</td>\n",
              "      <td>-0.431052</td>\n",
              "      <td>3.135878</td>\n",
              "      <td>1.933838</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.249632</td>\n",
              "      <td>0.948764</td>\n",
              "      <td>0.005937</td>\n",
              "      <td>-0.751717</td>\n",
              "      <td>0</td>\n",
              "      <td>0.110173</td>\n",
              "      <td>0.067072</td>\n",
              "      <td>0.154542</td>\n",
              "      <td>0.030345</td>\n",
              "      <td>0.016297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19429</th>\n",
              "      <td>0.352949</td>\n",
              "      <td>0.842864</td>\n",
              "      <td>1.671222</td>\n",
              "      <td>1.438546</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.693327</td>\n",
              "      <td>0.892089</td>\n",
              "      <td>0.123208</td>\n",
              "      <td>-1.294293</td>\n",
              "      <td>0</td>\n",
              "      <td>0.856533</td>\n",
              "      <td>0.055441</td>\n",
              "      <td>0.775242</td>\n",
              "      <td>0.258909</td>\n",
              "      <td>0.577208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4381</th>\n",
              "      <td>0.237681</td>\n",
              "      <td>-0.685494</td>\n",
              "      <td>1.914837</td>\n",
              "      <td>1.570059</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.264918</td>\n",
              "      <td>0.496601</td>\n",
              "      <td>0.232770</td>\n",
              "      <td>-0.116019</td>\n",
              "      <td>0</td>\n",
              "      <td>0.486070</td>\n",
              "      <td>0.029283</td>\n",
              "      <td>-0.320918</td>\n",
              "      <td>0.148097</td>\n",
              "      <td>0.025689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7659</th>\n",
              "      <td>0.141268</td>\n",
              "      <td>0.058747</td>\n",
              "      <td>3.025678</td>\n",
              "      <td>1.935007</td>\n",
              "      <td>1</td>\n",
              "      <td>0.653290</td>\n",
              "      <td>0.198428</td>\n",
              "      <td>0.296989</td>\n",
              "      <td>-1.250158</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033149</td>\n",
              "      <td>0.351685</td>\n",
              "      <td>0.175874</td>\n",
              "      <td>-0.045462</td>\n",
              "      <td>0.522686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10637</th>\n",
              "      <td>0.186597</td>\n",
              "      <td>0.445117</td>\n",
              "      <td>1.101864</td>\n",
              "      <td>0.869283</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.091805</td>\n",
              "      <td>0.999073</td>\n",
              "      <td>0.761553</td>\n",
              "      <td>0.232988</td>\n",
              "      <td>1</td>\n",
              "      <td>0.322511</td>\n",
              "      <td>0.356911</td>\n",
              "      <td>0.296305</td>\n",
              "      <td>0.036260</td>\n",
              "      <td>0.088549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17045</th>\n",
              "      <td>0.523210</td>\n",
              "      <td>0.371765</td>\n",
              "      <td>0.315079</td>\n",
              "      <td>2.038442</td>\n",
              "      <td>1</td>\n",
              "      <td>0.954960</td>\n",
              "      <td>-0.342773</td>\n",
              "      <td>0.968143</td>\n",
              "      <td>0.838122</td>\n",
              "      <td>1</td>\n",
              "      <td>0.317342</td>\n",
              "      <td>0.344666</td>\n",
              "      <td>-0.474761</td>\n",
              "      <td>0.039049</td>\n",
              "      <td>0.296147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24978</th>\n",
              "      <td>0.287102</td>\n",
              "      <td>-0.635989</td>\n",
              "      <td>0.032661</td>\n",
              "      <td>1.495410</td>\n",
              "      <td>1</td>\n",
              "      <td>0.489368</td>\n",
              "      <td>-0.478478</td>\n",
              "      <td>0.446252</td>\n",
              "      <td>-1.130273</td>\n",
              "      <td>1</td>\n",
              "      <td>0.092086</td>\n",
              "      <td>0.081887</td>\n",
              "      <td>-0.496986</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.097796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13639</th>\n",
              "      <td>0.675054</td>\n",
              "      <td>-0.472454</td>\n",
              "      <td>0.210905</td>\n",
              "      <td>1.562585</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.997666</td>\n",
              "      <td>0.881135</td>\n",
              "      <td>0.969532</td>\n",
              "      <td>0.109907</td>\n",
              "      <td>0</td>\n",
              "      <td>0.847673</td>\n",
              "      <td>0.079667</td>\n",
              "      <td>-0.168957</td>\n",
              "      <td>0.215391</td>\n",
              "      <td>0.622419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9468</th>\n",
              "      <td>0.493854</td>\n",
              "      <td>0.209625</td>\n",
              "      <td>1.295365</td>\n",
              "      <td>1.864519</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.401776</td>\n",
              "      <td>-0.984597</td>\n",
              "      <td>0.057949</td>\n",
              "      <td>-1.037027</td>\n",
              "      <td>1</td>\n",
              "      <td>0.332311</td>\n",
              "      <td>0.141056</td>\n",
              "      <td>-0.909323</td>\n",
              "      <td>0.067077</td>\n",
              "      <td>0.368561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-541fcad0-d730-4d0b-820c-47e05eb4b9fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-541fcad0-d730-4d0b-820c-47e05eb4b9fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-541fcad0-d730-4d0b-820c-47e05eb4b9fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b7d0081-0ab4-4392-af4d-88b6eaf8e441\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b7d0081-0ab4-4392-af4d-88b6eaf8e441')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b7d0081-0ab4-4392-af4d-88b6eaf8e441 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test",
              "summary": "{\n  \"name\": \"X_test\",\n  \"rows\": 9000,\n  \"fields\": [\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28766301244546866,\n        \"min\": 8.05512e-05,\n        \"max\": 0.999828928,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.582145349,\n          0.21770559,\n          0.263235634\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.99589265835956,\n        \"min\": -3.467420903,\n        \"max\": 3.540565011,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          -0.88591475,\n          -1.050461988,\n          0.664906519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9845445921559076,\n        \"min\": 5.72333e-05,\n        \"max\": 11.36809509,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          1.598502388,\n          1.887785453,\n          0.037800119\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4992821507709346,\n        \"min\": 0.12458818,\n        \"max\": 2.974074819,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          2.279419225,\n          1.221745806,\n          1.851774157\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7113351201470546,\n        \"min\": -0.999999877,\n        \"max\": 0.999999934,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.617552105,\n          -0.502465237\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7055886404793468,\n        \"min\": -0.999999942,\n        \"max\": 0.999999885,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          -0.951223146,\n          0.103405778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2889862932493892,\n        \"min\": 0.000316904,\n        \"max\": 0.999415056,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.42576028,\n          0.210171459\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.703468147015135,\n        \"min\": -1.823155262,\n        \"max\": 1.884984986,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.712107676,\n          -0.107179046\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23615463775732057,\n        \"min\": 1.93574e-05,\n        \"max\": 0.978350362,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.349593748,\n          0.480845555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10086161169974757,\n        \"min\": 9.00286e-06,\n        \"max\": 0.69356489,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.227883297,\n          0.001419769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5799829167022181,\n        \"min\": -0.999666947,\n        \"max\": 0.999555246,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.800923403,\n          0.383230702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06684967475001906,\n        \"min\": -0.146993875,\n        \"max\": 0.302820863,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.032118866,\n          0.12231597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30201513712770695,\n        \"min\": 1.33927e-09,\n        \"max\": 0.999988691,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          0.327472317,\n          0.088402243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.head(10)"
      ],
      "metadata": {
        "id": "e1o1Y7qL4651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "9b81c3fa-aae5-4efb-9c19-baf2403d2aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13125     16.084036\n",
              "14635     73.100874\n",
              "19429     88.114504\n",
              "4381     128.835435\n",
              "7659     103.259832\n",
              "10637    -51.006675\n",
              "17045     92.479078\n",
              "24978     95.867235\n",
              "13639     71.900774\n",
              "9468     193.957762\n",
              "Name: y, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13125</th>\n",
              "      <td>16.084036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14635</th>\n",
              "      <td>73.100874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19429</th>\n",
              "      <td>88.114504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4381</th>\n",
              "      <td>128.835435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7659</th>\n",
              "      <td>103.259832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10637</th>\n",
              "      <td>-51.006675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17045</th>\n",
              "      <td>92.479078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24978</th>\n",
              "      <td>95.867235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13639</th>\n",
              "      <td>71.900774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9468</th>\n",
              "      <td>193.957762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2. Deep Learning (100 pts)**"
      ],
      "metadata": {
        "id": "BuV3AEf4s941"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you're going to experiment with several hyperparameters to improve the predictive performance of your deep learning model. In the following sections, you will practice:\n",
        "* Number of Nodes and Hidden Layers\n",
        "* Activation Functions\n",
        "* Learning Rates\n",
        "* Epochs\n",
        "* Batch Sizes\n",
        "* Dropout Rates"
      ],
      "metadata": {
        "id": "sR5Ez1Nw0xKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **A. Number of Nodes and Hidden Layers (25 pts)**"
      ],
      "metadata": {
        "id": "4oR6cVNs7_Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question A1. Build, train, and assess a neural network model with 1 hidden layer of 20 neurons.** In doing so, you should use all of the 15 input variables, a ReLU activation function, and mean absolute errors (MAE) as your loss function. You should set a batch size as 1000, epochs as 200, a learning rate as 0.001, the Adam algorithm for your optimizer, and no dropout."
      ],
      "metadata": {
        "id": "MVkeHO1g9Prp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "model = keras.Sequential([\n",
        "    Dense(20, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "OJp6sFXG8iRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a0c05d-3c08-458b-e941-2e53a7fc5daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 65.0967 - mae: 65.0967 - mse: 6801.5859\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 65.0803 - mae: 65.0803 - mse: 6789.9204\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.5572 - mae: 64.5572 - mse: 6705.0356\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.0076 - mae: 64.0076 - mse: 6588.8828 \n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.6641 - mae: 63.6641 - mse: 6495.5859 \n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.9469 - mae: 62.9469 - mse: 6402.8853 \n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.1459 - mae: 62.1459 - mse: 6225.5542\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.6260 - mae: 61.6260 - mse: 6123.1841 \n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.5287 - mae: 60.5287 - mse: 5955.6973\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 59.5176 - mae: 59.5176 - mse: 5742.9883\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.6687 - mae: 58.6687 - mse: 5589.9541\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 57.2456 - mae: 57.2456 - mse: 5397.5239\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.7241 - mae: 56.7241 - mse: 5247.7681\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.7861 - mae: 55.7861 - mse: 5118.7534\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 54.7327 - mae: 54.7327 - mse: 4885.8550\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.1785 - mae: 54.1785 - mse: 4827.5503\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 53.6580 - mae: 53.6580 - mse: 4729.5151\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.3781 - mae: 52.3781 - mse: 4506.4624\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 51.6740 - mae: 51.6740 - mse: 4423.6055\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 51.1988 - mae: 51.1988 - mse: 4335.0952\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.3159 - mae: 51.3159 - mse: 4345.0020\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.4756 - mae: 50.4756 - mse: 4226.0649  \n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.0071 - mae: 50.0071 - mse: 4121.4067 \n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.0289 - mae: 50.0289 - mse: 4137.6577\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.6748 - mae: 49.6748 - mse: 4063.4680\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.1510 - mae: 49.1510 - mse: 4018.0977\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.8666 - mae: 48.8666 - mse: 3924.4927 \n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.7489 - mae: 48.7489 - mse: 3882.7332\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.9373 - mae: 47.9373 - mse: 3777.4587\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.3671 - mae: 48.3671 - mse: 3863.9045\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.0263 - mae: 48.0263 - mse: 3764.0925 \n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.0253 - mae: 48.0253 - mse: 3808.1929 \n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.2738 - mae: 47.2738 - mse: 3671.7744 \n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.3670 - mae: 47.3670 - mse: 3691.4517 \n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.1854 - mae: 47.1854 - mse: 3697.0896 \n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.8809 - mae: 46.8809 - mse: 3617.0811 \n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.2863 - mae: 47.2863 - mse: 3638.7363 \n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.5758 - mae: 46.5758 - mse: 3549.1448\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.5440 - mae: 46.5440 - mse: 3527.6345 \n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.4062 - mae: 46.4062 - mse: 3541.8547 \n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.3244 - mae: 46.3244 - mse: 3515.1350 \n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.8033 - mae: 45.8033 - mse: 3406.0703 \n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.8237 - mae: 45.8237 - mse: 3437.8289 \n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.9355 - mae: 45.9355 - mse: 3439.8816 \n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.3004 - mae: 45.3004 - mse: 3351.7275 \n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.1873 - mae: 45.1873 - mse: 3300.7007 \n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.5978 - mae: 45.5978 - mse: 3374.2144\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.1680 - mae: 45.1680 - mse: 3324.0857\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.9316 - mae: 44.9316 - mse: 3267.1392 \n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.9567 - mae: 44.9567 - mse: 3258.4331\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.9848 - mae: 44.9848 - mse: 3274.6519 \n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.9266 - mae: 44.9266 - mse: 3246.0996\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.3742 - mae: 45.3742 - mse: 3335.6838\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.9425 - mae: 44.9425 - mse: 3243.1211 \n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.3120 - mae: 44.3120 - mse: 3156.2727 \n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.3303 - mae: 44.3303 - mse: 3142.5850 \n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.8335 - mae: 43.8335 - mse: 3086.1587 \n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.0993 - mae: 44.0993 - mse: 3145.4653 \n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.6927 - mae: 43.6927 - mse: 3090.2129 \n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.1894 - mae: 44.1894 - mse: 3142.6377 \n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.6883 - mae: 44.6883 - mse: 3178.8652\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.6356 - mae: 43.6356 - mse: 3029.7654 \n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.9105 - mae: 43.9105 - mse: 3108.5520\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.9545 - mae: 43.9545 - mse: 3111.6438\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.7755 - mae: 43.7755 - mse: 3046.8616 \n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.4778 - mae: 43.4778 - mse: 3017.4404 \n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.7025 - mae: 43.7025 - mse: 3094.8135 \n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.2243 - mae: 43.2243 - mse: 2964.4705 \n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.3581 - mae: 43.3581 - mse: 2997.4402 \n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.0253 - mae: 43.0253 - mse: 2963.9490 \n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.1362 - mae: 43.1362 - mse: 2981.7139 \n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.0162 - mae: 43.0162 - mse: 2942.6030\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.9461 - mae: 42.9461 - mse: 2997.6772 \n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.9398 - mae: 42.9398 - mse: 2956.8481\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.4816 - mae: 42.4816 - mse: 2902.6162\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.3433 - mae: 42.3433 - mse: 2854.7732\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.6303 - mae: 42.6303 - mse: 2934.7090 \n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.1142 - mae: 42.1142 - mse: 2862.4270\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.0227 - mae: 42.0227 - mse: 2818.9585 \n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.7460 - mae: 41.7460 - mse: 2761.8440\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.8741 - mae: 41.8741 - mse: 2802.3501 \n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.8742 - mae: 41.8742 - mse: 2790.4905 \n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.6970 - mae: 41.6970 - mse: 2786.7458\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.8626 - mae: 41.8626 - mse: 2808.9043\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.4095 - mae: 41.4095 - mse: 2765.5063 \n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.1876 - mae: 41.1876 - mse: 2733.4492\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.0237 - mae: 41.0237 - mse: 2675.7498 \n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.6399 - mae: 40.6399 - mse: 2643.0471\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 41.0148 - mae: 41.0148 - mse: 2757.7288 \n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.9762 - mae: 40.9762 - mse: 2693.4719\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.5747 - mae: 40.5747 - mse: 2630.2246 \n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.5138 - mae: 40.5138 - mse: 2621.4531\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.0853 - mae: 40.0853 - mse: 2592.5325\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.2693 - mae: 40.2693 - mse: 2571.0923 \n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.2198 - mae: 40.2198 - mse: 2607.0293\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.0780 - mae: 40.0780 - mse: 2576.4868\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.1135 - mae: 40.1135 - mse: 2579.1489\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.9853 - mae: 39.9853 - mse: 2571.4578\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.0993 - mae: 40.0993 - mse: 2632.0457\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.9313 - mae: 39.9313 - mse: 2571.1553\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.5094 - mae: 39.5094 - mse: 2471.8086\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.3303 - mae: 39.3303 - mse: 2515.0930\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.1995 - mae: 39.1995 - mse: 2434.3757\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.9506 - mae: 38.9506 - mse: 2446.9998\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.1175 - mae: 39.1175 - mse: 2452.7412\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.7075 - mae: 38.7075 - mse: 2430.2593\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.9215 - mae: 38.9215 - mse: 2428.4719\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.3931 - mae: 38.3931 - mse: 2381.2197\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.4932 - mae: 38.4932 - mse: 2373.4958  \n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.3284 - mae: 38.3284 - mse: 2384.0151\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.2740 - mae: 38.2740 - mse: 2375.0117 \n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.1055 - mae: 38.1055 - mse: 2347.0771 \n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.2360 - mae: 38.2360 - mse: 2370.8489 \n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.8292 - mae: 37.8292 - mse: 2299.9666 \n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.7146 - mae: 37.7146 - mse: 2331.2432 \n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.8326 - mae: 37.8326 - mse: 2332.0120\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.4672 - mae: 37.4672 - mse: 2296.4680 \n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.4292 - mae: 37.4292 - mse: 2279.7402\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.5832 - mae: 37.5832 - mse: 2286.2812\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.2416 - mae: 37.2416 - mse: 2230.9351\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.1768 - mae: 37.1768 - mse: 2261.7666\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.1433 - mae: 37.1433 - mse: 2236.1870 \n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.8431 - mae: 36.8431 - mse: 2199.6169 \n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.6210 - mae: 36.6210 - mse: 2165.4917\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.7620 - mae: 36.7620 - mse: 2183.0081\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.6457 - mae: 36.6457 - mse: 2153.3337 \n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.1629 - mae: 36.1629 - mse: 2107.6501 \n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.4373 - mae: 36.4373 - mse: 2172.2576 \n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.0741 - mae: 36.0741 - mse: 2105.9255\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.1534 - mae: 36.1534 - mse: 2132.4026 \n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.8962 - mae: 35.8962 - mse: 2085.2751 \n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.8033 - mae: 35.8033 - mse: 2077.3232\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.9914 - mae: 35.9914 - mse: 2090.8254\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.8005 - mae: 35.8005 - mse: 2079.5090 \n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3854 - mae: 35.3854 - mse: 2048.6392 \n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.6975 - mae: 35.6975 - mse: 2065.9795 \n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.4914 - mae: 35.4914 - mse: 2030.6274 \n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.4781 - mae: 35.4781 - mse: 2025.7633 \n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.5363 - mae: 35.5363 - mse: 2049.9138 \n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.0947 - mae: 35.0947 - mse: 2007.8302\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.8762 - mae: 34.8762 - mse: 1941.2526\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.6447 - mae: 34.6447 - mse: 1937.5458\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.2085 - mae: 35.2085 - mse: 2041.1296 \n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.1812 - mae: 35.1812 - mse: 2010.8834 \n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.7196 - mae: 34.7196 - mse: 1943.6017 \n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.5125 - mae: 34.5125 - mse: 1939.2990 \n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.7068 - mae: 34.7068 - mse: 1942.8390 \n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.3225 - mae: 34.3225 - mse: 1913.1096\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.5527 - mae: 34.5527 - mse: 1954.0583\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.4593 - mae: 34.4593 - mse: 1954.3403\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.2579 - mae: 34.2579 - mse: 1912.1555 \n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.5680 - mae: 34.5680 - mse: 1973.8516\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.0377 - mae: 34.0377 - mse: 1859.6918 \n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.0502 - mae: 34.0502 - mse: 1903.8234\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.0995 - mae: 34.0995 - mse: 1931.5099 \n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.0870 - mae: 34.0870 - mse: 1905.6520 \n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.0470 - mae: 34.0470 - mse: 1881.8534\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.7748 - mae: 33.7748 - mse: 1876.2084\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.7382 - mae: 33.7382 - mse: 1839.7769\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.6084 - mae: 33.6084 - mse: 1867.5647\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.7728 - mae: 33.7728 - mse: 1882.3873 \n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.6389 - mae: 33.6389 - mse: 1826.5013\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.5809 - mae: 33.5809 - mse: 1862.7666\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.6175 - mae: 33.6175 - mse: 1841.7639\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.6292 - mae: 33.6292 - mse: 1843.1678\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.3015 - mae: 33.3015 - mse: 1834.2897\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.1038 - mae: 33.1038 - mse: 1786.7028\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.3828 - mae: 33.3828 - mse: 1835.1848 \n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.2581 - mae: 33.2581 - mse: 1834.9838\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.2160 - mae: 33.2160 - mse: 1812.4659\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.9200 - mae: 32.9200 - mse: 1764.8584\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.3498 - mae: 33.3498 - mse: 1850.0409\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.2007 - mae: 33.2007 - mse: 1846.1757\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.9824 - mae: 32.9824 - mse: 1798.6936\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.7989 - mae: 32.7989 - mse: 1794.6622\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.0039 - mae: 33.0039 - mse: 1780.7656\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.9044 - mae: 32.9044 - mse: 1816.7019\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.7397 - mae: 32.7397 - mse: 1772.3558\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.7263 - mae: 32.7263 - mse: 1760.4138\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.5100 - mae: 32.5100 - mse: 1751.2737\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.8796 - mae: 32.8796 - mse: 1792.8002\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.5458 - mae: 32.5458 - mse: 1754.7612\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.6868 - mae: 32.6868 - mse: 1760.7861\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.7017 - mae: 32.7017 - mse: 1766.4401\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.2744 - mae: 32.2744 - mse: 1714.1981\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.3033 - mae: 32.3033 - mse: 1711.8303\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.4761 - mae: 32.4761 - mse: 1766.1196\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.3686 - mae: 32.3686 - mse: 1726.4443\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.4798 - mae: 32.4798 - mse: 1755.2505\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2277 - mae: 32.2277 - mse: 1701.0477\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.3315 - mae: 32.3315 - mse: 1724.3397\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.2650 - mae: 32.2650 - mse: 1715.1772\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.9170 - mae: 31.9170 - mse: 1677.4099\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.1677 - mae: 32.1677 - mse: 1724.6663 \n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.4824 - mae: 32.4824 - mse: 1730.2223 \n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0555 - mae: 32.0555 - mse: 1714.2611 \n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.2866 - mae: 32.2866 - mse: 1702.8547 \n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.4814 - mae: 32.4814 - mse: 1728.9943 \n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1547 - mae: 32.1547 - mse: 1733.8978\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.7868 - mae: 31.7868 - mse: 1660.8256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3c402d190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_A = {}\n",
        "performance_A['(20 x 1)'] = loss"
      ],
      "metadata": {
        "id": "eN_a4xzXDADo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36dab73-a924-4d1b-b12f-e93a25adc3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.6986 - mae: 31.6986 - mse: 1676.9381\n",
            "Loss: [32.059452056884766, 32.059452056884766, 1678.92333984375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question A2. Build, train, and assess a neural network model with 3 hidden layers, 30 neurons for each.** In doing so, you should use all of the 15 input variables, a ReLU activation function, and mean absolute errors (MAE) as your loss function. You should set a batch size as 1000, epochs as 200, a learning rate as 0.001, the Adam algorithm for your optimizer, and no dropout."
      ],
      "metadata": {
        "id": "8VOXJh-rDtcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "import random\n",
        "random.seed(1234)\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "ntU2b647D1nF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4a831d-b2ea-4085-c70a-a777088a562f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 65.4378 - mae: 65.4378 - mse: 6860.2656\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.7059 - mae: 64.7059 - mse: 6720.6636\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 63.5633 - mae: 63.5633 - mse: 6483.6602\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.6447 - mae: 60.6447 - mse: 5960.5986\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.4026 - mae: 54.4026 - mse: 4848.0449\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.9513 - mae: 51.9513 - mse: 4460.0005\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.3650 - mae: 50.3650 - mse: 4146.2339\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.5981 - mae: 48.5981 - mse: 3935.0325\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.6926 - mae: 46.6926 - mse: 3557.1709\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.4671 - mae: 45.4671 - mse: 3378.2673\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.4435 - mae: 44.4435 - mse: 3179.1965\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.8089 - mae: 43.8089 - mse: 3071.8538\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.3862 - mae: 43.3862 - mse: 3020.1003\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.8568 - mae: 42.8568 - mse: 2926.6797\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.7901 - mae: 41.7901 - mse: 2782.0442\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.1928 - mae: 40.1928 - mse: 2595.4731\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.0633 - mae: 38.0633 - mse: 2348.1226\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.3187 - mae: 36.3187 - mse: 2150.0095\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.3972 - mae: 34.3972 - mse: 1978.0327\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.1671 - mae: 33.1671 - mse: 1828.6042\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.2710 - mae: 32.2710 - mse: 1723.5933\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8680 - mae: 31.8680 - mse: 1712.3794\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.9102 - mae: 31.9102 - mse: 1739.2751\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.6252 - mae: 31.6252 - mse: 1665.3719\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.3068 - mae: 31.3068 - mse: 1614.4210\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5048 - mae: 31.5048 - mse: 1630.1233\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.3559 - mae: 31.3559 - mse: 1614.1874\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.1132 - mae: 31.1132 - mse: 1603.2291\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.1586 - mae: 31.1586 - mse: 1661.9764\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.9114 - mae: 30.9114 - mse: 1566.1445\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7155 - mae: 30.7155 - mse: 1558.9166\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.4608 - mae: 30.4608 - mse: 1533.8079\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6806 - mae: 30.6806 - mse: 1568.5197\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.6585 - mae: 30.6585 - mse: 1554.6952\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7890 - mae: 30.7890 - mse: 1559.9052\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.4706 - mae: 30.4706 - mse: 1534.4062\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3667 - mae: 30.3667 - mse: 1522.2874\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.1728 - mae: 30.1728 - mse: 1500.6165\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.3459 - mae: 30.3459 - mse: 1512.4498\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.2789 - mae: 30.2789 - mse: 1513.3502\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8065 - mae: 29.8065 - mse: 1464.5142\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9513 - mae: 29.9513 - mse: 1500.9071\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9172 - mae: 29.9172 - mse: 1462.4701\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8718 - mae: 29.8718 - mse: 1470.3474\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.9522 - mae: 29.9522 - mse: 1473.9745\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.5230 - mae: 29.5230 - mse: 1415.0424\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6944 - mae: 29.6944 - mse: 1442.0070\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5079 - mae: 29.5079 - mse: 1425.4528\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5674 - mae: 29.5674 - mse: 1405.4294\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4015 - mae: 29.4015 - mse: 1401.7932\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3395 - mae: 29.3395 - mse: 1403.8898\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.2712 - mae: 29.2712 - mse: 1395.4360\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4295 - mae: 29.4295 - mse: 1400.1522\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4020 - mae: 29.4020 - mse: 1393.8694\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3818 - mae: 29.3818 - mse: 1401.8990\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1542 - mae: 29.1542 - mse: 1369.4371\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1112 - mae: 29.1112 - mse: 1362.1759\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.0355 - mae: 29.0355 - mse: 1359.7498\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0073 - mae: 29.0073 - mse: 1361.8185\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.1931 - mae: 29.1931 - mse: 1364.5564\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0435 - mae: 29.0435 - mse: 1358.5260\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9354 - mae: 28.9354 - mse: 1344.0464\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1131 - mae: 29.1131 - mse: 1372.6798\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8437 - mae: 28.8437 - mse: 1353.0454\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0004 - mae: 29.0004 - mse: 1369.3602\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7329 - mae: 28.7329 - mse: 1323.7139\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0358 - mae: 29.0358 - mse: 1359.0562\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0179 - mae: 29.0179 - mse: 1356.3370\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9471 - mae: 28.9471 - mse: 1357.6187\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8873 - mae: 28.8873 - mse: 1350.8761\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9597 - mae: 28.9597 - mse: 1361.3315\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5879 - mae: 28.5879 - mse: 1334.0656\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9403 - mae: 28.9403 - mse: 1347.0734\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6313 - mae: 28.6313 - mse: 1325.4181\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0344 - mae: 29.0344 - mse: 1357.7086\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7390 - mae: 28.7390 - mse: 1326.0844\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7505 - mae: 28.7505 - mse: 1326.2736\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0330 - mae: 29.0330 - mse: 1347.2108\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9205 - mae: 28.9205 - mse: 1354.0114\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7881 - mae: 28.7881 - mse: 1336.0232\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9175 - mae: 28.9175 - mse: 1335.9218\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9120 - mae: 28.9120 - mse: 1363.7764\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8103 - mae: 28.8103 - mse: 1329.6976\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6918 - mae: 28.6918 - mse: 1322.3047\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7933 - mae: 28.7933 - mse: 1358.4628\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7471 - mae: 28.7471 - mse: 1328.6061\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6353 - mae: 28.6353 - mse: 1336.5176\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4997 - mae: 28.4997 - mse: 1307.6409\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5021 - mae: 28.5021 - mse: 1322.1547\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6595 - mae: 28.6595 - mse: 1318.7507\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7270 - mae: 28.7270 - mse: 1334.4291\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9697 - mae: 28.9697 - mse: 1356.8063\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6642 - mae: 28.6642 - mse: 1316.3964\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6964 - mae: 28.6964 - mse: 1318.2657\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8811 - mae: 28.8811 - mse: 1355.5862\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6601 - mae: 28.6601 - mse: 1314.7588\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9060 - mae: 28.9060 - mse: 1331.1572\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9417 - mae: 28.9417 - mse: 1348.2034\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3876 - mae: 28.3876 - mse: 1305.8284\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6478 - mae: 28.6478 - mse: 1325.3273\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7453 - mae: 28.7453 - mse: 1337.7390\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7521 - mae: 28.7521 - mse: 1320.0966\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5338 - mae: 28.5338 - mse: 1307.9473\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8784 - mae: 28.8784 - mse: 1340.0496\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6112 - mae: 28.6112 - mse: 1321.1174\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6789 - mae: 28.6789 - mse: 1331.1589\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7452 - mae: 28.7452 - mse: 1324.9127\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6666 - mae: 28.6666 - mse: 1324.6859\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4887 - mae: 28.4887 - mse: 1322.4335\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6420 - mae: 28.6420 - mse: 1317.5067\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4778 - mae: 28.4778 - mse: 1299.2705\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6726 - mae: 28.6726 - mse: 1326.3578\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6127 - mae: 28.6127 - mse: 1319.9606\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5349 - mae: 28.5349 - mse: 1304.2520\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6499 - mae: 28.6499 - mse: 1327.5786\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5023 - mae: 28.5023 - mse: 1299.5514\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6207 - mae: 28.6207 - mse: 1313.0760\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4950 - mae: 28.4950 - mse: 1325.1603\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5696 - mae: 28.5696 - mse: 1306.1503\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7731 - mae: 28.7731 - mse: 1336.9871\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4581 - mae: 28.4581 - mse: 1304.6185\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5407 - mae: 28.5407 - mse: 1307.5604\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6148 - mae: 28.6148 - mse: 1333.9397\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4729 - mae: 28.4729 - mse: 1315.3594\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3738 - mae: 28.3738 - mse: 1295.9183\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6017 - mae: 28.6017 - mse: 1323.0804\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7406 - mae: 28.7406 - mse: 1340.1067\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8176 - mae: 28.8176 - mse: 1343.4244\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4977 - mae: 28.4977 - mse: 1308.1702\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4164 - mae: 28.4164 - mse: 1307.7648\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3898 - mae: 28.3898 - mse: 1296.5741\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4679 - mae: 28.4679 - mse: 1299.9508\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4256 - mae: 28.4256 - mse: 1294.1995\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.3547 - mae: 28.3547 - mse: 1306.2120\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4284 - mae: 28.4284 - mse: 1304.1501\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4603 - mae: 28.4603 - mse: 1308.6754\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4852 - mae: 28.4852 - mse: 1301.1661\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5266 - mae: 28.5266 - mse: 1298.7048\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4122 - mae: 28.4122 - mse: 1299.7264\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3141 - mae: 28.3141 - mse: 1307.5470\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4688 - mae: 28.4688 - mse: 1302.0396\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.4012 - mae: 28.4012 - mse: 1285.8965\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.6431 - mae: 28.6431 - mse: 1309.7721\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5022 - mae: 28.5022 - mse: 1302.7301\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5543 - mae: 28.5543 - mse: 1311.7516\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5499 - mae: 28.5499 - mse: 1308.6898\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3978 - mae: 28.3978 - mse: 1301.7965\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2587 - mae: 28.2587 - mse: 1282.4293\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4135 - mae: 28.4135 - mse: 1293.3989\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4457 - mae: 28.4457 - mse: 1303.2826\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3470 - mae: 28.3470 - mse: 1301.1648\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5502 - mae: 28.5502 - mse: 1301.2921\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1823 - mae: 28.1823 - mse: 1280.4319\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5118 - mae: 28.5118 - mse: 1309.3805\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2665 - mae: 28.2665 - mse: 1288.4539\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3554 - mae: 28.3554 - mse: 1296.3877\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5110 - mae: 28.5110 - mse: 1312.0924\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4888 - mae: 28.4888 - mse: 1304.7825\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2642 - mae: 28.2642 - mse: 1289.6095\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3096 - mae: 28.3096 - mse: 1300.1587\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1799 - mae: 28.1799 - mse: 1279.9489\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5550 - mae: 28.5550 - mse: 1307.8606\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7642 - mae: 28.7642 - mse: 1329.6923\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3934 - mae: 28.3934 - mse: 1293.8978\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7819 - mae: 28.7819 - mse: 1327.3004\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4286 - mae: 28.4286 - mse: 1310.7864\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1770 - mae: 28.1770 - mse: 1277.2511\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5859 - mae: 28.5859 - mse: 1308.1204\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3984 - mae: 28.3984 - mse: 1301.2540\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4624 - mae: 28.4624 - mse: 1308.5917\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4901 - mae: 28.4901 - mse: 1297.4913\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2609 - mae: 28.2609 - mse: 1281.5315\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3176 - mae: 28.3176 - mse: 1304.4352\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5166 - mae: 28.5166 - mse: 1328.7748\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5005 - mae: 28.5005 - mse: 1304.1738\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8411 - mae: 28.8411 - mse: 1330.2623\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7200 - mae: 28.7200 - mse: 1332.3330\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4886 - mae: 28.4886 - mse: 1306.4924\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3235 - mae: 28.3235 - mse: 1291.9147\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4105 - mae: 28.4105 - mse: 1290.3619\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5427 - mae: 28.5427 - mse: 1300.0258\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4794 - mae: 28.4794 - mse: 1303.7350\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2766 - mae: 28.2766 - mse: 1291.3479\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5843 - mae: 28.5843 - mse: 1309.0840\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3645 - mae: 28.3645 - mse: 1294.5974\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4950 - mae: 28.4950 - mse: 1313.9143\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6702 - mae: 28.6702 - mse: 1321.4270\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4633 - mae: 28.4633 - mse: 1303.6331\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4153 - mae: 28.4153 - mse: 1296.5890\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3292 - mae: 28.3292 - mse: 1302.9414\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2338 - mae: 28.2338 - mse: 1288.8107\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5396 - mae: 28.5396 - mse: 1300.0504\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3612 - mae: 28.3612 - mse: 1293.5428\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4947 - mae: 28.4947 - mse: 1302.5211\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5317 - mae: 28.5317 - mse: 1310.0889\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4165 - mae: 28.4165 - mse: 1305.4127\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3772 - mae: 28.3772 - mse: 1306.9391\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3531 - mae: 28.3531 - mse: 1292.5913\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3045 - mae: 28.3045 - mse: 1289.4393\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4965 - mae: 28.4965 - mse: 1299.1217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3c01e3d10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_A['(30 x 3)'] = loss"
      ],
      "metadata": {
        "id": "5TFh6RSpD12j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834d3a5c-1edd-4ef7-c1c6-5df51572eef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.4648 - mae: 28.4648 - mse: 1288.1936\n",
            "Loss: [28.562971115112305, 28.562971115112305, 1281.6761474609375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **B. Activation Functions (25 pts)**"
      ],
      "metadata": {
        "id": "73uzQLBO8VNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question B1. You're going to make only one change to the model in Question A2. Please replace the current activation function (ReLU) with 1) the sigmoid function and 2) the softplus function** (You should train the model with sigmoid and the one with softplus separately)**. Do you find any improvement compared to the model in Question A2?**"
      ],
      "metadata": {
        "id": "CuCUqe0cEnjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.sigmoid, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.sigmoid, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.sigmoid, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "6JPEnomv8io0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9951fbd7-e2e9-4254-fa79-f6443f078d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 65.7002 - mae: 65.7002 - mse: 6869.1270\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 64.8035 - mae: 64.8035 - mse: 6737.1187\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 64.5445 - mae: 64.5445 - mse: 6713.4424\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 63.7187 - mae: 63.7187 - mse: 6528.5703\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 63.9534 - mae: 63.9534 - mse: 6579.0415\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 63.1046 - mae: 63.1046 - mse: 6428.0796\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 63.1881 - mae: 63.1881 - mse: 6448.0063\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 63.1946 - mae: 63.1946 - mse: 6477.1528\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 62.3964 - mae: 62.3964 - mse: 6321.8521\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 62.5005 - mae: 62.5005 - mse: 6319.0225\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 62.0514 - mae: 62.0514 - mse: 6271.6157\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 62.3168 - mae: 62.3168 - mse: 6274.1270\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.7846 - mae: 61.7846 - mse: 6267.2104\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.1060 - mae: 62.1060 - mse: 6243.0547\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.2254 - mae: 62.2254 - mse: 6334.1377\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.3539 - mae: 61.3539 - mse: 6133.3022\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.4628 - mae: 61.4628 - mse: 6191.4424\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.1626 - mae: 61.1626 - mse: 6058.4775\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.0079 - mae: 61.0079 - mse: 6123.4668\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.0969 - mae: 61.0969 - mse: 6100.9731\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.7351 - mae: 60.7351 - mse: 6042.0488\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.1690 - mae: 60.1690 - mse: 5913.3936\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.3292 - mae: 60.3292 - mse: 5971.2905\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.6780 - mae: 60.6780 - mse: 6005.1260\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.0068 - mae: 60.0068 - mse: 5908.6382\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 60.0959 - mae: 60.0959 - mse: 5972.5542\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 60.0709 - mae: 60.0709 - mse: 5896.8740\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.8048 - mae: 59.8048 - mse: 5871.3193\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.4310 - mae: 59.4310 - mse: 5813.2051\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.5182 - mae: 59.5182 - mse: 5771.9766\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.1813 - mae: 59.1813 - mse: 5725.7500\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.2574 - mae: 59.2574 - mse: 5741.7446\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.7405 - mae: 58.7405 - mse: 5669.7397\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 59.5458 - mae: 59.5458 - mse: 5826.9199\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.1455 - mae: 59.1455 - mse: 5735.8394\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.2669 - mae: 58.2669 - mse: 5649.5864\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.5872 - mae: 58.5872 - mse: 5693.7876\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.6828 - mae: 58.6828 - mse: 5681.9912\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.4389 - mae: 58.4389 - mse: 5643.0742\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.0218 - mae: 58.0218 - mse: 5553.1162\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 57.9048 - mae: 57.9048 - mse: 5543.7358\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.7196 - mae: 58.7196 - mse: 5719.6846\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.0253 - mae: 58.0253 - mse: 5546.0688\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.9567 - mae: 57.9567 - mse: 5566.6880\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.2482 - mae: 58.2482 - mse: 5600.3789\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.1300 - mae: 58.1300 - mse: 5592.9771\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.9038 - mae: 57.9038 - mse: 5529.7510\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.4209 - mae: 58.4209 - mse: 5639.4077\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.9827 - mae: 57.9827 - mse: 5544.0771\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.6212 - mae: 57.6212 - mse: 5475.4482\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7271 - mae: 57.7271 - mse: 5478.9243\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7260 - mae: 57.7260 - mse: 5524.2500\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.2977 - mae: 57.2977 - mse: 5404.5884\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7743 - mae: 57.7743 - mse: 5510.2246\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.9276 - mae: 57.9276 - mse: 5515.6250\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.7327 - mae: 57.7327 - mse: 5473.2188\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.6150 - mae: 57.6150 - mse: 5494.7134\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.3968 - mae: 57.3968 - mse: 5395.2246\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.0918 - mae: 57.0918 - mse: 5408.9990\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.0278 - mae: 57.0278 - mse: 5365.0962\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.8386 - mae: 56.8386 - mse: 5324.6025\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.0254 - mae: 57.0254 - mse: 5349.8877\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.0075 - mae: 57.0075 - mse: 5370.7188\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 57.2980 - mae: 57.2980 - mse: 5422.7026\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 57.6937 - mae: 57.6937 - mse: 5504.6348\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.7911 - mae: 56.7911 - mse: 5351.0479\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.7606 - mae: 56.7606 - mse: 5326.5278\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.5057 - mae: 56.5057 - mse: 5266.2334\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.6602 - mae: 56.6602 - mse: 5301.9678\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.0081 - mae: 56.0081 - mse: 5189.7070\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.7839 - mae: 56.7839 - mse: 5325.8667\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.1381 - mae: 56.1381 - mse: 5191.9932\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.7865 - mae: 56.7865 - mse: 5347.1592\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.7494 - mae: 56.7494 - mse: 5305.2056\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.6095 - mae: 56.6095 - mse: 5316.0244\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.5273 - mae: 56.5273 - mse: 5293.8628\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.3400 - mae: 56.3400 - mse: 5271.6177\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.8424 - mae: 56.8424 - mse: 5378.4565\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.4218 - mae: 56.4218 - mse: 5261.0483\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.5142 - mae: 56.5142 - mse: 5308.0664\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.4142 - mae: 56.4142 - mse: 5265.7222\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.0377 - mae: 56.0377 - mse: 5171.1572\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.5802 - mae: 56.5802 - mse: 5295.9321\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.0737 - mae: 56.0737 - mse: 5209.8018\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.7894 - mae: 56.7894 - mse: 5305.9941\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.4822 - mae: 56.4822 - mse: 5301.2095\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.4271 - mae: 56.4271 - mse: 5282.9707\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.5060 - mae: 56.5060 - mse: 5301.2603\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.9431 - mae: 56.9431 - mse: 5357.4351\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.1721 - mae: 56.1721 - mse: 5212.0010\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 55.8798 - mae: 55.8798 - mse: 5157.3184\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 55.6434 - mae: 55.6434 - mse: 5135.6372\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 56.2331 - mae: 56.2331 - mse: 5186.7476\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 55.4172 - mae: 55.4172 - mse: 5121.7266\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 54.6607 - mae: 54.6607 - mse: 4969.6616\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.5221 - mae: 53.5221 - mse: 4802.5430\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 53.1406 - mae: 53.1406 - mse: 4710.9805\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 52.2509 - mae: 52.2509 - mse: 4533.5762\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.4051 - mae: 52.4051 - mse: 4586.0337\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.3984 - mae: 51.3984 - mse: 4457.4375\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.1598 - mae: 51.1598 - mse: 4434.1479\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 50.6193 - mae: 50.6193 - mse: 4314.4307\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.6018 - mae: 50.6018 - mse: 4308.5273\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.4574 - mae: 50.4574 - mse: 4292.0684\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.1432 - mae: 50.1432 - mse: 4255.9424\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.4895 - mae: 49.4895 - mse: 4157.7812\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.6190 - mae: 49.6190 - mse: 4147.1377\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.8872 - mae: 49.8872 - mse: 4187.8511\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.9235 - mae: 49.9235 - mse: 4179.0620\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.4175 - mae: 49.4175 - mse: 4083.3267\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.1968 - mae: 49.1968 - mse: 4084.0396\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.4503 - mae: 49.4503 - mse: 4153.1348\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.6640 - mae: 48.6640 - mse: 3970.0408\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 48.0679 - mae: 48.0679 - mse: 3958.5146\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.9967 - mae: 48.9967 - mse: 4049.3945\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.6738 - mae: 48.6738 - mse: 4001.2952\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.6222 - mae: 48.6222 - mse: 3972.8979\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.3195 - mae: 48.3195 - mse: 3925.2986\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.4271 - mae: 48.4271 - mse: 3926.4473\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.3040 - mae: 48.3040 - mse: 3923.5234\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.2448 - mae: 48.2448 - mse: 3899.7920\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.2147 - mae: 48.2147 - mse: 3936.5825\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.3258 - mae: 48.3258 - mse: 3932.6123\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.0292 - mae: 48.0292 - mse: 3864.3860\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.7012 - mae: 47.7012 - mse: 3828.1777\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.0316 - mae: 48.0316 - mse: 3905.6719\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.9331 - mae: 47.9331 - mse: 3856.1628\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.2955 - mae: 47.2955 - mse: 3780.0044\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.2275 - mae: 47.2275 - mse: 3753.0930\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.5413 - mae: 47.5413 - mse: 3800.4424\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.5542 - mae: 47.5542 - mse: 3788.8535\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.2137 - mae: 47.2137 - mse: 3748.0703\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.3500 - mae: 47.3500 - mse: 3765.5178\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.0315 - mae: 47.0315 - mse: 3687.3528\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.8732 - mae: 46.8732 - mse: 3708.1499\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.6490 - mae: 47.6490 - mse: 3828.0237\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.6697 - mae: 47.6697 - mse: 3828.3835\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.7863 - mae: 46.7863 - mse: 3673.7942\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.7180 - mae: 46.7180 - mse: 3667.7510\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.3065 - mae: 47.3065 - mse: 3747.1663\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.9172 - mae: 46.9172 - mse: 3704.0305\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.8104 - mae: 46.8104 - mse: 3674.4189\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.9298 - mae: 46.9298 - mse: 3707.9475\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.9241 - mae: 46.9241 - mse: 3705.6553\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.6565 - mae: 46.6565 - mse: 3651.4224\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.7491 - mae: 46.7491 - mse: 3675.5371\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.5025 - mae: 46.5025 - mse: 3614.0015\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.3570 - mae: 46.3570 - mse: 3627.0645\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.7606 - mae: 46.7606 - mse: 3696.8733\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.4723 - mae: 46.4723 - mse: 3607.8621\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.4286 - mae: 46.4286 - mse: 3624.2800\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.5071 - mae: 46.5071 - mse: 3657.3315\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.8618 - mae: 46.8618 - mse: 3717.1721\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.6267 - mae: 46.6267 - mse: 3662.6018\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.0720 - mae: 46.0720 - mse: 3532.2026\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.9500 - mae: 45.9500 - mse: 3570.4651\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.8899 - mae: 45.8899 - mse: 3528.2314\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.5412 - mae: 45.5412 - mse: 3474.1062\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.6648 - mae: 45.6648 - mse: 3534.2664\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.3068 - mae: 45.3068 - mse: 3432.6628\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.9548 - mae: 45.9548 - mse: 3544.9141\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 45.3076 - mae: 45.3076 - mse: 3429.1572\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45.0048 - mae: 45.0048 - mse: 3415.3904\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.9913 - mae: 44.9913 - mse: 3413.9443\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.2993 - mae: 44.2993 - mse: 3345.4971\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.0971 - mae: 44.0971 - mse: 3298.1960\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.2156 - mae: 44.2156 - mse: 3319.3042\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 43.5963 - mae: 43.5963 - mse: 3229.8018\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.5084 - mae: 43.5084 - mse: 3236.2549\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.0210 - mae: 43.0210 - mse: 3218.6375\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.5386 - mae: 42.5386 - mse: 3128.2546\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 42.2606 - mae: 42.2606 - mse: 3092.0195\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 41.9856 - mae: 41.9856 - mse: 3035.7139\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 41.9762 - mae: 41.9762 - mse: 3064.4971\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 41.5018 - mae: 41.5018 - mse: 3005.2361\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.2682 - mae: 41.2682 - mse: 2954.8589\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.2991 - mae: 41.2991 - mse: 2984.4878\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.9640 - mae: 40.9640 - mse: 2881.9309\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.0669 - mae: 41.0669 - mse: 2924.4692\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.4672 - mae: 40.4672 - mse: 2839.4551\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.5562 - mae: 40.5562 - mse: 2862.1682\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.4016 - mae: 40.4016 - mse: 2868.5559\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.5358 - mae: 40.5358 - mse: 2846.5774\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.2031 - mae: 40.2031 - mse: 2806.0662\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.1080 - mae: 40.1080 - mse: 2815.8337\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39.5690 - mae: 39.5690 - mse: 2725.6025\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.9934 - mae: 39.9934 - mse: 2768.9705\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.7697 - mae: 39.7697 - mse: 2763.0669\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.1857 - mae: 39.1857 - mse: 2667.7700\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.7967 - mae: 39.7967 - mse: 2757.6492\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.4322 - mae: 39.4322 - mse: 2699.9233\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.4765 - mae: 39.4765 - mse: 2709.9404\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.1092 - mae: 39.1092 - mse: 2660.3733\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.0657 - mae: 39.0657 - mse: 2638.1501\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.4497 - mae: 39.4497 - mse: 2680.4124\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.0042 - mae: 39.0042 - mse: 2679.2170\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.6894 - mae: 38.6894 - mse: 2618.5120\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.4643 - mae: 38.4643 - mse: 2593.5347\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.5722 - mae: 38.5722 - mse: 2590.0820\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.5670 - mae: 38.5670 - mse: 2588.1377\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3c36ccb10>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_B = {}\n",
        "performance_B['Sigmoid'] = loss"
      ],
      "metadata": {
        "id": "jbcl4gnDFXfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4621ef90-20b0-4446-c6e3-2ffe9923cdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.6833 - mae: 38.6833 - mse: 2638.3806\n",
            "Loss: [38.52397918701172, 38.52397918701172, 2586.60107421875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.softplus, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.softplus, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.softplus, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "XmFLOZoyFXR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c147ee1-cb4d-4646-c4a6-eb0f93810ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 65.1390 - mae: 65.1390 - mse: 6781.8530\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 63.8832 - mae: 63.8832 - mse: 6617.4653\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 61.7343 - mae: 61.7343 - mse: 6210.5542\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 57.6499 - mae: 57.6499 - mse: 5486.0322\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.9363 - mae: 53.9363 - mse: 4831.5796\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.2481 - mae: 53.2481 - mse: 4660.3535\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.1722 - mae: 53.1722 - mse: 4688.6074\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.5697 - mae: 52.5697 - mse: 4560.9194\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.1361 - mae: 52.1361 - mse: 4488.4395\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 51.0240 - mae: 51.0240 - mse: 4302.3887\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.0865 - mae: 50.0865 - mse: 4124.1104\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.7248 - mae: 48.7248 - mse: 3930.9314\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.0642 - mae: 47.0642 - mse: 3647.8992\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.1304 - mae: 46.1304 - mse: 3470.2405\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.3538 - mae: 44.3538 - mse: 3192.6309\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.5195 - mae: 44.5195 - mse: 3229.9563\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.0746 - mae: 44.0746 - mse: 3144.5205\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.8105 - mae: 43.8105 - mse: 3066.2559\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 43.7542 - mae: 43.7542 - mse: 3000.8953\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 43.1027 - mae: 43.1027 - mse: 2940.7148\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.0664 - mae: 43.0664 - mse: 2922.4680\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 42.7537 - mae: 42.7537 - mse: 2871.8850\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 42.8355 - mae: 42.8355 - mse: 2894.4802\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 42.9231 - mae: 42.9231 - mse: 2911.6963\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 42.7618 - mae: 42.7618 - mse: 2875.8499\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 42.6566 - mae: 42.6566 - mse: 2888.1978\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42.4460 - mae: 42.4460 - mse: 2853.0125\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 41.7837 - mae: 41.7837 - mse: 2725.9868\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 41.8603 - mae: 41.8603 - mse: 2770.2627\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 41.7282 - mae: 41.7282 - mse: 2742.9050\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.3616 - mae: 41.3616 - mse: 2676.3999\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.7761 - mae: 40.7761 - mse: 2611.1548\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.6460 - mae: 40.6460 - mse: 2595.7227\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.9987 - mae: 39.9987 - mse: 2529.7734\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.4722 - mae: 39.4722 - mse: 2458.0012\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.0838 - mae: 39.0838 - mse: 2418.3135\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.8401 - mae: 38.8401 - mse: 2426.6785\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.1526 - mae: 38.1526 - mse: 2300.6714\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.0437 - mae: 37.0437 - mse: 2184.1843\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.6645 - mae: 36.6645 - mse: 2142.7312\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.2867 - mae: 36.2867 - mse: 2151.7747\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.8588 - mae: 34.8588 - mse: 1969.4032\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.6030 - mae: 34.6030 - mse: 1939.7164\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.0198 - mae: 34.0198 - mse: 1860.0737\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.4834 - mae: 33.4834 - mse: 1804.2039\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.0020 - mae: 33.0020 - mse: 1776.0133\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.1685 - mae: 32.1685 - mse: 1677.3093\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.4999 - mae: 32.4999 - mse: 1721.0272\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1289 - mae: 32.1289 - mse: 1685.6669\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8290 - mae: 31.8290 - mse: 1663.6097\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6591 - mae: 31.6591 - mse: 1636.8710\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.0331 - mae: 32.0331 - mse: 1671.4044\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.5352 - mae: 31.5352 - mse: 1619.1047\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4756 - mae: 31.4756 - mse: 1633.4047\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2835 - mae: 31.2835 - mse: 1609.8088\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1550 - mae: 31.1550 - mse: 1569.3488\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0252 - mae: 31.0252 - mse: 1581.0183\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8706 - mae: 30.8706 - mse: 1566.2307\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9735 - mae: 30.9735 - mse: 1568.3015\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0686 - mae: 31.0686 - mse: 1563.6797\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9913 - mae: 30.9913 - mse: 1575.1649\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.2755 - mae: 30.2755 - mse: 1478.0074\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6665 - mae: 30.6665 - mse: 1535.4879\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8758 - mae: 30.8758 - mse: 1558.3486\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6222 - mae: 30.6222 - mse: 1528.8824\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7168 - mae: 30.7168 - mse: 1544.7543\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.4748 - mae: 30.4748 - mse: 1518.2292\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3497 - mae: 30.3497 - mse: 1519.1460\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5434 - mae: 30.5434 - mse: 1525.4061\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4897 - mae: 30.4897 - mse: 1517.7675\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3784 - mae: 30.3784 - mse: 1491.2675\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3771 - mae: 30.3771 - mse: 1493.8094\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.4549 - mae: 30.4549 - mse: 1509.5962\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2061 - mae: 30.2061 - mse: 1481.1133\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0772 - mae: 30.0772 - mse: 1466.9814\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3716 - mae: 30.3716 - mse: 1496.8651\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3270 - mae: 30.3270 - mse: 1495.7891\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3682 - mae: 30.3682 - mse: 1495.4219\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1571 - mae: 30.1571 - mse: 1495.7039\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9193 - mae: 29.9193 - mse: 1452.0363\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1270 - mae: 30.1270 - mse: 1479.3558\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.8440 - mae: 29.8440 - mse: 1457.4916\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.0875 - mae: 30.0875 - mse: 1451.4598\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.9626 - mae: 29.9626 - mse: 1446.7222\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.7398 - mae: 29.7398 - mse: 1434.2905\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.7977 - mae: 29.7977 - mse: 1433.8763\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.9498 - mae: 29.9498 - mse: 1453.1814\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.1835 - mae: 30.1835 - mse: 1469.0276\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.7582 - mae: 29.7582 - mse: 1437.4836\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.9185 - mae: 29.9185 - mse: 1434.1715\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.0193 - mae: 30.0193 - mse: 1449.5074\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.5945 - mae: 29.5945 - mse: 1416.5088\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.0246 - mae: 30.0246 - mse: 1446.9517\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.9541 - mae: 29.9541 - mse: 1450.1030\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7655 - mae: 29.7655 - mse: 1432.3806\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7461 - mae: 29.7461 - mse: 1422.8331\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6263 - mae: 29.6263 - mse: 1408.0405\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6820 - mae: 29.6820 - mse: 1426.5343\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4870 - mae: 29.4870 - mse: 1398.2933\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5190 - mae: 29.5190 - mse: 1414.8070\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5894 - mae: 29.5894 - mse: 1413.5072\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7296 - mae: 29.7296 - mse: 1429.0945\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.6108 - mae: 29.6108 - mse: 1400.9385\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 29.5286 - mae: 29.5286 - mse: 1391.8805\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2215 - mae: 29.2215 - mse: 1383.7886\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5145 - mae: 29.5145 - mse: 1405.7358\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5021 - mae: 29.5021 - mse: 1387.2449\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2627 - mae: 29.2627 - mse: 1379.3442\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6694 - mae: 29.6694 - mse: 1418.3124\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4627 - mae: 29.4627 - mse: 1394.3337\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4781 - mae: 29.4781 - mse: 1394.4886\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4287 - mae: 29.4287 - mse: 1387.4109\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4865 - mae: 29.4865 - mse: 1395.7336\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1926 - mae: 29.1926 - mse: 1370.2892\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5031 - mae: 29.5031 - mse: 1407.9312\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2188 - mae: 29.2188 - mse: 1390.6755\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2967 - mae: 29.2967 - mse: 1373.2446\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2614 - mae: 29.2614 - mse: 1373.7661\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1083 - mae: 29.1083 - mse: 1361.3064\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3118 - mae: 29.3118 - mse: 1376.0480\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1314 - mae: 29.1314 - mse: 1372.7452\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2430 - mae: 29.2430 - mse: 1368.4004\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9899 - mae: 28.9899 - mse: 1344.9888\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5262 - mae: 29.5262 - mse: 1398.9492\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2761 - mae: 29.2761 - mse: 1366.9222\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0666 - mae: 29.0666 - mse: 1349.6168\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.9251 - mae: 28.9251 - mse: 1333.4376\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3664 - mae: 29.3664 - mse: 1369.6180\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.9761 - mae: 28.9761 - mse: 1342.0026\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0832 - mae: 29.0832 - mse: 1346.1022\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0153 - mae: 29.0153 - mse: 1350.1885\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0119 - mae: 29.0119 - mse: 1342.2039\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0497 - mae: 29.0497 - mse: 1346.0569\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3920 - mae: 29.3920 - mse: 1366.6748\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2787 - mae: 29.2787 - mse: 1389.6558\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.7851 - mae: 28.7851 - mse: 1328.4470\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.8609 - mae: 28.8609 - mse: 1328.8403\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.1213 - mae: 29.1213 - mse: 1360.6218\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.1816 - mae: 29.1816 - mse: 1368.7920\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.7986 - mae: 28.7986 - mse: 1337.7684\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.1808 - mae: 29.1808 - mse: 1357.5120\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.0025 - mae: 29.0025 - mse: 1341.7676\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.2110 - mae: 29.2110 - mse: 1364.4795\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 28.9864 - mae: 28.9864 - mse: 1343.0430\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.0794 - mae: 29.0794 - mse: 1344.2002\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.9378 - mae: 28.9378 - mse: 1335.3435\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.8390 - mae: 28.8390 - mse: 1330.7223\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.9307 - mae: 28.9307 - mse: 1331.1823\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.8172 - mae: 28.8172 - mse: 1340.4316\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2465 - mae: 29.2465 - mse: 1365.1381\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6590 - mae: 28.6590 - mse: 1323.1293\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8276 - mae: 28.8276 - mse: 1334.7848\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8872 - mae: 28.8872 - mse: 1328.9114\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9317 - mae: 28.9317 - mse: 1335.5598\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9662 - mae: 28.9662 - mse: 1339.5671\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1058 - mae: 29.1058 - mse: 1354.2542\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2156 - mae: 29.2156 - mse: 1362.8760\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0885 - mae: 29.0885 - mse: 1353.5798\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8052 - mae: 28.8052 - mse: 1330.9084\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8300 - mae: 28.8300 - mse: 1333.9182\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9222 - mae: 28.9222 - mse: 1331.9047\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1145 - mae: 29.1145 - mse: 1351.6803\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8387 - mae: 28.8387 - mse: 1334.5490\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9365 - mae: 28.9365 - mse: 1339.7440\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7789 - mae: 28.7789 - mse: 1316.5533\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4545 - mae: 28.4545 - mse: 1300.3784\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9093 - mae: 28.9093 - mse: 1328.7002\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.0620 - mae: 29.0620 - mse: 1345.3622\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1809 - mae: 29.1809 - mse: 1345.1062\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2117 - mae: 29.2117 - mse: 1357.2966\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8486 - mae: 28.8486 - mse: 1318.2454\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0122 - mae: 29.0122 - mse: 1336.9474\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0120 - mae: 29.0120 - mse: 1333.0771\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0803 - mae: 29.0803 - mse: 1345.5409\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7274 - mae: 28.7274 - mse: 1311.7596\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5821 - mae: 28.5821 - mse: 1307.1703\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7911 - mae: 28.7911 - mse: 1320.3303\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8621 - mae: 28.8621 - mse: 1330.2920\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8646 - mae: 28.8646 - mse: 1334.3755\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6710 - mae: 28.6710 - mse: 1318.8442\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7433 - mae: 28.7433 - mse: 1317.6141\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0958 - mae: 29.0958 - mse: 1358.3723\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8146 - mae: 28.8146 - mse: 1329.2157\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8476 - mae: 28.8476 - mse: 1326.8141\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9070 - mae: 28.9070 - mse: 1331.1621\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.7110 - mae: 28.7110 - mse: 1311.6587\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8204 - mae: 28.8204 - mse: 1327.0226\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7103 - mae: 28.7103 - mse: 1320.8230\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8115 - mae: 28.8115 - mse: 1316.5498\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8584 - mae: 28.8584 - mse: 1318.1053\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1155 - mae: 29.1155 - mse: 1346.2941\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0878 - mae: 29.0878 - mse: 1359.9449\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8419 - mae: 28.8419 - mse: 1327.0077\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9431 - mae: 28.9431 - mse: 1334.5543\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6498 - mae: 28.6498 - mse: 1312.3475\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6939 - mae: 28.6939 - mse: 1312.2371\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.8395 - mae: 28.8395 - mse: 1326.7904\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8077 - mae: 28.8077 - mse: 1315.0957\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0163 - mae: 29.0163 - mse: 1336.1521\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7600 - mae: 28.7600 - mse: 1316.4308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3bb530d90>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_B['Softplus'] = loss"
      ],
      "metadata": {
        "id": "J-Woui5-FXCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ccc512-efd5-480e-aa18-49edd6829d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.5318 - mae: 28.5318 - mse: 1296.5765\n",
            "Loss: [28.669757843017578, 28.669757843017578, 1296.729248046875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "print(performance_A['(20 x 1)'])\n",
        "print(performance_A['(30 x 3)'])\n",
        "print(performance_B['Sigmoid'])\n",
        "print(performance_B['Softplus'])"
      ],
      "metadata": {
        "id": "Dn-jwWFcGIwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48bf463-e7fb-4cf7-95aa-30aafed0104a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32.059452056884766, 32.059452056884766, 1678.92333984375]\n",
            "[28.562971115112305, 28.562971115112305, 1281.6761474609375]\n",
            "[38.52397918701172, 38.52397918701172, 2586.60107421875]\n",
            "[28.669757843017578, 28.669757843017578, 1296.729248046875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you find any improvement compared to the model in Question A2?**\n",
        "\n",
        "* **Your answer:**\n",
        "We can see the comparison of three different activation functions from this step. It's clear that relu is the best performing function out of the 3 choices because it provides the lowest mse value (A2 model). Softplus model comes second for silghtly higher values for all parameters."
      ],
      "metadata": {
        "id": "QXoHdJbmGXE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question B2. Revise the model in Question B1 as follows. For the first/second/third layers, use the activation function sigmoid/softplus/relu, respectively. Do you find any improvement compared to the models in Question A2 and Question B1?**"
      ],
      "metadata": {
        "id": "gQ80ZHzuFZK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.sigmoid, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.softplus, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "yjOl5dRuFZfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ce5cf1-432d-4ce1-d511-4661bd7c20b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 65.7949 - mae: 65.7949 - mse: 6928.3809\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 65.0175 - mae: 65.0175 - mse: 6787.8281\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 63.5190 - mae: 63.5190 - mse: 6548.0864\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.7762 - mae: 61.7762 - mse: 6211.4575\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.9965 - mae: 58.9965 - mse: 5740.5859\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.6399 - mae: 55.6399 - mse: 5099.9839\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 54.9506 - mae: 54.9506 - mse: 5021.7783\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 54.8957 - mae: 54.8957 - mse: 4963.7378\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.9478 - mae: 53.9478 - mse: 4792.3389\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.9825 - mae: 53.9825 - mse: 4802.1025\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 53.5886 - mae: 53.5886 - mse: 4771.5308\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 53.0901 - mae: 53.0901 - mse: 4665.2192\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 53.0722 - mae: 53.0722 - mse: 4649.0122\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 52.2094 - mae: 52.2094 - mse: 4484.5454\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 52.2724 - mae: 52.2724 - mse: 4523.0762\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 51.8300 - mae: 51.8300 - mse: 4454.1538\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 51.2217 - mae: 51.2217 - mse: 4348.5151\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 50.7115 - mae: 50.7115 - mse: 4300.6479\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 50.3995 - mae: 50.3995 - mse: 4162.4214\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 49.7263 - mae: 49.7263 - mse: 4108.3013\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 49.4064 - mae: 49.4064 - mse: 3983.5066\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 49.6950 - mae: 49.6950 - mse: 4061.0942\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 48.1561 - mae: 48.1561 - mse: 3770.4937\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.2550 - mae: 48.2550 - mse: 3826.8325\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 47.3282 - mae: 47.3282 - mse: 3681.8784\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.5868 - mae: 46.5868 - mse: 3543.8091\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 46.1847 - mae: 46.1847 - mse: 3445.7036\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.7234 - mae: 45.7234 - mse: 3339.9316\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.5718 - mae: 45.5718 - mse: 3300.9111\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.6884 - mae: 45.6884 - mse: 3343.7224\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.9028 - mae: 44.9028 - mse: 3226.4299\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.0927 - mae: 45.0927 - mse: 3241.5212\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.4393 - mae: 44.4393 - mse: 3129.7471\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.5104 - mae: 44.5104 - mse: 3158.0806\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.6859 - mae: 44.6859 - mse: 3191.1602\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.3973 - mae: 44.3973 - mse: 3135.2673\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.6603 - mae: 44.6603 - mse: 3153.0190\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 44.1423 - mae: 44.1423 - mse: 3133.7271\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 43.7248 - mae: 43.7248 - mse: 3011.1016\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.6574 - mae: 43.6574 - mse: 3026.5562\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.7393 - mae: 43.7393 - mse: 3034.9399\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 43.1896 - mae: 43.1896 - mse: 2944.7896\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 43.2150 - mae: 43.2150 - mse: 2958.1042\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 42.7286 - mae: 42.7286 - mse: 2890.5918\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 42.7858 - mae: 42.7858 - mse: 2899.7405\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 42.3008 - mae: 42.3008 - mse: 2830.5317\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42.1287 - mae: 42.1287 - mse: 2825.5505\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 41.6047 - mae: 41.6047 - mse: 2745.7119\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 41.1861 - mae: 41.1861 - mse: 2698.7439\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 40.9064 - mae: 40.9064 - mse: 2659.0242\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.3243 - mae: 40.3243 - mse: 2579.1746\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.0300 - mae: 40.0300 - mse: 2563.4734\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.4052 - mae: 39.4052 - mse: 2478.4946\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.4048 - mae: 38.4048 - mse: 2359.7019\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.4791 - mae: 37.4791 - mse: 2257.9087\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.2451 - mae: 37.2451 - mse: 2248.1860\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.6366 - mae: 36.6366 - mse: 2172.4692\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.5876 - mae: 35.5876 - mse: 2057.0623\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.8137 - mae: 34.8137 - mse: 1981.4595\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.5860 - mae: 34.5860 - mse: 1949.5415\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.7371 - mae: 33.7371 - mse: 1868.2433\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.5878 - mae: 33.5878 - mse: 1868.3013\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.2331 - mae: 33.2331 - mse: 1802.1702\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.8506 - mae: 32.8506 - mse: 1787.3563\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.8190 - mae: 32.8190 - mse: 1785.9351\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.3147 - mae: 32.3147 - mse: 1708.1244\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1464 - mae: 32.1464 - mse: 1743.1719\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0635 - mae: 32.0635 - mse: 1684.6237\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.9304 - mae: 31.9304 - mse: 1704.5736\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.9418 - mae: 31.9418 - mse: 1688.8217\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8904 - mae: 31.8904 - mse: 1670.7211\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8151 - mae: 31.8151 - mse: 1682.6184\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6842 - mae: 31.6842 - mse: 1696.6017\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4327 - mae: 31.4327 - mse: 1633.4153\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4088 - mae: 31.4088 - mse: 1624.0752\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5251 - mae: 31.5251 - mse: 1620.5111\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7549 - mae: 31.7549 - mse: 1662.4427\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7305 - mae: 31.7305 - mse: 1681.1698\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7799 - mae: 31.7799 - mse: 1646.4729\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.7101 - mae: 31.7101 - mse: 1658.4917\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3931 - mae: 31.3931 - mse: 1651.9486\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3687 - mae: 31.3687 - mse: 1617.4734\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2639 - mae: 31.2639 - mse: 1637.1827\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2715 - mae: 31.2715 - mse: 1613.1152\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4640 - mae: 31.4640 - mse: 1631.1809\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3780 - mae: 31.3780 - mse: 1660.7400\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2513 - mae: 31.2513 - mse: 1615.4869\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0295 - mae: 31.0295 - mse: 1603.0731\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3474 - mae: 31.3474 - mse: 1638.3282\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8835 - mae: 30.8835 - mse: 1589.8945\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.1942 - mae: 31.1942 - mse: 1608.8136\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.9505 - mae: 30.9505 - mse: 1573.8467\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.9067 - mae: 30.9067 - mse: 1576.7424\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0343 - mae: 31.0343 - mse: 1595.7551\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.9061 - mae: 30.9061 - mse: 1582.8755\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.8626 - mae: 30.8626 - mse: 1557.2593\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7412 - mae: 30.7412 - mse: 1545.7426\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0502 - mae: 31.0502 - mse: 1578.7734\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6337 - mae: 30.6337 - mse: 1542.8481\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6751 - mae: 30.6751 - mse: 1554.5046\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.5123 - mae: 30.5123 - mse: 1530.2467\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.4577 - mae: 30.4577 - mse: 1518.1362\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6697 - mae: 30.6697 - mse: 1544.8407\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7336 - mae: 30.7336 - mse: 1552.3745\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7339 - mae: 30.7339 - mse: 1549.6740\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.4707 - mae: 30.4707 - mse: 1506.8586\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1686 - mae: 30.1686 - mse: 1500.4763\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3169 - mae: 30.3169 - mse: 1520.0591\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.5243 - mae: 30.5243 - mse: 1525.6801\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.5552 - mae: 30.5552 - mse: 1532.1653\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3108 - mae: 30.3108 - mse: 1524.7242\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.2707 - mae: 30.2707 - mse: 1510.7632\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2267 - mae: 30.2267 - mse: 1496.0120\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.4041 - mae: 30.4041 - mse: 1517.1858\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1566 - mae: 30.1566 - mse: 1493.4161\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1516 - mae: 30.1516 - mse: 1493.6373\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.2715 - mae: 30.2715 - mse: 1517.4932\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.1392 - mae: 30.1392 - mse: 1491.3147\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.0140 - mae: 30.0140 - mse: 1460.7102\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1333 - mae: 30.1333 - mse: 1499.1414\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.0642 - mae: 30.0642 - mse: 1499.2866\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.9707 - mae: 29.9707 - mse: 1459.7540\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.9783 - mae: 29.9783 - mse: 1481.9980\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.8510 - mae: 29.8510 - mse: 1455.6571\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.7673 - mae: 29.7673 - mse: 1447.1304\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.9616 - mae: 29.9616 - mse: 1456.6189\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9995 - mae: 29.9995 - mse: 1447.9635\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9082 - mae: 29.9082 - mse: 1447.8163\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9556 - mae: 29.9556 - mse: 1454.5499\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8702 - mae: 29.8702 - mse: 1449.1978\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6132 - mae: 29.6132 - mse: 1423.1576\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6290 - mae: 29.6290 - mse: 1438.4930\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4428 - mae: 29.4428 - mse: 1403.5110\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6675 - mae: 29.6675 - mse: 1439.5665\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8175 - mae: 29.8175 - mse: 1440.6300\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6960 - mae: 29.6960 - mse: 1439.8060\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5444 - mae: 29.5444 - mse: 1423.4056\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5403 - mae: 29.5403 - mse: 1401.4318\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5697 - mae: 29.5697 - mse: 1410.6735\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6055 - mae: 29.6055 - mse: 1411.8833\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5309 - mae: 29.5309 - mse: 1438.2407\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6102 - mae: 29.6102 - mse: 1418.0134\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3428 - mae: 29.3428 - mse: 1392.5386\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4646 - mae: 29.4646 - mse: 1406.6736\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6438 - mae: 29.6438 - mse: 1406.7710\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4370 - mae: 29.4370 - mse: 1413.0276\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2672 - mae: 29.2672 - mse: 1395.0118\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3944 - mae: 29.3944 - mse: 1394.7996\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3528 - mae: 29.3528 - mse: 1380.2091\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3336 - mae: 29.3336 - mse: 1384.7902\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1635 - mae: 29.1635 - mse: 1366.0554\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4169 - mae: 29.4169 - mse: 1417.7534\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3091 - mae: 29.3091 - mse: 1381.9037\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0373 - mae: 29.0373 - mse: 1377.3445\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2780 - mae: 29.2780 - mse: 1383.4496\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0429 - mae: 29.0429 - mse: 1363.2662\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2259 - mae: 29.2259 - mse: 1379.2979\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1839 - mae: 29.1839 - mse: 1379.8770\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0986 - mae: 29.0986 - mse: 1361.2164\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2368 - mae: 29.2368 - mse: 1367.3669\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2792 - mae: 29.2792 - mse: 1391.6066\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9474 - mae: 28.9474 - mse: 1345.6841\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8776 - mae: 28.8776 - mse: 1350.3181\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3386 - mae: 29.3386 - mse: 1398.5582\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.2698 - mae: 29.2698 - mse: 1378.5917\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2845 - mae: 29.2845 - mse: 1366.9988\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0745 - mae: 29.0745 - mse: 1368.9955\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9607 - mae: 28.9607 - mse: 1351.3311\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.9683 - mae: 28.9683 - mse: 1351.4517\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8214 - mae: 28.8214 - mse: 1341.5138\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9661 - mae: 28.9661 - mse: 1357.4604\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9562 - mae: 28.9562 - mse: 1345.9163\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1456 - mae: 29.1456 - mse: 1365.0480\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0105 - mae: 29.0105 - mse: 1341.4191\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2285 - mae: 29.2285 - mse: 1374.0040\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1269 - mae: 29.1269 - mse: 1367.5447\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0533 - mae: 29.0533 - mse: 1368.1348\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1186 - mae: 29.1186 - mse: 1368.4254\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2552 - mae: 29.2552 - mse: 1376.2689\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0175 - mae: 29.0175 - mse: 1355.2576\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0933 - mae: 29.0933 - mse: 1360.7250\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8055 - mae: 28.8055 - mse: 1336.9106\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2100 - mae: 29.2100 - mse: 1383.4829\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1059 - mae: 29.1059 - mse: 1367.4608\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0274 - mae: 29.0274 - mse: 1354.5319\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9166 - mae: 28.9166 - mse: 1345.1897\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1390 - mae: 29.1390 - mse: 1356.9740\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9777 - mae: 28.9777 - mse: 1339.1472\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8771 - mae: 28.8771 - mse: 1336.9641\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1024 - mae: 29.1024 - mse: 1355.7275\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.8881 - mae: 28.8881 - mse: 1340.7850\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.7336 - mae: 28.7336 - mse: 1323.6125\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.8705 - mae: 28.8705 - mse: 1333.9241\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.8854 - mae: 28.8854 - mse: 1352.2357\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8144 - mae: 28.8144 - mse: 1339.6978\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 28.8708 - mae: 28.8708 - mse: 1341.0713\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.1277 - mae: 29.1277 - mse: 1361.7269\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9388 - mae: 28.9388 - mse: 1341.0190\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.7904 - mae: 28.7904 - mse: 1323.9266\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.8031 - mae: 28.8031 - mse: 1332.5183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3bb537350>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_B['Sigmoid/Softplus/ReLU'] = loss"
      ],
      "metadata": {
        "id": "LWIYtfSRFZxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ed66c5-20f1-44f5-dd2d-c090fda14671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.5923 - mae: 28.5923 - mse: 1311.2065\n",
            "Loss: [28.712177276611328, 28.712177276611328, 1303.4306640625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "print(performance_A['(20 x 1)'])\n",
        "print(performance_A['(30 x 3)'])\n",
        "print(performance_B['Sigmoid'])\n",
        "print(performance_B['Softplus'])\n",
        "print(performance_B['Sigmoid/Softplus/ReLU'])"
      ],
      "metadata": {
        "id": "zfwqEYZQHmMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200efc4e-21db-482a-f09e-da6b92b182fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32.059452056884766, 32.059452056884766, 1678.92333984375]\n",
            "[28.562971115112305, 28.562971115112305, 1281.6761474609375]\n",
            "[38.52397918701172, 38.52397918701172, 2586.60107421875]\n",
            "[28.669757843017578, 28.669757843017578, 1296.729248046875]\n",
            "[28.712177276611328, 28.712177276611328, 1303.4306640625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you find any improvement compared to the models in Question A2 and Question B1?**\n",
        "\n",
        "* **Your answer:**\n",
        "We see that the model from A2, namely with 3 hidden layers all using relu activation function has the lowest mse value, which substantiates why relu is the most common activation function in deep learning models. It's also noteworthy that sigmoid/softplus/relu model provides decent result, suggesting that a mixture of different activation functions could somehow neutralize the limitation of differet function and aggregate their strength."
      ],
      "metadata": {
        "id": "RgugpBE5Gs2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **C. Learning Rates, Epochs, and Batch Sizes (25 pts)**"
      ],
      "metadata": {
        "id": "-Mb9SQt_8XMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question C1. You're going to make only one change to the model in Question A2. Please train and assess four models, each of which has (learning_rates, batch_size, epochs) combination (0.01, 1000, 200), (0.001, 1000, 400), (0.01, 1000, 400), and (0.01, 500, 400), respectively. Do you find any improvement compared to the model in Question A2?**"
      ],
      "metadata": {
        "id": "7Zk5je0wIDfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) (learning_rates, batch_size, epochs) = (0.01, 1000, 200)"
      ],
      "metadata": {
        "id": "3d1le_EmJZuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "I3ogP7vZ8jHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b344af8f-6ab1-4bc1-d91f-72f16828f5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 62.7873 - mae: 62.7873 - mse: 6397.7202\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.0512 - mae: 51.0512 - mse: 4294.3447\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.0103 - mae: 45.0103 - mse: 3347.3474\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.9882 - mae: 41.9882 - mse: 2871.1008\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.9749 - mae: 36.9749 - mse: 2311.2424\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.4480 - mae: 35.4480 - mse: 2180.1990\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.2590 - mae: 34.2590 - mse: 1987.3632\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.8401 - mae: 31.8401 - mse: 1666.9885\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4449 - mae: 31.4449 - mse: 1608.8961\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.5987 - mae: 30.5987 - mse: 1541.1362\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3460 - mae: 30.3460 - mse: 1510.7030\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.8709 - mae: 29.8709 - mse: 1441.1390\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.9332 - mae: 29.9332 - mse: 1458.7821\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.4040 - mae: 29.4040 - mse: 1403.8553\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.4069 - mae: 29.4069 - mse: 1394.0621\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3317 - mae: 29.3317 - mse: 1377.5275\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1813 - mae: 29.1813 - mse: 1373.3937\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2311 - mae: 29.2311 - mse: 1378.4825\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2652 - mae: 29.2652 - mse: 1374.7668\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0748 - mae: 29.0748 - mse: 1364.5702\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0955 - mae: 29.0955 - mse: 1351.5315\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9086 - mae: 28.9086 - mse: 1339.8286\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2424 - mae: 29.2424 - mse: 1369.5538\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8433 - mae: 28.8433 - mse: 1331.1163\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8479 - mae: 28.8479 - mse: 1339.7250\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1307 - mae: 29.1307 - mse: 1367.5505\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7582 - mae: 28.7582 - mse: 1334.7444\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9669 - mae: 28.9669 - mse: 1343.7811\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9588 - mae: 28.9588 - mse: 1334.3911\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5057 - mae: 28.5057 - mse: 1305.8752\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6261 - mae: 28.6261 - mse: 1313.6770\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7454 - mae: 28.7454 - mse: 1336.8839\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8345 - mae: 28.8345 - mse: 1329.7073\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4916 - mae: 28.4916 - mse: 1309.7130\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6587 - mae: 28.6587 - mse: 1315.6837\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8097 - mae: 28.8097 - mse: 1335.1439\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7551 - mae: 28.7551 - mse: 1339.6729\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5091 - mae: 28.5091 - mse: 1315.6056\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5402 - mae: 28.5402 - mse: 1307.5002\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4157 - mae: 28.4157 - mse: 1298.5636\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8064 - mae: 28.8064 - mse: 1335.5814\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5565 - mae: 28.5565 - mse: 1306.4409\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5351 - mae: 28.5351 - mse: 1305.8967\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7946 - mae: 28.7946 - mse: 1336.9115\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5621 - mae: 28.5621 - mse: 1320.6329\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3716 - mae: 28.3716 - mse: 1293.0143\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8111 - mae: 28.8111 - mse: 1326.5919\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3049 - mae: 28.3049 - mse: 1287.3665\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4583 - mae: 28.4583 - mse: 1304.3865\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4148 - mae: 28.4148 - mse: 1306.0502\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.6923 - mae: 28.6923 - mse: 1324.7402\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5945 - mae: 28.5945 - mse: 1317.5771\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4712 - mae: 28.4712 - mse: 1306.5997\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9241 - mae: 28.9241 - mse: 1338.0217\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5103 - mae: 28.5103 - mse: 1301.4443\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.3982 - mae: 28.3982 - mse: 1288.5449\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4906 - mae: 28.4906 - mse: 1309.8325\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5309 - mae: 28.5309 - mse: 1308.8988\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5529 - mae: 28.5529 - mse: 1307.0656\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.2895 - mae: 28.2895 - mse: 1283.0314\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5426 - mae: 28.5426 - mse: 1313.9880\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4845 - mae: 28.4845 - mse: 1304.9432\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5496 - mae: 28.5496 - mse: 1309.3092\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2791 - mae: 28.2791 - mse: 1279.4564\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2099 - mae: 28.2099 - mse: 1276.8938\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9795 - mae: 27.9795 - mse: 1259.6702\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3676 - mae: 28.3676 - mse: 1284.8612\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7310 - mae: 28.7310 - mse: 1325.5895\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2885 - mae: 28.2885 - mse: 1281.2604\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3868 - mae: 28.3868 - mse: 1302.7870\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9889 - mae: 27.9889 - mse: 1264.1825\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1950 - mae: 28.1950 - mse: 1268.0735\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4399 - mae: 28.4399 - mse: 1300.7639\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5341 - mae: 28.5341 - mse: 1298.8784\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2223 - mae: 28.2223 - mse: 1279.7792\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3472 - mae: 28.3472 - mse: 1284.8818\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5094 - mae: 28.5094 - mse: 1303.4485\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5734 - mae: 28.5734 - mse: 1301.8158\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2393 - mae: 28.2393 - mse: 1282.3889\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3519 - mae: 28.3519 - mse: 1283.6173\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3281 - mae: 28.3281 - mse: 1292.9194\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5433 - mae: 28.5433 - mse: 1301.0825\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3426 - mae: 28.3426 - mse: 1300.6401\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0712 - mae: 28.0712 - mse: 1257.5597\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2075 - mae: 28.2075 - mse: 1281.8458\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0480 - mae: 28.0480 - mse: 1263.5665\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0430 - mae: 28.0430 - mse: 1263.6967\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0304 - mae: 28.0304 - mse: 1265.1176\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0371 - mae: 28.0371 - mse: 1263.0143\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1644 - mae: 28.1644 - mse: 1282.8912\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2219 - mae: 28.2219 - mse: 1281.1919\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0196 - mae: 28.0196 - mse: 1264.2152\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2147 - mae: 28.2147 - mse: 1275.8085\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1954 - mae: 28.1954 - mse: 1273.8120\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9591 - mae: 27.9591 - mse: 1244.6512\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3576 - mae: 28.3576 - mse: 1290.9867\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4961 - mae: 28.4961 - mse: 1303.3042\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1344 - mae: 28.1344 - mse: 1268.1106\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1835 - mae: 28.1835 - mse: 1272.4844\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3701 - mae: 28.3701 - mse: 1292.1282\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1004 - mae: 28.1004 - mse: 1269.6146\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1265 - mae: 28.1265 - mse: 1269.5769\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2384 - mae: 28.2384 - mse: 1285.6779\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9872 - mae: 27.9872 - mse: 1257.9562\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3229 - mae: 28.3229 - mse: 1276.7711\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1873 - mae: 28.1873 - mse: 1284.6348\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0205 - mae: 28.0205 - mse: 1256.3531\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2656 - mae: 28.2656 - mse: 1283.0846\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1508 - mae: 28.1508 - mse: 1275.5515\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3199 - mae: 28.3199 - mse: 1285.8851\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2853 - mae: 28.2853 - mse: 1286.9316\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9531 - mae: 27.9531 - mse: 1254.5573\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3685 - mae: 28.3685 - mse: 1297.5524\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0857 - mae: 28.0857 - mse: 1263.5012\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9639 - mae: 27.9639 - mse: 1258.2189\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2304 - mae: 28.2304 - mse: 1278.1853\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9599 - mae: 27.9599 - mse: 1254.9343\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2699 - mae: 28.2699 - mse: 1290.3269\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9113 - mae: 27.9113 - mse: 1256.8051\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3174 - mae: 28.3174 - mse: 1286.7195\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9229 - mae: 27.9229 - mse: 1256.7852\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0446 - mae: 28.0446 - mse: 1263.2163\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9419 - mae: 27.9419 - mse: 1262.8641\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8924 - mae: 27.8924 - mse: 1256.3927\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2760 - mae: 28.2760 - mse: 1277.9459\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9436 - mae: 27.9436 - mse: 1253.7650\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9913 - mae: 27.9913 - mse: 1259.2189\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8329 - mae: 27.8329 - mse: 1250.8755\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3267 - mae: 28.3267 - mse: 1287.8972\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1049 - mae: 28.1049 - mse: 1263.8574\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3201 - mae: 28.3201 - mse: 1297.2791\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.9012 - mae: 27.9012 - mse: 1253.6293\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.1120 - mae: 28.1120 - mse: 1267.7263\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1818 - mae: 28.1818 - mse: 1271.5895\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0163 - mae: 28.0163 - mse: 1276.8988\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1802 - mae: 28.1802 - mse: 1277.0590\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1099 - mae: 28.1099 - mse: 1271.5585\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0583 - mae: 28.0583 - mse: 1264.4316\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.7333 - mae: 27.7333 - mse: 1247.7295\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.2324 - mae: 28.2324 - mse: 1286.3879\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.2052 - mae: 28.2052 - mse: 1273.0697\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9720 - mae: 27.9720 - mse: 1259.2360\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0274 - mae: 28.0274 - mse: 1266.3353\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1236 - mae: 28.1236 - mse: 1261.1049\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8530 - mae: 27.8530 - mse: 1253.2064\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7355 - mae: 27.7355 - mse: 1243.8856\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9907 - mae: 27.9907 - mse: 1263.6265\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9327 - mae: 27.9327 - mse: 1252.3623\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9091 - mae: 27.9091 - mse: 1254.8749\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9511 - mae: 27.9511 - mse: 1260.1462\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9897 - mae: 27.9897 - mse: 1259.2589\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0753 - mae: 28.0753 - mse: 1276.7930\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8457 - mae: 27.8457 - mse: 1253.2515\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0729 - mae: 28.0729 - mse: 1264.9087\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1949 - mae: 28.1949 - mse: 1280.2952\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6533 - mae: 27.6533 - mse: 1236.3911\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9477 - mae: 27.9477 - mse: 1258.3293\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9508 - mae: 27.9508 - mse: 1253.8595\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8027 - mae: 27.8027 - mse: 1245.2911\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0510 - mae: 28.0510 - mse: 1264.3895\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1744 - mae: 28.1744 - mse: 1274.2125\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0064 - mae: 28.0064 - mse: 1264.6392\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9565 - mae: 27.9565 - mse: 1258.6476\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9565 - mae: 27.9565 - mse: 1260.4708\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1047 - mae: 28.1047 - mse: 1274.8481\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7905 - mae: 27.7905 - mse: 1241.2758\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9459 - mae: 27.9459 - mse: 1259.5247\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9123 - mae: 27.9123 - mse: 1261.3601\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0446 - mae: 28.0446 - mse: 1267.4263\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0818 - mae: 28.0818 - mse: 1269.1677\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0872 - mae: 28.0872 - mse: 1264.8364\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7799 - mae: 27.7799 - mse: 1246.3641\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9675 - mae: 27.9675 - mse: 1252.1439\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9304 - mae: 27.9304 - mse: 1266.7242\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9827 - mae: 27.9827 - mse: 1259.9266\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7880 - mae: 27.7880 - mse: 1240.4143\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9623 - mae: 27.9623 - mse: 1258.8815\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0288 - mae: 28.0288 - mse: 1263.2805\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9113 - mae: 27.9113 - mse: 1263.0902\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1314 - mae: 28.1314 - mse: 1274.1445\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9740 - mae: 27.9740 - mse: 1255.4907\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8648 - mae: 27.8648 - mse: 1254.4320\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0255 - mae: 28.0255 - mse: 1264.7604\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9850 - mae: 27.9850 - mse: 1259.2350\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7092 - mae: 27.7092 - mse: 1245.4905\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6982 - mae: 27.6982 - mse: 1236.2632\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5218 - mae: 27.5218 - mse: 1238.1729\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9848 - mae: 27.9848 - mse: 1263.1166\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4380 - mae: 27.4380 - mse: 1224.6233\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6645 - mae: 27.6645 - mse: 1243.6117\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8701 - mae: 27.8701 - mse: 1260.9221\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0386 - mae: 28.0386 - mse: 1271.6978\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9960 - mae: 27.9960 - mse: 1269.8857\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7849 - mae: 27.7849 - mse: 1248.1711\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8531 - mae: 27.8531 - mse: 1251.9672\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2727 - mae: 28.2727 - mse: 1278.4440\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8633 - mae: 27.8633 - mse: 1253.1119\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8097 - mae: 27.8097 - mse: 1248.8083\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7401 - mae: 27.7401 - mse: 1242.6719\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7788 - mae: 27.7788 - mse: 1253.5354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3bb1a3850>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_C = {}\n",
        "performance_C['(0.01, 1000, 200)'] = loss"
      ],
      "metadata": {
        "id": "IRIWD8l9IEYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eafad47d-3f12-4912-831a-d798dd6453fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.8206 - mae: 28.8206 - mse: 1294.2103\n",
            "Loss: [28.880550384521484, 28.880550384521484, 1300.154541015625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) (learning_rates, batch_size, epochs) = (0.001, 1000, 400)"
      ],
      "metadata": {
        "id": "Whf8TzxBJerM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=400, verbose=1)"
      ],
      "metadata": {
        "id": "piLWk7kPIFFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e55899b-34fb-4032-9e60-6ed08d675b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 65.8838 - mae: 65.8838 - mse: 6967.3667\n",
            "Epoch 2/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 65.4157 - mae: 65.4157 - mse: 6870.7520\n",
            "Epoch 3/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 63.2945 - mae: 63.2945 - mse: 6445.7310\n",
            "Epoch 4/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 59.8210 - mae: 59.8210 - mse: 5789.9233\n",
            "Epoch 5/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 54.4834 - mae: 54.4834 - mse: 4908.5508\n",
            "Epoch 6/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 52.0604 - mae: 52.0604 - mse: 4501.8638\n",
            "Epoch 7/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 50.2769 - mae: 50.2769 - mse: 4190.3413\n",
            "Epoch 8/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 47.7224 - mae: 47.7224 - mse: 3731.5364\n",
            "Epoch 9/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 47.1042 - mae: 47.1042 - mse: 3611.2805\n",
            "Epoch 10/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 45.2243 - mae: 45.2243 - mse: 3351.8523\n",
            "Epoch 11/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 44.8132 - mae: 44.8132 - mse: 3238.9470\n",
            "Epoch 12/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.7582 - mae: 43.7582 - mse: 3141.3862\n",
            "Epoch 13/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 43.4131 - mae: 43.4131 - mse: 3019.9729\n",
            "Epoch 14/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.7368 - mae: 42.7368 - mse: 2924.2798\n",
            "Epoch 15/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.7410 - mae: 41.7410 - mse: 2803.3330\n",
            "Epoch 16/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.0482 - mae: 40.0482 - mse: 2623.5610\n",
            "Epoch 17/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.9876 - mae: 37.9876 - mse: 2338.0342\n",
            "Epoch 18/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.6993 - mae: 36.6993 - mse: 2213.2495\n",
            "Epoch 19/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.9385 - mae: 34.9385 - mse: 1995.1964\n",
            "Epoch 20/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.8785 - mae: 32.8785 - mse: 1758.7412\n",
            "Epoch 21/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.3993 - mae: 32.3993 - mse: 1723.6511\n",
            "Epoch 22/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.9245 - mae: 31.9245 - mse: 1671.2195\n",
            "Epoch 23/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.7554 - mae: 31.7554 - mse: 1689.9087\n",
            "Epoch 24/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5022 - mae: 31.5022 - mse: 1670.0399\n",
            "Epoch 25/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.5458 - mae: 31.5458 - mse: 1654.1671\n",
            "Epoch 26/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.8565 - mae: 30.8565 - mse: 1597.8202\n",
            "Epoch 27/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.0316 - mae: 31.0316 - mse: 1605.9976\n",
            "Epoch 28/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.8718 - mae: 30.8718 - mse: 1574.0763\n",
            "Epoch 29/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.8085 - mae: 30.8085 - mse: 1560.3058\n",
            "Epoch 30/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.9300 - mae: 30.9300 - mse: 1584.6335\n",
            "Epoch 31/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.0522 - mae: 31.0522 - mse: 1601.2791\n",
            "Epoch 32/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7621 - mae: 30.7621 - mse: 1561.4032\n",
            "Epoch 33/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7514 - mae: 30.7514 - mse: 1580.8190\n",
            "Epoch 34/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.4578 - mae: 30.4578 - mse: 1529.6007\n",
            "Epoch 35/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.4977 - mae: 30.4977 - mse: 1550.7820\n",
            "Epoch 36/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.6074 - mae: 30.6074 - mse: 1572.8235\n",
            "Epoch 37/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.4195 - mae: 30.4195 - mse: 1537.4421\n",
            "Epoch 38/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.0755 - mae: 30.0755 - mse: 1486.4801\n",
            "Epoch 39/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7250 - mae: 29.7250 - mse: 1451.8552\n",
            "Epoch 40/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0608 - mae: 30.0608 - mse: 1488.8257\n",
            "Epoch 41/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9172 - mae: 29.9172 - mse: 1471.6610\n",
            "Epoch 42/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0084 - mae: 30.0084 - mse: 1475.1548\n",
            "Epoch 43/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7731 - mae: 29.7731 - mse: 1439.0286\n",
            "Epoch 44/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.8900 - mae: 29.8900 - mse: 1459.5438\n",
            "Epoch 45/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.8474 - mae: 29.8474 - mse: 1447.1840\n",
            "Epoch 46/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7659 - mae: 29.7659 - mse: 1452.1708\n",
            "Epoch 47/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6639 - mae: 29.6639 - mse: 1419.2135\n",
            "Epoch 48/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5366 - mae: 29.5366 - mse: 1406.9750\n",
            "Epoch 49/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3229 - mae: 29.3229 - mse: 1391.5015\n",
            "Epoch 50/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0787 - mae: 29.0787 - mse: 1382.5369\n",
            "Epoch 51/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0617 - mae: 29.0617 - mse: 1359.9346\n",
            "Epoch 52/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.4695 - mae: 29.4695 - mse: 1389.8993\n",
            "Epoch 53/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0976 - mae: 29.0976 - mse: 1395.4097\n",
            "Epoch 54/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2589 - mae: 29.2589 - mse: 1390.5728\n",
            "Epoch 55/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9508 - mae: 28.9508 - mse: 1360.2195\n",
            "Epoch 56/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2495 - mae: 29.2495 - mse: 1385.1700\n",
            "Epoch 57/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0436 - mae: 29.0436 - mse: 1351.9751\n",
            "Epoch 58/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2352 - mae: 29.2352 - mse: 1375.1626\n",
            "Epoch 59/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0078 - mae: 29.0078 - mse: 1357.1168\n",
            "Epoch 60/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.1354 - mae: 29.1354 - mse: 1364.5295\n",
            "Epoch 61/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9197 - mae: 28.9197 - mse: 1348.3237\n",
            "Epoch 62/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0306 - mae: 29.0306 - mse: 1362.1893\n",
            "Epoch 63/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2361 - mae: 29.2361 - mse: 1374.8606\n",
            "Epoch 64/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.1300 - mae: 29.1300 - mse: 1358.8759\n",
            "Epoch 65/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7644 - mae: 28.7644 - mse: 1343.0171\n",
            "Epoch 66/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9296 - mae: 28.9296 - mse: 1347.2101\n",
            "Epoch 67/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9995 - mae: 28.9995 - mse: 1351.0618\n",
            "Epoch 68/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6869 - mae: 28.6869 - mse: 1324.6810\n",
            "Epoch 69/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8432 - mae: 28.8432 - mse: 1360.4045\n",
            "Epoch 70/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0697 - mae: 29.0697 - mse: 1377.2966\n",
            "Epoch 71/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9805 - mae: 28.9805 - mse: 1363.4636\n",
            "Epoch 72/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9159 - mae: 28.9159 - mse: 1339.5042\n",
            "Epoch 73/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8685 - mae: 28.8685 - mse: 1338.4530\n",
            "Epoch 74/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8499 - mae: 28.8499 - mse: 1358.0021\n",
            "Epoch 75/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6350 - mae: 28.6350 - mse: 1321.2460\n",
            "Epoch 76/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8554 - mae: 28.8554 - mse: 1350.3075\n",
            "Epoch 77/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5349 - mae: 28.5349 - mse: 1312.4294\n",
            "Epoch 78/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6122 - mae: 28.6122 - mse: 1317.2428\n",
            "Epoch 79/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8522 - mae: 28.8522 - mse: 1335.9370\n",
            "Epoch 80/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8930 - mae: 28.8930 - mse: 1352.0760\n",
            "Epoch 81/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0258 - mae: 29.0258 - mse: 1360.1123\n",
            "Epoch 82/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5227 - mae: 28.5227 - mse: 1312.6147\n",
            "Epoch 83/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9591 - mae: 28.9591 - mse: 1328.1138\n",
            "Epoch 84/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.7984 - mae: 28.7984 - mse: 1330.4894\n",
            "Epoch 85/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0518 - mae: 29.0518 - mse: 1353.5159\n",
            "Epoch 86/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5762 - mae: 28.5762 - mse: 1319.3575\n",
            "Epoch 87/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.8083 - mae: 28.8083 - mse: 1326.7048\n",
            "Epoch 88/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.7671 - mae: 28.7671 - mse: 1327.6069\n",
            "Epoch 89/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.6301 - mae: 28.6301 - mse: 1336.3373\n",
            "Epoch 90/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5354 - mae: 28.5354 - mse: 1303.2589\n",
            "Epoch 91/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.8071 - mae: 28.8071 - mse: 1344.7784\n",
            "Epoch 92/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.7704 - mae: 28.7704 - mse: 1345.8168\n",
            "Epoch 93/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.5183 - mae: 28.5183 - mse: 1314.2985\n",
            "Epoch 94/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.6498 - mae: 28.6498 - mse: 1321.9998\n",
            "Epoch 95/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.6803 - mae: 28.6803 - mse: 1329.6482\n",
            "Epoch 96/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5639 - mae: 28.5639 - mse: 1306.1305\n",
            "Epoch 97/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7732 - mae: 28.7732 - mse: 1327.0773\n",
            "Epoch 98/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8265 - mae: 28.8265 - mse: 1329.9054\n",
            "Epoch 99/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6990 - mae: 28.6990 - mse: 1334.2834\n",
            "Epoch 100/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5475 - mae: 28.5475 - mse: 1307.2968\n",
            "Epoch 101/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5809 - mae: 28.5809 - mse: 1319.0522\n",
            "Epoch 102/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7114 - mae: 28.7114 - mse: 1329.3071\n",
            "Epoch 103/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5465 - mae: 28.5465 - mse: 1306.8740\n",
            "Epoch 104/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7899 - mae: 28.7899 - mse: 1331.2322\n",
            "Epoch 105/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3880 - mae: 28.3880 - mse: 1287.2921\n",
            "Epoch 106/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5487 - mae: 28.5487 - mse: 1321.9789\n",
            "Epoch 107/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5860 - mae: 28.5860 - mse: 1328.5883\n",
            "Epoch 108/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4249 - mae: 28.4249 - mse: 1304.9490\n",
            "Epoch 109/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5633 - mae: 28.5633 - mse: 1308.1240\n",
            "Epoch 110/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7869 - mae: 28.7869 - mse: 1325.4178\n",
            "Epoch 111/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5679 - mae: 28.5679 - mse: 1312.2815\n",
            "Epoch 112/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8046 - mae: 28.8046 - mse: 1344.4231\n",
            "Epoch 113/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6058 - mae: 28.6058 - mse: 1310.6904\n",
            "Epoch 114/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7605 - mae: 28.7605 - mse: 1329.8630\n",
            "Epoch 115/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4661 - mae: 28.4661 - mse: 1293.1429\n",
            "Epoch 116/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5408 - mae: 28.5408 - mse: 1303.5413\n",
            "Epoch 117/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4782 - mae: 28.4782 - mse: 1307.9028\n",
            "Epoch 118/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6933 - mae: 28.6933 - mse: 1334.4905\n",
            "Epoch 119/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2786 - mae: 28.2786 - mse: 1280.6478\n",
            "Epoch 120/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6571 - mae: 28.6571 - mse: 1315.7206\n",
            "Epoch 121/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5606 - mae: 28.5606 - mse: 1304.9913\n",
            "Epoch 122/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5239 - mae: 28.5239 - mse: 1307.8568\n",
            "Epoch 123/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5154 - mae: 28.5154 - mse: 1321.8715\n",
            "Epoch 124/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4780 - mae: 28.4780 - mse: 1305.4148\n",
            "Epoch 125/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5832 - mae: 28.5832 - mse: 1307.5648\n",
            "Epoch 126/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6875 - mae: 28.6875 - mse: 1314.3862\n",
            "Epoch 127/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5866 - mae: 28.5866 - mse: 1312.3217\n",
            "Epoch 128/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6166 - mae: 28.6166 - mse: 1312.5654\n",
            "Epoch 129/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5793 - mae: 28.5793 - mse: 1313.9814\n",
            "Epoch 130/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6324 - mae: 28.6324 - mse: 1309.7075\n",
            "Epoch 131/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6667 - mae: 28.6667 - mse: 1314.9027\n",
            "Epoch 132/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4178 - mae: 28.4178 - mse: 1298.2983\n",
            "Epoch 133/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5649 - mae: 28.5649 - mse: 1320.5712\n",
            "Epoch 134/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5610 - mae: 28.5610 - mse: 1305.7373\n",
            "Epoch 135/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5211 - mae: 28.5211 - mse: 1313.6565\n",
            "Epoch 136/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3750 - mae: 28.3750 - mse: 1284.4685\n",
            "Epoch 137/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2487 - mae: 28.2487 - mse: 1279.3518\n",
            "Epoch 138/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6236 - mae: 28.6236 - mse: 1311.0107\n",
            "Epoch 139/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2398 - mae: 28.2398 - mse: 1281.7073\n",
            "Epoch 140/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4831 - mae: 28.4831 - mse: 1299.4724\n",
            "Epoch 141/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3621 - mae: 28.3621 - mse: 1292.1891\n",
            "Epoch 142/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4145 - mae: 28.4145 - mse: 1290.6071\n",
            "Epoch 143/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4452 - mae: 28.4452 - mse: 1293.2106\n",
            "Epoch 144/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3611 - mae: 28.3611 - mse: 1292.5255\n",
            "Epoch 145/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6524 - mae: 28.6524 - mse: 1318.2415\n",
            "Epoch 146/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7564 - mae: 28.7564 - mse: 1326.7288\n",
            "Epoch 147/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5427 - mae: 28.5427 - mse: 1301.3337\n",
            "Epoch 148/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5131 - mae: 28.5131 - mse: 1310.7635\n",
            "Epoch 149/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5414 - mae: 28.5414 - mse: 1311.3091\n",
            "Epoch 150/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5125 - mae: 28.5125 - mse: 1304.3790\n",
            "Epoch 151/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1956 - mae: 28.1956 - mse: 1278.8613\n",
            "Epoch 152/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5393 - mae: 28.5393 - mse: 1309.3879\n",
            "Epoch 153/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3145 - mae: 28.3145 - mse: 1297.0507\n",
            "Epoch 154/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6500 - mae: 28.6500 - mse: 1313.7456\n",
            "Epoch 155/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5445 - mae: 28.5445 - mse: 1309.1296\n",
            "Epoch 156/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1817 - mae: 28.1817 - mse: 1290.4380\n",
            "Epoch 157/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3569 - mae: 28.3569 - mse: 1290.5168\n",
            "Epoch 158/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3571 - mae: 28.3571 - mse: 1301.3052\n",
            "Epoch 159/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2500 - mae: 28.2500 - mse: 1281.7603\n",
            "Epoch 160/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3071 - mae: 28.3071 - mse: 1294.6903\n",
            "Epoch 161/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3900 - mae: 28.3900 - mse: 1304.2297\n",
            "Epoch 162/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4233 - mae: 28.4233 - mse: 1290.2483\n",
            "Epoch 163/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6194 - mae: 28.6194 - mse: 1312.6169\n",
            "Epoch 164/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3958 - mae: 28.3958 - mse: 1290.7722\n",
            "Epoch 165/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5715 - mae: 28.5715 - mse: 1324.9941\n",
            "Epoch 166/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3031 - mae: 28.3031 - mse: 1275.6093\n",
            "Epoch 167/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5039 - mae: 28.5039 - mse: 1313.8201\n",
            "Epoch 168/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4066 - mae: 28.4066 - mse: 1297.0469\n",
            "Epoch 169/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5443 - mae: 28.5443 - mse: 1309.0632\n",
            "Epoch 170/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.5316 - mae: 28.5316 - mse: 1306.5405\n",
            "Epoch 171/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3273 - mae: 28.3273 - mse: 1295.9104\n",
            "Epoch 172/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5873 - mae: 28.5873 - mse: 1324.9160\n",
            "Epoch 173/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4610 - mae: 28.4610 - mse: 1295.6763\n",
            "Epoch 174/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.6843 - mae: 28.6843 - mse: 1338.8041\n",
            "Epoch 175/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5036 - mae: 28.5036 - mse: 1306.6696\n",
            "Epoch 176/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1987 - mae: 28.1987 - mse: 1275.9409\n",
            "Epoch 177/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1856 - mae: 28.1856 - mse: 1276.3363\n",
            "Epoch 178/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1545 - mae: 28.1545 - mse: 1272.3259\n",
            "Epoch 179/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1623 - mae: 28.1623 - mse: 1277.9225\n",
            "Epoch 180/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.3901 - mae: 28.3901 - mse: 1288.6544\n",
            "Epoch 181/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.3665 - mae: 28.3665 - mse: 1297.1783\n",
            "Epoch 182/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1499 - mae: 28.1499 - mse: 1273.3794\n",
            "Epoch 183/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5571 - mae: 28.5571 - mse: 1306.2501\n",
            "Epoch 184/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4513 - mae: 28.4513 - mse: 1299.3534\n",
            "Epoch 185/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2288 - mae: 28.2288 - mse: 1285.9406\n",
            "Epoch 186/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4815 - mae: 28.4815 - mse: 1316.2411\n",
            "Epoch 187/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1505 - mae: 28.1505 - mse: 1275.1403\n",
            "Epoch 188/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2393 - mae: 28.2393 - mse: 1286.8516\n",
            "Epoch 189/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4350 - mae: 28.4350 - mse: 1308.1693\n",
            "Epoch 190/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2775 - mae: 28.2775 - mse: 1295.0049\n",
            "Epoch 191/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4006 - mae: 28.4006 - mse: 1303.6575\n",
            "Epoch 192/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3315 - mae: 28.3315 - mse: 1281.0719\n",
            "Epoch 193/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3937 - mae: 28.3937 - mse: 1302.4120\n",
            "Epoch 194/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2435 - mae: 28.2435 - mse: 1285.3027\n",
            "Epoch 195/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2589 - mae: 28.2589 - mse: 1282.8524\n",
            "Epoch 196/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3176 - mae: 28.3176 - mse: 1297.1753\n",
            "Epoch 197/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4696 - mae: 28.4696 - mse: 1300.8464\n",
            "Epoch 198/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2956 - mae: 28.2956 - mse: 1283.8738\n",
            "Epoch 199/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3047 - mae: 28.3047 - mse: 1285.7449\n",
            "Epoch 200/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2563 - mae: 28.2563 - mse: 1273.4703\n",
            "Epoch 201/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4572 - mae: 28.4572 - mse: 1293.7562\n",
            "Epoch 202/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4289 - mae: 28.4289 - mse: 1303.4109\n",
            "Epoch 203/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5006 - mae: 28.5006 - mse: 1303.2626\n",
            "Epoch 204/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4175 - mae: 28.4175 - mse: 1307.2273\n",
            "Epoch 205/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2311 - mae: 28.2311 - mse: 1285.9358\n",
            "Epoch 206/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4845 - mae: 28.4845 - mse: 1323.4335\n",
            "Epoch 207/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3778 - mae: 28.3778 - mse: 1293.1995\n",
            "Epoch 208/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4859 - mae: 28.4859 - mse: 1301.8834\n",
            "Epoch 209/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4495 - mae: 28.4495 - mse: 1296.7074\n",
            "Epoch 210/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3477 - mae: 28.3477 - mse: 1280.1913\n",
            "Epoch 211/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4568 - mae: 28.4568 - mse: 1303.7866\n",
            "Epoch 212/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0715 - mae: 28.0715 - mse: 1273.0479\n",
            "Epoch 213/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1906 - mae: 28.1906 - mse: 1270.1139\n",
            "Epoch 214/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2985 - mae: 28.2985 - mse: 1286.4440\n",
            "Epoch 215/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2791 - mae: 28.2791 - mse: 1281.7483\n",
            "Epoch 216/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3304 - mae: 28.3304 - mse: 1296.9807\n",
            "Epoch 217/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3413 - mae: 28.3413 - mse: 1294.7299\n",
            "Epoch 218/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4123 - mae: 28.4123 - mse: 1288.3257\n",
            "Epoch 219/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3461 - mae: 28.3461 - mse: 1293.9398\n",
            "Epoch 220/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2644 - mae: 28.2644 - mse: 1295.2308\n",
            "Epoch 221/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3343 - mae: 28.3343 - mse: 1289.3671\n",
            "Epoch 222/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2105 - mae: 28.2105 - mse: 1273.7946\n",
            "Epoch 223/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5444 - mae: 28.5444 - mse: 1314.8301\n",
            "Epoch 224/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3155 - mae: 28.3155 - mse: 1290.4785\n",
            "Epoch 225/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2061 - mae: 28.2061 - mse: 1282.1880\n",
            "Epoch 226/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1390 - mae: 28.1390 - mse: 1268.0193\n",
            "Epoch 227/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5560 - mae: 28.5560 - mse: 1312.0736\n",
            "Epoch 228/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1958 - mae: 28.1958 - mse: 1290.6040\n",
            "Epoch 229/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4337 - mae: 28.4337 - mse: 1304.9958\n",
            "Epoch 230/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3766 - mae: 28.3766 - mse: 1305.8816\n",
            "Epoch 231/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2711 - mae: 28.2711 - mse: 1282.0156\n",
            "Epoch 232/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2792 - mae: 28.2792 - mse: 1280.6493\n",
            "Epoch 233/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6153 - mae: 28.6153 - mse: 1316.8633\n",
            "Epoch 234/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4278 - mae: 28.4278 - mse: 1302.9175\n",
            "Epoch 235/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4215 - mae: 28.4215 - mse: 1299.8884\n",
            "Epoch 236/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1129 - mae: 28.1129 - mse: 1265.0706\n",
            "Epoch 237/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2157 - mae: 28.2157 - mse: 1269.2976\n",
            "Epoch 238/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4233 - mae: 28.4233 - mse: 1298.3246\n",
            "Epoch 239/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4248 - mae: 28.4248 - mse: 1298.4457\n",
            "Epoch 240/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4236 - mae: 28.4236 - mse: 1299.1693\n",
            "Epoch 241/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1794 - mae: 28.1794 - mse: 1282.5854\n",
            "Epoch 242/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3446 - mae: 28.3446 - mse: 1304.8617\n",
            "Epoch 243/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2277 - mae: 28.2277 - mse: 1285.2535\n",
            "Epoch 244/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1528 - mae: 28.1528 - mse: 1276.4999\n",
            "Epoch 245/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3007 - mae: 28.3007 - mse: 1295.6277\n",
            "Epoch 246/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0764 - mae: 28.0764 - mse: 1266.1808\n",
            "Epoch 247/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1265 - mae: 28.1265 - mse: 1274.2847\n",
            "Epoch 248/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4123 - mae: 28.4123 - mse: 1296.0420\n",
            "Epoch 249/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2405 - mae: 28.2405 - mse: 1271.7084\n",
            "Epoch 250/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3595 - mae: 28.3595 - mse: 1286.5458\n",
            "Epoch 251/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1318 - mae: 28.1318 - mse: 1271.2930\n",
            "Epoch 252/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3282 - mae: 28.3282 - mse: 1288.1514\n",
            "Epoch 253/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2962 - mae: 28.2962 - mse: 1286.8912\n",
            "Epoch 254/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2144 - mae: 28.2144 - mse: 1284.5137\n",
            "Epoch 255/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.2707 - mae: 28.2707 - mse: 1288.7878\n",
            "Epoch 256/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.3403 - mae: 28.3403 - mse: 1295.7085\n",
            "Epoch 257/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1693 - mae: 28.1693 - mse: 1273.1259\n",
            "Epoch 258/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2934 - mae: 28.2934 - mse: 1287.7854\n",
            "Epoch 259/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4467 - mae: 28.4467 - mse: 1301.6238\n",
            "Epoch 260/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5570 - mae: 28.5570 - mse: 1312.5101\n",
            "Epoch 261/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9922 - mae: 27.9922 - mse: 1264.2783\n",
            "Epoch 262/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2384 - mae: 28.2384 - mse: 1279.4551\n",
            "Epoch 263/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1432 - mae: 28.1432 - mse: 1267.8767\n",
            "Epoch 264/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2196 - mae: 28.2196 - mse: 1271.8893\n",
            "Epoch 265/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3451 - mae: 28.3451 - mse: 1297.3000\n",
            "Epoch 266/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3858 - mae: 28.3858 - mse: 1298.3596\n",
            "Epoch 267/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1748 - mae: 28.1748 - mse: 1277.3197\n",
            "Epoch 268/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3460 - mae: 28.3460 - mse: 1291.4049\n",
            "Epoch 269/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2086 - mae: 28.2086 - mse: 1270.7113\n",
            "Epoch 270/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1342 - mae: 28.1342 - mse: 1275.8751\n",
            "Epoch 271/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0071 - mae: 28.0071 - mse: 1259.9738\n",
            "Epoch 272/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1510 - mae: 28.1510 - mse: 1274.1675\n",
            "Epoch 273/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2892 - mae: 28.2892 - mse: 1289.0012\n",
            "Epoch 274/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2562 - mae: 28.2562 - mse: 1284.1801\n",
            "Epoch 275/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2904 - mae: 28.2904 - mse: 1278.2805\n",
            "Epoch 276/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1458 - mae: 28.1458 - mse: 1281.5323\n",
            "Epoch 277/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3298 - mae: 28.3298 - mse: 1290.9270\n",
            "Epoch 278/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2807 - mae: 28.2807 - mse: 1280.3522\n",
            "Epoch 279/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1544 - mae: 28.1544 - mse: 1267.3596\n",
            "Epoch 280/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4039 - mae: 28.4039 - mse: 1294.4260\n",
            "Epoch 281/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1639 - mae: 28.1639 - mse: 1276.2502\n",
            "Epoch 282/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2209 - mae: 28.2209 - mse: 1275.4143\n",
            "Epoch 283/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2723 - mae: 28.2723 - mse: 1281.7489\n",
            "Epoch 284/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0350 - mae: 28.0350 - mse: 1260.4365\n",
            "Epoch 285/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4706 - mae: 28.4706 - mse: 1300.0757\n",
            "Epoch 286/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2569 - mae: 28.2569 - mse: 1283.3341\n",
            "Epoch 287/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3144 - mae: 28.3144 - mse: 1293.1810\n",
            "Epoch 288/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0556 - mae: 28.0556 - mse: 1270.6639\n",
            "Epoch 289/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0733 - mae: 28.0733 - mse: 1267.2749\n",
            "Epoch 290/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3475 - mae: 28.3475 - mse: 1301.3145\n",
            "Epoch 291/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2045 - mae: 28.2045 - mse: 1271.5872\n",
            "Epoch 292/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4394 - mae: 28.4394 - mse: 1293.8212\n",
            "Epoch 293/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2624 - mae: 28.2624 - mse: 1287.7628\n",
            "Epoch 294/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3049 - mae: 28.3049 - mse: 1289.4857\n",
            "Epoch 295/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3853 - mae: 28.3853 - mse: 1298.6318\n",
            "Epoch 296/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2296 - mae: 28.2296 - mse: 1284.6284\n",
            "Epoch 297/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2344 - mae: 28.2344 - mse: 1285.3212\n",
            "Epoch 298/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2675 - mae: 28.2675 - mse: 1279.2698\n",
            "Epoch 299/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1974 - mae: 28.1974 - mse: 1295.6755\n",
            "Epoch 300/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1044 - mae: 28.1044 - mse: 1273.0143\n",
            "Epoch 301/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2393 - mae: 28.2393 - mse: 1282.4945\n",
            "Epoch 302/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2256 - mae: 28.2256 - mse: 1285.4261\n",
            "Epoch 303/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2318 - mae: 28.2318 - mse: 1277.8340\n",
            "Epoch 304/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2701 - mae: 28.2701 - mse: 1283.1866\n",
            "Epoch 305/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0873 - mae: 28.0873 - mse: 1267.6698\n",
            "Epoch 306/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3098 - mae: 28.3098 - mse: 1287.6991\n",
            "Epoch 307/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1804 - mae: 28.1804 - mse: 1275.4581\n",
            "Epoch 308/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0291 - mae: 28.0291 - mse: 1257.9806\n",
            "Epoch 309/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2591 - mae: 28.2591 - mse: 1289.8879\n",
            "Epoch 310/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9603 - mae: 27.9603 - mse: 1261.2344\n",
            "Epoch 311/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1920 - mae: 28.1920 - mse: 1279.9017\n",
            "Epoch 312/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1234 - mae: 28.1234 - mse: 1276.4777\n",
            "Epoch 313/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1272 - mae: 28.1272 - mse: 1271.2874\n",
            "Epoch 314/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0541 - mae: 28.0541 - mse: 1274.8678\n",
            "Epoch 315/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1284 - mae: 28.1284 - mse: 1260.4333\n",
            "Epoch 316/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0586 - mae: 28.0586 - mse: 1272.2791\n",
            "Epoch 317/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9757 - mae: 27.9757 - mse: 1261.4625\n",
            "Epoch 318/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2443 - mae: 28.2443 - mse: 1282.3691\n",
            "Epoch 319/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2261 - mae: 28.2261 - mse: 1282.5438\n",
            "Epoch 320/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2148 - mae: 28.2148 - mse: 1281.6234\n",
            "Epoch 321/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1330 - mae: 28.1330 - mse: 1273.6611\n",
            "Epoch 322/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.0434 - mae: 28.0434 - mse: 1271.3136\n",
            "Epoch 323/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.2263 - mae: 28.2263 - mse: 1285.7742\n",
            "Epoch 324/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2432 - mae: 28.2432 - mse: 1289.9349\n",
            "Epoch 325/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 28.4477 - mae: 28.4477 - mse: 1293.3702\n",
            "Epoch 326/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2749 - mae: 28.2749 - mse: 1296.1411\n",
            "Epoch 327/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2048 - mae: 28.2048 - mse: 1285.9630\n",
            "Epoch 328/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27.9579 - mae: 27.9579 - mse: 1255.9203\n",
            "Epoch 329/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1071 - mae: 28.1071 - mse: 1271.3909\n",
            "Epoch 330/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.0478 - mae: 28.0478 - mse: 1261.7620\n",
            "Epoch 331/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.0818 - mae: 28.0818 - mse: 1265.7382\n",
            "Epoch 332/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.3947 - mae: 28.3947 - mse: 1285.4272\n",
            "Epoch 333/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3415 - mae: 28.3415 - mse: 1298.2286\n",
            "Epoch 334/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1383 - mae: 28.1383 - mse: 1262.9242\n",
            "Epoch 335/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2705 - mae: 28.2705 - mse: 1293.7262\n",
            "Epoch 336/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9809 - mae: 27.9809 - mse: 1264.7369\n",
            "Epoch 337/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3471 - mae: 28.3471 - mse: 1292.4999\n",
            "Epoch 338/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2039 - mae: 28.2039 - mse: 1275.8494\n",
            "Epoch 339/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0517 - mae: 28.0517 - mse: 1275.5673\n",
            "Epoch 340/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2097 - mae: 28.2097 - mse: 1286.3060\n",
            "Epoch 341/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1553 - mae: 28.1553 - mse: 1278.2295\n",
            "Epoch 342/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2810 - mae: 28.2810 - mse: 1288.4397\n",
            "Epoch 343/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9513 - mae: 27.9513 - mse: 1261.3024\n",
            "Epoch 344/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0490 - mae: 28.0490 - mse: 1280.4027\n",
            "Epoch 345/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2186 - mae: 28.2186 - mse: 1288.7156\n",
            "Epoch 346/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2203 - mae: 28.2203 - mse: 1286.1608\n",
            "Epoch 347/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0854 - mae: 28.0854 - mse: 1275.2548\n",
            "Epoch 348/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1403 - mae: 28.1403 - mse: 1279.5797\n",
            "Epoch 349/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7842 - mae: 27.7842 - mse: 1239.2822\n",
            "Epoch 350/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1335 - mae: 28.1335 - mse: 1283.9863\n",
            "Epoch 351/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1985 - mae: 28.1985 - mse: 1280.4745\n",
            "Epoch 352/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0679 - mae: 28.0679 - mse: 1260.9695\n",
            "Epoch 353/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9367 - mae: 27.9367 - mse: 1259.9882\n",
            "Epoch 354/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2336 - mae: 28.2336 - mse: 1293.7245\n",
            "Epoch 355/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9819 - mae: 27.9819 - mse: 1268.4100\n",
            "Epoch 356/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9900 - mae: 27.9900 - mse: 1263.6995\n",
            "Epoch 357/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0870 - mae: 28.0870 - mse: 1278.1840\n",
            "Epoch 358/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1042 - mae: 28.1042 - mse: 1276.2484\n",
            "Epoch 359/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3393 - mae: 28.3393 - mse: 1289.8394\n",
            "Epoch 360/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1993 - mae: 28.1993 - mse: 1276.8025\n",
            "Epoch 361/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3413 - mae: 28.3413 - mse: 1293.8223\n",
            "Epoch 362/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1998 - mae: 28.1998 - mse: 1291.0759\n",
            "Epoch 363/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2631 - mae: 28.2631 - mse: 1291.7981\n",
            "Epoch 364/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8773 - mae: 27.8773 - mse: 1258.0631\n",
            "Epoch 365/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9574 - mae: 27.9574 - mse: 1267.3593\n",
            "Epoch 366/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0256 - mae: 28.0256 - mse: 1270.4500\n",
            "Epoch 367/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2152 - mae: 28.2152 - mse: 1292.3350\n",
            "Epoch 368/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9716 - mae: 27.9716 - mse: 1260.0327\n",
            "Epoch 369/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4008 - mae: 28.4008 - mse: 1296.6051\n",
            "Epoch 370/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1117 - mae: 28.1117 - mse: 1268.2935\n",
            "Epoch 371/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1917 - mae: 28.1917 - mse: 1276.6166\n",
            "Epoch 372/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2039 - mae: 28.2039 - mse: 1273.8705\n",
            "Epoch 373/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3069 - mae: 28.3069 - mse: 1291.6228\n",
            "Epoch 374/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1777 - mae: 28.1777 - mse: 1283.1450\n",
            "Epoch 375/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0834 - mae: 28.0834 - mse: 1269.4062\n",
            "Epoch 376/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0411 - mae: 28.0411 - mse: 1266.9922\n",
            "Epoch 377/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1485 - mae: 28.1485 - mse: 1279.6392\n",
            "Epoch 378/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2748 - mae: 28.2748 - mse: 1282.2876\n",
            "Epoch 379/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1691 - mae: 28.1691 - mse: 1286.5261\n",
            "Epoch 380/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1599 - mae: 28.1599 - mse: 1277.0978\n",
            "Epoch 381/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0888 - mae: 28.0888 - mse: 1266.8058\n",
            "Epoch 382/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2070 - mae: 28.2070 - mse: 1277.3887\n",
            "Epoch 383/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0455 - mae: 28.0455 - mse: 1264.5648\n",
            "Epoch 384/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1871 - mae: 28.1871 - mse: 1278.6613\n",
            "Epoch 385/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4012 - mae: 28.4012 - mse: 1292.0057\n",
            "Epoch 386/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9459 - mae: 27.9459 - mse: 1255.3154\n",
            "Epoch 387/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2070 - mae: 28.2070 - mse: 1281.9646\n",
            "Epoch 388/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1221 - mae: 28.1221 - mse: 1276.5879\n",
            "Epoch 389/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0399 - mae: 28.0399 - mse: 1259.5924\n",
            "Epoch 390/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2352 - mae: 28.2352 - mse: 1280.3124\n",
            "Epoch 391/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.9618 - mae: 27.9618 - mse: 1264.1688\n",
            "Epoch 392/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1672 - mae: 28.1672 - mse: 1287.8900\n",
            "Epoch 393/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.9842 - mae: 27.9842 - mse: 1261.3240\n",
            "Epoch 394/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.0154 - mae: 28.0154 - mse: 1267.8882\n",
            "Epoch 395/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0791 - mae: 28.0791 - mse: 1274.4507\n",
            "Epoch 396/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.1691 - mae: 28.1691 - mse: 1280.6654\n",
            "Epoch 397/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27.9769 - mae: 27.9769 - mse: 1266.7174\n",
            "Epoch 398/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3042 - mae: 28.3042 - mse: 1291.9379\n",
            "Epoch 399/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.9827 - mae: 27.9827 - mse: 1269.8820\n",
            "Epoch 400/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.9928 - mae: 27.9928 - mse: 1264.7122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3b9c82f50>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_C['(0.001, 1000, 400)'] = loss"
      ],
      "metadata": {
        "id": "1BiOH4j2IGGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e5d611-adb6-467f-eb58-44b127f23254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.4781 - mae: 28.4781 - mse: 1280.6718\n",
            "Loss: [28.607107162475586, 28.607107162475586, 1280.333984375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) (learning_rates, batch_size, epochs) = (0.01, 1000, 400)"
      ],
      "metadata": {
        "id": "Kx7UmsBwIGqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=400, verbose=1)"
      ],
      "metadata": {
        "id": "EbB-fEbrJt9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7e4b7a-494a-46f4-e2c1-69a42261bdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 63.5574 - mae: 63.5574 - mse: 6504.8867\n",
            "Epoch 2/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.5745 - mae: 50.5745 - mse: 4210.4399\n",
            "Epoch 3/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.5919 - mae: 45.5919 - mse: 3380.5046\n",
            "Epoch 4/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.0284 - mae: 43.0284 - mse: 3021.0872\n",
            "Epoch 5/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.2951 - mae: 39.2951 - mse: 2585.5027\n",
            "Epoch 6/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.3877 - mae: 35.3877 - mse: 2153.2561\n",
            "Epoch 7/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.5321 - mae: 32.5321 - mse: 1772.3903\n",
            "Epoch 8/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7442 - mae: 31.7442 - mse: 1683.2938\n",
            "Epoch 9/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4167 - mae: 31.4167 - mse: 1637.6635\n",
            "Epoch 10/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5348 - mae: 31.5348 - mse: 1630.4293\n",
            "Epoch 11/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6010 - mae: 30.6010 - mse: 1547.9092\n",
            "Epoch 12/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.9762 - mae: 30.9762 - mse: 1598.1313\n",
            "Epoch 13/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.1189 - mae: 31.1189 - mse: 1630.0461\n",
            "Epoch 14/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.7406 - mae: 30.7406 - mse: 1539.0923\n",
            "Epoch 15/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.6181 - mae: 30.6181 - mse: 1569.3199\n",
            "Epoch 16/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.1650 - mae: 30.1650 - mse: 1493.0103\n",
            "Epoch 17/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.0026 - mae: 30.0026 - mse: 1462.0485\n",
            "Epoch 18/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.8413 - mae: 29.8413 - mse: 1452.4193\n",
            "Epoch 19/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3890 - mae: 29.3890 - mse: 1381.9923\n",
            "Epoch 20/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1100 - mae: 29.1100 - mse: 1361.7627\n",
            "Epoch 21/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.4339 - mae: 29.4339 - mse: 1392.2638\n",
            "Epoch 22/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.3202 - mae: 29.3202 - mse: 1376.7842\n",
            "Epoch 23/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8918 - mae: 28.8918 - mse: 1333.1536\n",
            "Epoch 24/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7926 - mae: 28.7926 - mse: 1320.8685\n",
            "Epoch 25/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6599 - mae: 28.6599 - mse: 1317.4418\n",
            "Epoch 26/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8064 - mae: 28.8064 - mse: 1345.1149\n",
            "Epoch 27/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9844 - mae: 28.9844 - mse: 1346.2008\n",
            "Epoch 28/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6748 - mae: 28.6748 - mse: 1312.6327\n",
            "Epoch 29/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9249 - mae: 28.9249 - mse: 1332.6527\n",
            "Epoch 30/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8066 - mae: 28.8066 - mse: 1318.7722\n",
            "Epoch 31/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5400 - mae: 28.5400 - mse: 1311.9237\n",
            "Epoch 32/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7201 - mae: 28.7201 - mse: 1329.5350\n",
            "Epoch 33/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6544 - mae: 28.6544 - mse: 1319.8608\n",
            "Epoch 34/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5972 - mae: 28.5972 - mse: 1309.7738\n",
            "Epoch 35/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6582 - mae: 28.6582 - mse: 1311.0577\n",
            "Epoch 36/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6722 - mae: 28.6722 - mse: 1326.2825\n",
            "Epoch 37/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5906 - mae: 28.5906 - mse: 1298.2649\n",
            "Epoch 38/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5362 - mae: 28.5362 - mse: 1301.1959\n",
            "Epoch 39/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3801 - mae: 28.3801 - mse: 1290.1906\n",
            "Epoch 40/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5458 - mae: 28.5458 - mse: 1299.6407\n",
            "Epoch 41/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5826 - mae: 28.5826 - mse: 1308.3921\n",
            "Epoch 42/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5639 - mae: 28.5639 - mse: 1300.2631\n",
            "Epoch 43/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7096 - mae: 28.7096 - mse: 1311.4744\n",
            "Epoch 44/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4974 - mae: 28.4974 - mse: 1290.8540\n",
            "Epoch 45/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3008 - mae: 28.3008 - mse: 1280.8440\n",
            "Epoch 46/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3384 - mae: 28.3384 - mse: 1286.7966\n",
            "Epoch 47/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6123 - mae: 28.6123 - mse: 1301.7999\n",
            "Epoch 48/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4431 - mae: 28.4431 - mse: 1283.1477\n",
            "Epoch 49/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4382 - mae: 28.4382 - mse: 1286.8247\n",
            "Epoch 50/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4591 - mae: 28.4591 - mse: 1294.0715\n",
            "Epoch 51/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3943 - mae: 28.3943 - mse: 1285.7743\n",
            "Epoch 52/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2288 - mae: 28.2288 - mse: 1273.6533\n",
            "Epoch 53/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2833 - mae: 28.2833 - mse: 1279.1971\n",
            "Epoch 54/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4107 - mae: 28.4107 - mse: 1284.5161\n",
            "Epoch 55/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6082 - mae: 28.6082 - mse: 1300.6945\n",
            "Epoch 56/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4730 - mae: 28.4730 - mse: 1294.8752\n",
            "Epoch 57/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3409 - mae: 28.3409 - mse: 1279.5278\n",
            "Epoch 58/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4497 - mae: 28.4497 - mse: 1288.9070\n",
            "Epoch 59/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.0614 - mae: 28.0614 - mse: 1257.2056\n",
            "Epoch 60/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4089 - mae: 28.4089 - mse: 1289.7030\n",
            "Epoch 61/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.2541 - mae: 28.2541 - mse: 1269.1136\n",
            "Epoch 62/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.4495 - mae: 28.4495 - mse: 1286.1906\n",
            "Epoch 63/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.5943 - mae: 28.5943 - mse: 1309.9875\n",
            "Epoch 64/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3044 - mae: 28.3044 - mse: 1291.1786\n",
            "Epoch 65/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6484 - mae: 28.6484 - mse: 1302.0410\n",
            "Epoch 66/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2983 - mae: 28.2983 - mse: 1280.6085\n",
            "Epoch 67/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3082 - mae: 28.3082 - mse: 1278.5787\n",
            "Epoch 68/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7065 - mae: 28.7065 - mse: 1321.3042\n",
            "Epoch 69/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2269 - mae: 28.2269 - mse: 1273.5068\n",
            "Epoch 70/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4541 - mae: 28.4541 - mse: 1297.2968\n",
            "Epoch 71/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2239 - mae: 28.2239 - mse: 1268.4640\n",
            "Epoch 72/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5467 - mae: 28.5467 - mse: 1292.7842\n",
            "Epoch 73/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3527 - mae: 28.3527 - mse: 1284.4893\n",
            "Epoch 74/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3604 - mae: 28.3604 - mse: 1285.6084\n",
            "Epoch 75/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0106 - mae: 28.0106 - mse: 1255.7191\n",
            "Epoch 76/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6548 - mae: 28.6548 - mse: 1302.2902\n",
            "Epoch 77/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4036 - mae: 28.4036 - mse: 1291.6816\n",
            "Epoch 78/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1930 - mae: 28.1930 - mse: 1269.2241\n",
            "Epoch 79/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1385 - mae: 28.1385 - mse: 1262.4816\n",
            "Epoch 80/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1801 - mae: 28.1801 - mse: 1266.5057\n",
            "Epoch 81/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2015 - mae: 28.2015 - mse: 1270.8312\n",
            "Epoch 82/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0221 - mae: 28.0221 - mse: 1259.9739\n",
            "Epoch 83/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4232 - mae: 28.4232 - mse: 1285.9106\n",
            "Epoch 84/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3055 - mae: 28.3055 - mse: 1271.2429\n",
            "Epoch 85/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2522 - mae: 28.2522 - mse: 1270.6039\n",
            "Epoch 86/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1980 - mae: 28.1980 - mse: 1269.5099\n",
            "Epoch 87/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4307 - mae: 28.4307 - mse: 1286.7240\n",
            "Epoch 88/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3188 - mae: 28.3188 - mse: 1282.1809\n",
            "Epoch 89/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3399 - mae: 28.3399 - mse: 1282.5726\n",
            "Epoch 90/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3157 - mae: 28.3157 - mse: 1286.5214\n",
            "Epoch 91/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0627 - mae: 28.0627 - mse: 1268.0043\n",
            "Epoch 92/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1526 - mae: 28.1526 - mse: 1260.9677\n",
            "Epoch 93/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0221 - mae: 28.0221 - mse: 1256.9049\n",
            "Epoch 94/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1492 - mae: 28.1492 - mse: 1267.2161\n",
            "Epoch 95/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2545 - mae: 28.2545 - mse: 1271.5836\n",
            "Epoch 96/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3163 - mae: 28.3163 - mse: 1281.4396\n",
            "Epoch 97/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1424 - mae: 28.1424 - mse: 1267.7498\n",
            "Epoch 98/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2847 - mae: 28.2847 - mse: 1276.8840\n",
            "Epoch 99/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3034 - mae: 28.3034 - mse: 1279.3628\n",
            "Epoch 100/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1709 - mae: 28.1709 - mse: 1270.6533\n",
            "Epoch 101/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8372 - mae: 27.8372 - mse: 1243.8347\n",
            "Epoch 102/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1700 - mae: 28.1700 - mse: 1272.6842\n",
            "Epoch 103/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1167 - mae: 28.1167 - mse: 1258.2229\n",
            "Epoch 104/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0660 - mae: 28.0660 - mse: 1253.9507\n",
            "Epoch 105/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1993 - mae: 28.1993 - mse: 1268.4871\n",
            "Epoch 106/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4222 - mae: 28.4222 - mse: 1296.1304\n",
            "Epoch 107/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2901 - mae: 28.2901 - mse: 1274.4076\n",
            "Epoch 108/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8884 - mae: 27.8884 - mse: 1242.2488\n",
            "Epoch 109/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2915 - mae: 28.2915 - mse: 1275.2922\n",
            "Epoch 110/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0725 - mae: 28.0725 - mse: 1264.5154\n",
            "Epoch 111/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2375 - mae: 28.2375 - mse: 1274.1720\n",
            "Epoch 112/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1777 - mae: 28.1777 - mse: 1267.0784\n",
            "Epoch 113/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0610 - mae: 28.0610 - mse: 1257.3318\n",
            "Epoch 114/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2626 - mae: 28.2626 - mse: 1278.8157\n",
            "Epoch 115/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0910 - mae: 28.0910 - mse: 1257.0804\n",
            "Epoch 116/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1610 - mae: 28.1610 - mse: 1270.1416\n",
            "Epoch 117/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9974 - mae: 27.9974 - mse: 1247.8940\n",
            "Epoch 118/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1380 - mae: 28.1380 - mse: 1264.5865\n",
            "Epoch 119/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3121 - mae: 28.3121 - mse: 1283.4509\n",
            "Epoch 120/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0157 - mae: 28.0157 - mse: 1263.8212\n",
            "Epoch 121/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2340 - mae: 28.2340 - mse: 1267.6716\n",
            "Epoch 122/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9527 - mae: 27.9527 - mse: 1252.9666\n",
            "Epoch 123/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4512 - mae: 28.4512 - mse: 1292.1749\n",
            "Epoch 124/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3345 - mae: 28.3345 - mse: 1268.7133\n",
            "Epoch 125/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1950 - mae: 28.1950 - mse: 1266.1024\n",
            "Epoch 126/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1668 - mae: 28.1668 - mse: 1268.4122\n",
            "Epoch 127/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2412 - mae: 28.2412 - mse: 1278.8259\n",
            "Epoch 128/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0061 - mae: 28.0061 - mse: 1251.6975\n",
            "Epoch 129/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1173 - mae: 28.1173 - mse: 1263.9010\n",
            "Epoch 130/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1239 - mae: 28.1239 - mse: 1266.4257\n",
            "Epoch 131/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9902 - mae: 27.9902 - mse: 1256.5114\n",
            "Epoch 132/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0507 - mae: 28.0507 - mse: 1250.5001\n",
            "Epoch 133/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9987 - mae: 27.9987 - mse: 1258.4636\n",
            "Epoch 134/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1636 - mae: 28.1636 - mse: 1276.4978\n",
            "Epoch 135/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1555 - mae: 28.1555 - mse: 1261.6359\n",
            "Epoch 136/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1462 - mae: 28.1462 - mse: 1260.9872\n",
            "Epoch 137/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0222 - mae: 28.0222 - mse: 1262.0129\n",
            "Epoch 138/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.9443 - mae: 27.9443 - mse: 1247.4204\n",
            "Epoch 139/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3868 - mae: 28.3868 - mse: 1293.1001\n",
            "Epoch 140/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1900 - mae: 28.1900 - mse: 1265.3170\n",
            "Epoch 141/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4507 - mae: 28.4507 - mse: 1290.7571\n",
            "Epoch 142/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.0376 - mae: 28.0376 - mse: 1257.6316\n",
            "Epoch 143/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1627 - mae: 28.1627 - mse: 1276.1964\n",
            "Epoch 144/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1889 - mae: 28.1889 - mse: 1270.6576\n",
            "Epoch 145/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2349 - mae: 28.2349 - mse: 1270.4082\n",
            "Epoch 146/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1874 - mae: 28.1874 - mse: 1268.1921\n",
            "Epoch 147/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.4495 - mae: 28.4495 - mse: 1297.5635\n",
            "Epoch 148/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.0895 - mae: 28.0895 - mse: 1264.4248\n",
            "Epoch 149/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2076 - mae: 28.2076 - mse: 1270.3860\n",
            "Epoch 150/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0292 - mae: 28.0292 - mse: 1264.6957\n",
            "Epoch 151/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1756 - mae: 28.1756 - mse: 1265.5294\n",
            "Epoch 152/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8540 - mae: 27.8540 - mse: 1239.0884\n",
            "Epoch 153/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0831 - mae: 28.0831 - mse: 1264.1583\n",
            "Epoch 154/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8765 - mae: 27.8765 - mse: 1251.6891\n",
            "Epoch 155/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8514 - mae: 27.8514 - mse: 1244.7095\n",
            "Epoch 156/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9081 - mae: 27.9081 - mse: 1250.1796\n",
            "Epoch 157/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9178 - mae: 27.9178 - mse: 1248.2543\n",
            "Epoch 158/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8631 - mae: 27.8631 - mse: 1240.1161\n",
            "Epoch 159/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0740 - mae: 28.0740 - mse: 1263.3728\n",
            "Epoch 160/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0862 - mae: 28.0862 - mse: 1258.9286\n",
            "Epoch 161/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9160 - mae: 27.9160 - mse: 1250.0000\n",
            "Epoch 162/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3123 - mae: 28.3123 - mse: 1287.0104\n",
            "Epoch 163/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0551 - mae: 28.0551 - mse: 1264.6746\n",
            "Epoch 164/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1840 - mae: 28.1840 - mse: 1267.3677\n",
            "Epoch 165/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2381 - mae: 28.2381 - mse: 1273.6599\n",
            "Epoch 166/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0437 - mae: 28.0437 - mse: 1254.5070\n",
            "Epoch 167/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9897 - mae: 27.9897 - mse: 1259.0138\n",
            "Epoch 168/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7496 - mae: 27.7496 - mse: 1232.7351\n",
            "Epoch 169/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0007 - mae: 28.0007 - mse: 1252.3846\n",
            "Epoch 170/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1513 - mae: 28.1513 - mse: 1270.0009\n",
            "Epoch 171/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7359 - mae: 27.7359 - mse: 1237.4646\n",
            "Epoch 172/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0374 - mae: 28.0374 - mse: 1261.3647\n",
            "Epoch 173/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8476 - mae: 27.8476 - mse: 1245.5355\n",
            "Epoch 174/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8280 - mae: 27.8280 - mse: 1245.4755\n",
            "Epoch 175/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0132 - mae: 28.0132 - mse: 1259.9575\n",
            "Epoch 176/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8361 - mae: 27.8361 - mse: 1241.8573\n",
            "Epoch 177/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.8256 - mae: 27.8256 - mse: 1242.0555\n",
            "Epoch 178/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8396 - mae: 27.8396 - mse: 1244.7332\n",
            "Epoch 179/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7952 - mae: 27.7952 - mse: 1238.6450\n",
            "Epoch 180/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0229 - mae: 28.0229 - mse: 1256.1929\n",
            "Epoch 181/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0659 - mae: 28.0659 - mse: 1260.2307\n",
            "Epoch 182/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0258 - mae: 28.0258 - mse: 1260.9144\n",
            "Epoch 183/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0548 - mae: 28.0548 - mse: 1254.2429\n",
            "Epoch 184/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0753 - mae: 28.0753 - mse: 1271.4161\n",
            "Epoch 185/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6641 - mae: 27.6641 - mse: 1230.5977\n",
            "Epoch 186/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8397 - mae: 27.8397 - mse: 1242.3246\n",
            "Epoch 187/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0979 - mae: 28.0979 - mse: 1255.2728\n",
            "Epoch 188/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0414 - mae: 28.0414 - mse: 1269.1786\n",
            "Epoch 189/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0886 - mae: 28.0886 - mse: 1268.9382\n",
            "Epoch 190/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8024 - mae: 27.8024 - mse: 1239.0929\n",
            "Epoch 191/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7369 - mae: 27.7369 - mse: 1234.6506\n",
            "Epoch 192/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0937 - mae: 28.0937 - mse: 1257.6664\n",
            "Epoch 193/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1563 - mae: 28.1563 - mse: 1273.0435\n",
            "Epoch 194/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7230 - mae: 27.7230 - mse: 1239.7826\n",
            "Epoch 195/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1430 - mae: 28.1430 - mse: 1261.9053\n",
            "Epoch 196/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7019 - mae: 27.7019 - mse: 1230.2091\n",
            "Epoch 197/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1135 - mae: 28.1135 - mse: 1264.6116\n",
            "Epoch 198/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0702 - mae: 28.0702 - mse: 1258.8213\n",
            "Epoch 199/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9020 - mae: 27.9020 - mse: 1245.3892\n",
            "Epoch 200/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1916 - mae: 28.1916 - mse: 1272.3271\n",
            "Epoch 201/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9264 - mae: 27.9264 - mse: 1249.9033\n",
            "Epoch 202/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0519 - mae: 28.0519 - mse: 1263.8290\n",
            "Epoch 203/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7892 - mae: 27.7892 - mse: 1240.0341\n",
            "Epoch 204/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9603 - mae: 27.9603 - mse: 1256.8682\n",
            "Epoch 205/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9956 - mae: 27.9956 - mse: 1258.6050\n",
            "Epoch 206/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0896 - mae: 28.0896 - mse: 1265.9377\n",
            "Epoch 207/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9423 - mae: 27.9423 - mse: 1256.0381\n",
            "Epoch 208/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0481 - mae: 28.0481 - mse: 1268.4194\n",
            "Epoch 209/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8840 - mae: 27.8840 - mse: 1244.5192\n",
            "Epoch 210/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0484 - mae: 28.0484 - mse: 1263.7087\n",
            "Epoch 211/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1349 - mae: 28.1349 - mse: 1263.8291\n",
            "Epoch 212/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8952 - mae: 27.8952 - mse: 1248.0808\n",
            "Epoch 213/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8726 - mae: 27.8726 - mse: 1238.8878\n",
            "Epoch 214/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4147 - mae: 27.4147 - mse: 1206.2041\n",
            "Epoch 215/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8737 - mae: 27.8737 - mse: 1241.4475\n",
            "Epoch 216/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0724 - mae: 28.0724 - mse: 1264.9685\n",
            "Epoch 217/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.6535 - mae: 27.6535 - mse: 1230.9442\n",
            "Epoch 218/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.8158 - mae: 27.8158 - mse: 1234.4835\n",
            "Epoch 219/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9612 - mae: 27.9612 - mse: 1251.6311\n",
            "Epoch 220/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.7393 - mae: 27.7393 - mse: 1233.9495\n",
            "Epoch 221/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.0939 - mae: 28.0939 - mse: 1261.0443\n",
            "Epoch 222/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1690 - mae: 28.1690 - mse: 1269.3738\n",
            "Epoch 223/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.8306 - mae: 27.8306 - mse: 1238.2394\n",
            "Epoch 224/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1290 - mae: 28.1290 - mse: 1263.2623\n",
            "Epoch 225/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.1062 - mae: 28.1062 - mse: 1265.5852\n",
            "Epoch 226/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9310 - mae: 27.9310 - mse: 1242.8873\n",
            "Epoch 227/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.8430 - mae: 27.8430 - mse: 1240.5204\n",
            "Epoch 228/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8848 - mae: 27.8848 - mse: 1254.9926\n",
            "Epoch 229/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7488 - mae: 27.7488 - mse: 1241.5326\n",
            "Epoch 230/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7511 - mae: 27.7511 - mse: 1234.1761\n",
            "Epoch 231/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7494 - mae: 27.7494 - mse: 1233.3458\n",
            "Epoch 232/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0837 - mae: 28.0837 - mse: 1270.9202\n",
            "Epoch 233/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9819 - mae: 27.9819 - mse: 1250.5551\n",
            "Epoch 234/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0025 - mae: 28.0025 - mse: 1256.9993\n",
            "Epoch 235/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9689 - mae: 27.9689 - mse: 1259.2639\n",
            "Epoch 236/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0881 - mae: 28.0881 - mse: 1259.1603\n",
            "Epoch 237/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8685 - mae: 27.8685 - mse: 1247.1929\n",
            "Epoch 238/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0872 - mae: 28.0872 - mse: 1265.6754\n",
            "Epoch 239/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5801 - mae: 27.5801 - mse: 1224.1967\n",
            "Epoch 240/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.8426 - mae: 27.8426 - mse: 1248.4072\n",
            "Epoch 241/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7172 - mae: 27.7172 - mse: 1236.7513\n",
            "Epoch 242/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6912 - mae: 27.6912 - mse: 1236.4342\n",
            "Epoch 243/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1277 - mae: 28.1277 - mse: 1268.0507\n",
            "Epoch 244/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9135 - mae: 27.9135 - mse: 1250.3441\n",
            "Epoch 245/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8474 - mae: 27.8474 - mse: 1249.1211\n",
            "Epoch 246/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8007 - mae: 27.8007 - mse: 1246.7959\n",
            "Epoch 247/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1721 - mae: 28.1721 - mse: 1272.3496\n",
            "Epoch 248/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0147 - mae: 28.0147 - mse: 1261.8391\n",
            "Epoch 249/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8663 - mae: 27.8663 - mse: 1255.0735\n",
            "Epoch 250/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8592 - mae: 27.8592 - mse: 1251.8801\n",
            "Epoch 251/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7954 - mae: 27.7954 - mse: 1242.6456\n",
            "Epoch 252/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8860 - mae: 27.8860 - mse: 1250.9180\n",
            "Epoch 253/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9460 - mae: 27.9460 - mse: 1261.6606\n",
            "Epoch 254/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9186 - mae: 27.9186 - mse: 1251.1947\n",
            "Epoch 255/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8221 - mae: 27.8221 - mse: 1245.5596\n",
            "Epoch 256/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6677 - mae: 27.6677 - mse: 1229.7606\n",
            "Epoch 257/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8843 - mae: 27.8843 - mse: 1247.8224\n",
            "Epoch 258/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8941 - mae: 27.8941 - mse: 1247.5215\n",
            "Epoch 259/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0008 - mae: 28.0008 - mse: 1258.0103\n",
            "Epoch 260/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6126 - mae: 27.6126 - mse: 1230.2014\n",
            "Epoch 261/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7623 - mae: 27.7623 - mse: 1244.6443\n",
            "Epoch 262/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8345 - mae: 27.8345 - mse: 1251.3678\n",
            "Epoch 263/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5268 - mae: 27.5268 - mse: 1216.0227\n",
            "Epoch 264/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6865 - mae: 27.6865 - mse: 1229.6211\n",
            "Epoch 265/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8651 - mae: 27.8651 - mse: 1247.9923\n",
            "Epoch 266/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7544 - mae: 27.7544 - mse: 1236.5710\n",
            "Epoch 267/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7534 - mae: 27.7534 - mse: 1238.2623\n",
            "Epoch 268/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7523 - mae: 27.7523 - mse: 1247.8678\n",
            "Epoch 269/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6569 - mae: 27.6569 - mse: 1236.6642\n",
            "Epoch 270/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0285 - mae: 28.0285 - mse: 1262.0173\n",
            "Epoch 271/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7835 - mae: 27.7835 - mse: 1241.5881\n",
            "Epoch 272/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0891 - mae: 28.0891 - mse: 1262.3309\n",
            "Epoch 273/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8568 - mae: 27.8568 - mse: 1255.8842\n",
            "Epoch 274/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.8506 - mae: 27.8506 - mse: 1253.7699\n",
            "Epoch 275/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7995 - mae: 27.7995 - mse: 1247.3682\n",
            "Epoch 276/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7991 - mae: 27.7991 - mse: 1239.8846\n",
            "Epoch 277/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9516 - mae: 27.9516 - mse: 1256.3014\n",
            "Epoch 278/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9298 - mae: 27.9298 - mse: 1254.4709\n",
            "Epoch 279/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8522 - mae: 27.8522 - mse: 1255.8423\n",
            "Epoch 280/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9110 - mae: 27.9110 - mse: 1257.8904\n",
            "Epoch 281/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6496 - mae: 27.6496 - mse: 1238.6304\n",
            "Epoch 282/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6416 - mae: 27.6416 - mse: 1233.1904\n",
            "Epoch 283/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5966 - mae: 27.5966 - mse: 1223.2161\n",
            "Epoch 284/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6350 - mae: 27.6350 - mse: 1232.8016\n",
            "Epoch 285/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9192 - mae: 27.9192 - mse: 1253.3385\n",
            "Epoch 286/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7577 - mae: 27.7577 - mse: 1241.4924\n",
            "Epoch 287/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6497 - mae: 27.6497 - mse: 1231.7719\n",
            "Epoch 288/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7770 - mae: 27.7770 - mse: 1247.8932\n",
            "Epoch 289/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.7344 - mae: 27.7344 - mse: 1244.6110\n",
            "Epoch 290/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.5411 - mae: 27.5411 - mse: 1219.6254\n",
            "Epoch 291/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.8763 - mae: 27.8763 - mse: 1246.5605\n",
            "Epoch 292/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.7663 - mae: 27.7663 - mse: 1238.1852\n",
            "Epoch 293/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.5154 - mae: 27.5154 - mse: 1220.0438\n",
            "Epoch 294/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.6431 - mae: 27.6431 - mse: 1233.5276\n",
            "Epoch 295/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27.6696 - mae: 27.6696 - mse: 1233.8112\n",
            "Epoch 296/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.6853 - mae: 27.6853 - mse: 1228.4788\n",
            "Epoch 297/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.7061 - mae: 27.7061 - mse: 1245.5432\n",
            "Epoch 298/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.7218 - mae: 27.7218 - mse: 1241.8859\n",
            "Epoch 299/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.6131 - mae: 27.6131 - mse: 1234.4633\n",
            "Epoch 300/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.6369 - mae: 27.6369 - mse: 1236.5066\n",
            "Epoch 301/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.6195 - mae: 27.6195 - mse: 1236.6836\n",
            "Epoch 302/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6467 - mae: 27.6467 - mse: 1238.1898\n",
            "Epoch 303/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7194 - mae: 27.7194 - mse: 1238.9296\n",
            "Epoch 304/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7635 - mae: 27.7635 - mse: 1246.0443\n",
            "Epoch 305/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1784 - mae: 28.1784 - mse: 1278.5969\n",
            "Epoch 306/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7692 - mae: 27.7692 - mse: 1251.6838\n",
            "Epoch 307/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3816 - mae: 27.3816 - mse: 1213.7866\n",
            "Epoch 308/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4744 - mae: 27.4744 - mse: 1221.3112\n",
            "Epoch 309/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6423 - mae: 27.6423 - mse: 1226.9144\n",
            "Epoch 310/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7610 - mae: 27.7610 - mse: 1252.0507\n",
            "Epoch 311/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6767 - mae: 27.6767 - mse: 1238.7467\n",
            "Epoch 312/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7341 - mae: 27.7341 - mse: 1242.4247\n",
            "Epoch 313/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7058 - mae: 27.7058 - mse: 1241.1943\n",
            "Epoch 314/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6410 - mae: 27.6410 - mse: 1231.3027\n",
            "Epoch 315/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5980 - mae: 27.5980 - mse: 1234.4697\n",
            "Epoch 316/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8338 - mae: 27.8338 - mse: 1255.9166\n",
            "Epoch 317/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6622 - mae: 27.6622 - mse: 1235.5033\n",
            "Epoch 318/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.5626 - mae: 27.5626 - mse: 1232.7625\n",
            "Epoch 319/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6483 - mae: 27.6483 - mse: 1237.3185\n",
            "Epoch 320/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8895 - mae: 27.8895 - mse: 1268.7302\n",
            "Epoch 321/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4578 - mae: 27.4578 - mse: 1225.8890\n",
            "Epoch 322/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9115 - mae: 27.9115 - mse: 1250.5333\n",
            "Epoch 323/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5610 - mae: 27.5610 - mse: 1225.4490\n",
            "Epoch 324/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4164 - mae: 27.4164 - mse: 1218.2260\n",
            "Epoch 325/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6098 - mae: 27.6098 - mse: 1232.7775\n",
            "Epoch 326/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6562 - mae: 27.6562 - mse: 1236.2781\n",
            "Epoch 327/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6898 - mae: 27.6898 - mse: 1237.3972\n",
            "Epoch 328/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4796 - mae: 27.4796 - mse: 1225.0533\n",
            "Epoch 329/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5068 - mae: 27.5068 - mse: 1228.9360\n",
            "Epoch 330/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6348 - mae: 27.6348 - mse: 1239.7388\n",
            "Epoch 331/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5500 - mae: 27.5500 - mse: 1226.2203\n",
            "Epoch 332/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5954 - mae: 27.5954 - mse: 1234.8866\n",
            "Epoch 333/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7758 - mae: 27.7758 - mse: 1254.3015\n",
            "Epoch 334/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5385 - mae: 27.5385 - mse: 1228.4764\n",
            "Epoch 335/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4677 - mae: 27.4677 - mse: 1221.9969\n",
            "Epoch 336/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7429 - mae: 27.7429 - mse: 1244.1031\n",
            "Epoch 337/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5338 - mae: 27.5338 - mse: 1232.6598\n",
            "Epoch 338/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7333 - mae: 27.7333 - mse: 1248.1858\n",
            "Epoch 339/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7291 - mae: 27.7291 - mse: 1249.0316\n",
            "Epoch 340/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6097 - mae: 27.6097 - mse: 1238.1403\n",
            "Epoch 341/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4046 - mae: 27.4046 - mse: 1214.8713\n",
            "Epoch 342/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4519 - mae: 27.4519 - mse: 1222.6072\n",
            "Epoch 343/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6122 - mae: 27.6122 - mse: 1238.5500\n",
            "Epoch 344/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.4312 - mae: 27.4312 - mse: 1221.5686\n",
            "Epoch 345/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5797 - mae: 27.5797 - mse: 1228.6234\n",
            "Epoch 346/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5809 - mae: 27.5809 - mse: 1237.8790\n",
            "Epoch 347/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.6637 - mae: 27.6637 - mse: 1238.6597\n",
            "Epoch 348/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7477 - mae: 27.7477 - mse: 1249.4969\n",
            "Epoch 349/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5376 - mae: 27.5376 - mse: 1222.5767\n",
            "Epoch 350/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3185 - mae: 27.3185 - mse: 1211.3329\n",
            "Epoch 351/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5775 - mae: 27.5775 - mse: 1239.9906\n",
            "Epoch 352/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6913 - mae: 27.6913 - mse: 1235.4951\n",
            "Epoch 353/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7728 - mae: 27.7728 - mse: 1246.1825\n",
            "Epoch 354/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5918 - mae: 27.5918 - mse: 1229.1255\n",
            "Epoch 355/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5942 - mae: 27.5942 - mse: 1236.2820\n",
            "Epoch 356/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6880 - mae: 27.6880 - mse: 1240.7761\n",
            "Epoch 357/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5010 - mae: 27.5010 - mse: 1224.7070\n",
            "Epoch 358/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5652 - mae: 27.5652 - mse: 1235.8446\n",
            "Epoch 359/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4582 - mae: 27.4582 - mse: 1231.6132\n",
            "Epoch 360/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6032 - mae: 27.6032 - mse: 1229.5121\n",
            "Epoch 361/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3525 - mae: 27.3525 - mse: 1214.7603\n",
            "Epoch 362/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3850 - mae: 27.3850 - mse: 1208.8177\n",
            "Epoch 363/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.5622 - mae: 27.5622 - mse: 1233.5530\n",
            "Epoch 364/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.6063 - mae: 27.6063 - mse: 1236.7819\n",
            "Epoch 365/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6981 - mae: 27.6981 - mse: 1243.1748\n",
            "Epoch 366/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6086 - mae: 27.6086 - mse: 1236.7687\n",
            "Epoch 367/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.5692 - mae: 27.5692 - mse: 1228.2003\n",
            "Epoch 368/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.7514 - mae: 27.7514 - mse: 1242.2229\n",
            "Epoch 369/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.3793 - mae: 27.3793 - mse: 1228.4041\n",
            "Epoch 370/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.4668 - mae: 27.4668 - mse: 1223.3091\n",
            "Epoch 371/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.4289 - mae: 27.4289 - mse: 1219.1742\n",
            "Epoch 372/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.6343 - mae: 27.6343 - mse: 1232.9541\n",
            "Epoch 373/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.5218 - mae: 27.5218 - mse: 1232.2091\n",
            "Epoch 374/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.6785 - mae: 27.6785 - mse: 1240.2203\n",
            "Epoch 375/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.5975 - mae: 27.5975 - mse: 1232.3544\n",
            "Epoch 376/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.5128 - mae: 27.5128 - mse: 1226.9531\n",
            "Epoch 377/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4583 - mae: 27.4583 - mse: 1234.4725\n",
            "Epoch 378/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6912 - mae: 27.6912 - mse: 1245.0261\n",
            "Epoch 379/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5077 - mae: 27.5077 - mse: 1227.3906\n",
            "Epoch 380/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5630 - mae: 27.5630 - mse: 1231.8246\n",
            "Epoch 381/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6729 - mae: 27.6729 - mse: 1241.7705\n",
            "Epoch 382/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.2159 - mae: 27.2159 - mse: 1208.1206\n",
            "Epoch 383/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1937 - mae: 27.1937 - mse: 1204.2429\n",
            "Epoch 384/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5590 - mae: 27.5590 - mse: 1232.4253\n",
            "Epoch 385/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5027 - mae: 27.5027 - mse: 1228.2516\n",
            "Epoch 386/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5673 - mae: 27.5673 - mse: 1228.1790\n",
            "Epoch 387/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4785 - mae: 27.4785 - mse: 1222.8304\n",
            "Epoch 388/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3899 - mae: 27.3899 - mse: 1220.8051\n",
            "Epoch 389/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6511 - mae: 27.6511 - mse: 1242.8916\n",
            "Epoch 390/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3315 - mae: 27.3315 - mse: 1219.0225\n",
            "Epoch 391/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6146 - mae: 27.6146 - mse: 1233.7135\n",
            "Epoch 392/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5747 - mae: 27.5747 - mse: 1227.7280\n",
            "Epoch 393/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6518 - mae: 27.6518 - mse: 1243.0072\n",
            "Epoch 394/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.2846 - mae: 27.2846 - mse: 1212.4670\n",
            "Epoch 395/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3575 - mae: 27.3575 - mse: 1223.4508\n",
            "Epoch 396/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5613 - mae: 27.5613 - mse: 1232.9980\n",
            "Epoch 397/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4807 - mae: 27.4807 - mse: 1227.1199\n",
            "Epoch 398/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4016 - mae: 27.4016 - mse: 1224.1697\n",
            "Epoch 399/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3745 - mae: 27.3745 - mse: 1221.8737\n",
            "Epoch 400/400\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1488 - mae: 27.1488 - mse: 1210.6326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3b9b9ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_C['(0.01, 1000, 400)'] = loss"
      ],
      "metadata": {
        "id": "oA1gxr8AJuY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58fe9ab-c2f2-49cb-d96e-2a0630d921a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.8260 - mae: 28.8260 - mse: 1299.7816\n",
            "Loss: [28.883014678955078, 28.883014678955078, 1301.1168212890625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) (learning_rates, batch_size, epochs) = (0.01, 500, 400)"
      ],
      "metadata": {
        "id": "SJjFuxheIHHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=500, epochs=400, verbose=1)"
      ],
      "metadata": {
        "id": "1NUtfulhJvC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af77789e-a0da-421b-db87-1a23247b74fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 60.5580 - mae: 60.5580 - mse: 5970.5229\n",
            "Epoch 2/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 44.6526 - mae: 44.6526 - mse: 3277.0359\n",
            "Epoch 3/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.0902 - mae: 36.0902 - mse: 2167.1453\n",
            "Epoch 4/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.9141 - mae: 31.9141 - mse: 1675.2640\n",
            "Epoch 5/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.1522 - mae: 31.1522 - mse: 1599.3044\n",
            "Epoch 6/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.3142 - mae: 30.3142 - mse: 1493.3417\n",
            "Epoch 7/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.9169 - mae: 29.9169 - mse: 1445.6031\n",
            "Epoch 8/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.5847 - mae: 29.5847 - mse: 1401.3811\n",
            "Epoch 9/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.3893 - mae: 29.3893 - mse: 1389.9031\n",
            "Epoch 10/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2632 - mae: 29.2632 - mse: 1381.3474\n",
            "Epoch 11/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.8287 - mae: 28.8287 - mse: 1346.5490\n",
            "Epoch 12/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2061 - mae: 29.2061 - mse: 1383.1483\n",
            "Epoch 13/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5490 - mae: 29.5490 - mse: 1401.7648\n",
            "Epoch 14/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8980 - mae: 28.8980 - mse: 1335.1514\n",
            "Epoch 15/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4690 - mae: 28.4690 - mse: 1304.4468\n",
            "Epoch 16/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4933 - mae: 28.4933 - mse: 1299.8503\n",
            "Epoch 17/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6000 - mae: 28.6000 - mse: 1302.8846\n",
            "Epoch 18/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6325 - mae: 28.6325 - mse: 1300.1338\n",
            "Epoch 19/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5666 - mae: 28.5666 - mse: 1315.1921\n",
            "Epoch 20/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4855 - mae: 28.4855 - mse: 1291.6929\n",
            "Epoch 21/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6446 - mae: 28.6446 - mse: 1306.0806\n",
            "Epoch 22/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 28.3486 - mae: 28.3486 - mse: 1286.7367\n",
            "Epoch 23/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6327 - mae: 28.6327 - mse: 1303.6121\n",
            "Epoch 24/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2959 - mae: 28.2959 - mse: 1280.4958\n",
            "Epoch 25/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3807 - mae: 28.3807 - mse: 1298.7979\n",
            "Epoch 26/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4660 - mae: 28.4660 - mse: 1291.1896\n",
            "Epoch 27/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1201 - mae: 28.1201 - mse: 1268.8372\n",
            "Epoch 28/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4457 - mae: 28.4457 - mse: 1290.7767\n",
            "Epoch 29/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.7279 - mae: 28.7279 - mse: 1324.1077\n",
            "Epoch 30/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5186 - mae: 28.5186 - mse: 1302.1595\n",
            "Epoch 31/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1738 - mae: 28.1738 - mse: 1275.4971\n",
            "Epoch 32/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0326 - mae: 28.0326 - mse: 1261.2803\n",
            "Epoch 33/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3323 - mae: 28.3323 - mse: 1274.7866\n",
            "Epoch 34/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6241 - mae: 28.6241 - mse: 1303.2013\n",
            "Epoch 35/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2880 - mae: 28.2880 - mse: 1279.5380\n",
            "Epoch 36/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3652 - mae: 28.3652 - mse: 1285.0692\n",
            "Epoch 37/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1015 - mae: 28.1015 - mse: 1260.8862\n",
            "Epoch 38/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2663 - mae: 28.2663 - mse: 1274.8197\n",
            "Epoch 39/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3526 - mae: 28.3526 - mse: 1279.4127\n",
            "Epoch 40/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2143 - mae: 28.2143 - mse: 1273.3942\n",
            "Epoch 41/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2621 - mae: 28.2621 - mse: 1280.1669\n",
            "Epoch 42/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3235 - mae: 28.3235 - mse: 1281.4611\n",
            "Epoch 43/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0053 - mae: 28.0053 - mse: 1257.9432\n",
            "Epoch 44/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1647 - mae: 28.1647 - mse: 1257.0854\n",
            "Epoch 45/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3438 - mae: 28.3438 - mse: 1286.1389\n",
            "Epoch 46/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0626 - mae: 28.0626 - mse: 1264.5076\n",
            "Epoch 47/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3796 - mae: 28.3796 - mse: 1282.0865\n",
            "Epoch 48/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4874 - mae: 28.4874 - mse: 1295.9904\n",
            "Epoch 49/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2577 - mae: 28.2577 - mse: 1287.0082\n",
            "Epoch 50/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9948 - mae: 27.9948 - mse: 1253.8080\n",
            "Epoch 51/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0261 - mae: 28.0261 - mse: 1266.1754\n",
            "Epoch 52/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2739 - mae: 28.2739 - mse: 1285.4988\n",
            "Epoch 53/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1528 - mae: 28.1528 - mse: 1267.1313\n",
            "Epoch 54/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2242 - mae: 28.2242 - mse: 1278.2068\n",
            "Epoch 55/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0605 - mae: 28.0605 - mse: 1271.1978\n",
            "Epoch 56/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1718 - mae: 28.1718 - mse: 1267.4399\n",
            "Epoch 57/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9038 - mae: 27.9038 - mse: 1262.8102\n",
            "Epoch 58/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3143 - mae: 28.3143 - mse: 1293.2253\n",
            "Epoch 59/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8899 - mae: 27.8899 - mse: 1251.6495\n",
            "Epoch 60/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7759 - mae: 27.7759 - mse: 1246.8943\n",
            "Epoch 61/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8934 - mae: 27.8934 - mse: 1254.2147\n",
            "Epoch 62/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2953 - mae: 28.2953 - mse: 1277.6119\n",
            "Epoch 63/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9579 - mae: 27.9579 - mse: 1265.1469\n",
            "Epoch 64/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.6679 - mae: 27.6679 - mse: 1238.5444\n",
            "Epoch 65/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.1308 - mae: 28.1308 - mse: 1275.8972\n",
            "Epoch 66/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0411 - mae: 28.0411 - mse: 1262.2765\n",
            "Epoch 67/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3568 - mae: 28.3568 - mse: 1290.5500\n",
            "Epoch 68/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.9253 - mae: 27.9253 - mse: 1260.3108\n",
            "Epoch 69/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0143 - mae: 28.0143 - mse: 1260.0864\n",
            "Epoch 70/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2718 - mae: 28.2718 - mse: 1287.0410\n",
            "Epoch 71/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8828 - mae: 27.8828 - mse: 1254.5465\n",
            "Epoch 72/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7970 - mae: 27.7970 - mse: 1256.3239\n",
            "Epoch 73/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8596 - mae: 27.8596 - mse: 1252.9491\n",
            "Epoch 74/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0852 - mae: 28.0852 - mse: 1264.3805\n",
            "Epoch 75/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2735 - mae: 28.2735 - mse: 1286.2507\n",
            "Epoch 76/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9836 - mae: 27.9836 - mse: 1273.7664\n",
            "Epoch 77/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2347 - mae: 28.2347 - mse: 1279.9923\n",
            "Epoch 78/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7754 - mae: 27.7754 - mse: 1247.4016\n",
            "Epoch 79/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9261 - mae: 27.9261 - mse: 1259.3840\n",
            "Epoch 80/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7515 - mae: 27.7515 - mse: 1244.0204\n",
            "Epoch 81/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0675 - mae: 28.0675 - mse: 1270.8011\n",
            "Epoch 82/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7411 - mae: 27.7411 - mse: 1249.3119\n",
            "Epoch 83/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8414 - mae: 27.8414 - mse: 1242.5580\n",
            "Epoch 84/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7801 - mae: 27.7801 - mse: 1251.6106\n",
            "Epoch 85/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7637 - mae: 27.7637 - mse: 1245.2186\n",
            "Epoch 86/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0543 - mae: 28.0543 - mse: 1265.2111\n",
            "Epoch 87/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9587 - mae: 27.9587 - mse: 1269.5920\n",
            "Epoch 88/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6499 - mae: 27.6499 - mse: 1240.2760\n",
            "Epoch 89/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6711 - mae: 27.6711 - mse: 1239.5356\n",
            "Epoch 90/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7588 - mae: 27.7588 - mse: 1253.3363\n",
            "Epoch 91/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0194 - mae: 28.0194 - mse: 1259.1006\n",
            "Epoch 92/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0178 - mae: 28.0178 - mse: 1268.3062\n",
            "Epoch 93/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7560 - mae: 27.7560 - mse: 1249.1877\n",
            "Epoch 94/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5159 - mae: 27.5159 - mse: 1230.3759\n",
            "Epoch 95/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6384 - mae: 27.6384 - mse: 1236.6161\n",
            "Epoch 96/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9297 - mae: 27.9297 - mse: 1265.8097\n",
            "Epoch 97/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0034 - mae: 28.0034 - mse: 1272.7208\n",
            "Epoch 98/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8274 - mae: 27.8274 - mse: 1250.3373\n",
            "Epoch 99/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6694 - mae: 27.6694 - mse: 1236.8118\n",
            "Epoch 100/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8190 - mae: 27.8190 - mse: 1257.4152\n",
            "Epoch 101/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6730 - mae: 27.6730 - mse: 1238.9185\n",
            "Epoch 102/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7405 - mae: 27.7405 - mse: 1250.7899\n",
            "Epoch 103/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7843 - mae: 27.7843 - mse: 1243.7798\n",
            "Epoch 104/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2074 - mae: 28.2074 - mse: 1287.2216\n",
            "Epoch 105/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6591 - mae: 27.6591 - mse: 1242.8684\n",
            "Epoch 106/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5557 - mae: 27.5557 - mse: 1237.7355\n",
            "Epoch 107/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4274 - mae: 27.4274 - mse: 1225.4291\n",
            "Epoch 108/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8155 - mae: 27.8155 - mse: 1253.7979\n",
            "Epoch 109/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6355 - mae: 27.6355 - mse: 1228.9933\n",
            "Epoch 110/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6567 - mae: 27.6567 - mse: 1238.8993\n",
            "Epoch 111/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5939 - mae: 27.5939 - mse: 1236.7705\n",
            "Epoch 112/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.7051 - mae: 27.7051 - mse: 1247.5448\n",
            "Epoch 113/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5290 - mae: 27.5290 - mse: 1234.2867\n",
            "Epoch 114/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7500 - mae: 27.7500 - mse: 1245.8827\n",
            "Epoch 115/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.7059 - mae: 27.7059 - mse: 1243.2565\n",
            "Epoch 116/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5973 - mae: 27.5973 - mse: 1245.3151\n",
            "Epoch 117/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.6949 - mae: 27.6949 - mse: 1247.6134\n",
            "Epoch 118/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6618 - mae: 27.6618 - mse: 1242.1793\n",
            "Epoch 119/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.4470 - mae: 27.4470 - mse: 1230.2681\n",
            "Epoch 120/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.5373 - mae: 27.5373 - mse: 1240.4977\n",
            "Epoch 121/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 27.6743 - mae: 27.6743 - mse: 1240.5420\n",
            "Epoch 122/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 27.5736 - mae: 27.5736 - mse: 1232.0693\n",
            "Epoch 123/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.5695 - mae: 27.5695 - mse: 1242.9324\n",
            "Epoch 124/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3542 - mae: 27.3542 - mse: 1218.9587\n",
            "Epoch 125/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.5711 - mae: 27.5711 - mse: 1231.1742\n",
            "Epoch 126/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3434 - mae: 27.3434 - mse: 1220.6627\n",
            "Epoch 127/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4417 - mae: 27.4417 - mse: 1217.7433\n",
            "Epoch 128/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.5504 - mae: 27.5504 - mse: 1236.2064\n",
            "Epoch 129/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4305 - mae: 27.4305 - mse: 1226.9028\n",
            "Epoch 130/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.5973 - mae: 27.5973 - mse: 1239.7847\n",
            "Epoch 131/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.6294 - mae: 27.6294 - mse: 1246.7744\n",
            "Epoch 132/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4466 - mae: 27.4466 - mse: 1225.8563\n",
            "Epoch 133/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0054 - mae: 28.0054 - mse: 1265.0404\n",
            "Epoch 134/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8632 - mae: 27.8632 - mse: 1258.0560\n",
            "Epoch 135/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7704 - mae: 27.7704 - mse: 1256.1411\n",
            "Epoch 136/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5344 - mae: 27.5344 - mse: 1236.7489\n",
            "Epoch 137/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.2136 - mae: 27.2136 - mse: 1209.8616\n",
            "Epoch 138/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7061 - mae: 27.7061 - mse: 1249.1483\n",
            "Epoch 139/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6326 - mae: 27.6326 - mse: 1250.0586\n",
            "Epoch 140/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5396 - mae: 27.5396 - mse: 1228.2681\n",
            "Epoch 141/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4934 - mae: 27.4934 - mse: 1227.7090\n",
            "Epoch 142/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5239 - mae: 27.5239 - mse: 1235.5679\n",
            "Epoch 143/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4130 - mae: 27.4130 - mse: 1230.5199\n",
            "Epoch 144/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4870 - mae: 27.4870 - mse: 1234.7678\n",
            "Epoch 145/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6532 - mae: 27.6532 - mse: 1244.9552\n",
            "Epoch 146/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5492 - mae: 27.5492 - mse: 1238.3770\n",
            "Epoch 147/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.5320 - mae: 27.5320 - mse: 1245.4592\n",
            "Epoch 148/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4453 - mae: 27.4453 - mse: 1231.3149\n",
            "Epoch 149/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3985 - mae: 27.3985 - mse: 1226.6085\n",
            "Epoch 150/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8250 - mae: 27.8250 - mse: 1258.2866\n",
            "Epoch 151/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.5596 - mae: 27.5596 - mse: 1239.6030\n",
            "Epoch 152/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6047 - mae: 27.6047 - mse: 1249.8553\n",
            "Epoch 153/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6614 - mae: 27.6614 - mse: 1243.1229\n",
            "Epoch 154/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5725 - mae: 27.5725 - mse: 1245.9077\n",
            "Epoch 155/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2545 - mae: 27.2545 - mse: 1224.3561\n",
            "Epoch 156/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3565 - mae: 27.3565 - mse: 1226.1119\n",
            "Epoch 157/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.2686 - mae: 27.2686 - mse: 1214.6765\n",
            "Epoch 158/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5183 - mae: 27.5183 - mse: 1238.6266\n",
            "Epoch 159/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.3971 - mae: 27.3971 - mse: 1226.7297\n",
            "Epoch 160/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5424 - mae: 27.5424 - mse: 1235.6796\n",
            "Epoch 161/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.1773 - mae: 27.1773 - mse: 1206.5559\n",
            "Epoch 162/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.5698 - mae: 27.5698 - mse: 1235.1482\n",
            "Epoch 163/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.6508 - mae: 27.6508 - mse: 1245.5272\n",
            "Epoch 164/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.2208 - mae: 27.2208 - mse: 1219.8916\n",
            "Epoch 165/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 27.0671 - mae: 27.0671 - mse: 1197.7953\n",
            "Epoch 166/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4066 - mae: 27.4066 - mse: 1235.0708\n",
            "Epoch 167/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3388 - mae: 27.3388 - mse: 1222.9447\n",
            "Epoch 168/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3152 - mae: 27.3152 - mse: 1221.0371\n",
            "Epoch 169/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4074 - mae: 27.4074 - mse: 1229.4769\n",
            "Epoch 170/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5142 - mae: 27.5142 - mse: 1238.8489\n",
            "Epoch 171/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3830 - mae: 27.3830 - mse: 1226.9254\n",
            "Epoch 172/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.6489 - mae: 27.6489 - mse: 1252.4835\n",
            "Epoch 173/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3024 - mae: 27.3024 - mse: 1228.8812\n",
            "Epoch 174/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4841 - mae: 27.4841 - mse: 1236.0348\n",
            "Epoch 175/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2246 - mae: 27.2246 - mse: 1213.6166\n",
            "Epoch 176/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0864 - mae: 27.0864 - mse: 1208.8213\n",
            "Epoch 177/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1524 - mae: 27.1524 - mse: 1210.1003\n",
            "Epoch 178/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4183 - mae: 27.4183 - mse: 1224.1697\n",
            "Epoch 179/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3378 - mae: 27.3378 - mse: 1227.9729\n",
            "Epoch 180/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3537 - mae: 27.3537 - mse: 1218.3669\n",
            "Epoch 181/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5821 - mae: 27.5821 - mse: 1236.6455\n",
            "Epoch 182/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.4033 - mae: 27.4033 - mse: 1217.5079\n",
            "Epoch 183/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2741 - mae: 27.2741 - mse: 1227.3688\n",
            "Epoch 184/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3176 - mae: 27.3176 - mse: 1227.7408\n",
            "Epoch 185/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1322 - mae: 27.1322 - mse: 1220.2041\n",
            "Epoch 186/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2985 - mae: 27.2985 - mse: 1225.5107\n",
            "Epoch 187/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4921 - mae: 27.4921 - mse: 1231.8472\n",
            "Epoch 188/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0682 - mae: 27.0682 - mse: 1206.2731\n",
            "Epoch 189/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5943 - mae: 27.5943 - mse: 1238.8843\n",
            "Epoch 190/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3662 - mae: 27.3662 - mse: 1222.6924\n",
            "Epoch 191/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2449 - mae: 27.2449 - mse: 1213.6123\n",
            "Epoch 192/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3931 - mae: 27.3931 - mse: 1228.2861\n",
            "Epoch 193/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9994 - mae: 26.9994 - mse: 1200.3318\n",
            "Epoch 194/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1532 - mae: 27.1532 - mse: 1209.7103\n",
            "Epoch 195/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4364 - mae: 27.4364 - mse: 1233.9087\n",
            "Epoch 196/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3535 - mae: 27.3535 - mse: 1222.2728\n",
            "Epoch 197/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1056 - mae: 27.1056 - mse: 1205.1418\n",
            "Epoch 198/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2089 - mae: 27.2089 - mse: 1224.1718\n",
            "Epoch 199/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3695 - mae: 27.3695 - mse: 1227.6718\n",
            "Epoch 200/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3053 - mae: 27.3053 - mse: 1223.5059\n",
            "Epoch 201/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1641 - mae: 27.1641 - mse: 1210.3851\n",
            "Epoch 202/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2049 - mae: 27.2049 - mse: 1219.3793\n",
            "Epoch 203/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3481 - mae: 27.3481 - mse: 1233.4054\n",
            "Epoch 204/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3408 - mae: 27.3408 - mse: 1241.8768\n",
            "Epoch 205/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.0504 - mae: 27.0504 - mse: 1211.9805\n",
            "Epoch 206/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.3949 - mae: 27.3949 - mse: 1235.1417\n",
            "Epoch 207/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1940 - mae: 27.1940 - mse: 1210.9342\n",
            "Epoch 208/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.2945 - mae: 27.2945 - mse: 1224.9194\n",
            "Epoch 209/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.4014 - mae: 27.4014 - mse: 1234.9908\n",
            "Epoch 210/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3718 - mae: 27.3718 - mse: 1233.8604\n",
            "Epoch 211/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.2214 - mae: 27.2214 - mse: 1219.2145\n",
            "Epoch 212/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.2583 - mae: 27.2583 - mse: 1217.5955\n",
            "Epoch 213/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.9973 - mae: 26.9973 - mse: 1196.9937\n",
            "Epoch 214/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.0913 - mae: 27.0913 - mse: 1208.2689\n",
            "Epoch 215/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.2267 - mae: 27.2267 - mse: 1222.0452\n",
            "Epoch 216/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.2027 - mae: 27.2027 - mse: 1211.6708\n",
            "Epoch 217/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.3475 - mae: 27.3475 - mse: 1230.8914\n",
            "Epoch 218/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1963 - mae: 27.1963 - mse: 1221.0958\n",
            "Epoch 219/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1687 - mae: 27.1687 - mse: 1220.8154\n",
            "Epoch 220/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4983 - mae: 27.4983 - mse: 1249.4437\n",
            "Epoch 221/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0350 - mae: 27.0350 - mse: 1202.4607\n",
            "Epoch 222/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2420 - mae: 27.2420 - mse: 1224.0229\n",
            "Epoch 223/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2690 - mae: 27.2690 - mse: 1227.2047\n",
            "Epoch 224/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.3879 - mae: 27.3879 - mse: 1227.5656\n",
            "Epoch 225/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0994 - mae: 27.0994 - mse: 1215.0520\n",
            "Epoch 226/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1337 - mae: 27.1337 - mse: 1209.9061\n",
            "Epoch 227/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0718 - mae: 27.0718 - mse: 1209.1262\n",
            "Epoch 228/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3876 - mae: 27.3876 - mse: 1235.6841\n",
            "Epoch 229/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1667 - mae: 27.1667 - mse: 1213.3442\n",
            "Epoch 230/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0295 - mae: 27.0295 - mse: 1202.3743\n",
            "Epoch 231/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0847 - mae: 27.0847 - mse: 1218.0931\n",
            "Epoch 232/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9504 - mae: 26.9504 - mse: 1200.4608\n",
            "Epoch 233/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0226 - mae: 27.0226 - mse: 1198.9823\n",
            "Epoch 234/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2328 - mae: 27.2328 - mse: 1225.0576\n",
            "Epoch 235/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1926 - mae: 27.1926 - mse: 1225.0306\n",
            "Epoch 236/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9117 - mae: 26.9117 - mse: 1196.6185\n",
            "Epoch 237/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9062 - mae: 26.9062 - mse: 1200.2439\n",
            "Epoch 238/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0715 - mae: 27.0715 - mse: 1213.2335\n",
            "Epoch 239/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0610 - mae: 27.0610 - mse: 1208.8123\n",
            "Epoch 240/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1458 - mae: 27.1458 - mse: 1223.8888\n",
            "Epoch 241/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8212 - mae: 26.8212 - mse: 1196.6564\n",
            "Epoch 242/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0379 - mae: 27.0379 - mse: 1207.8141\n",
            "Epoch 243/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0909 - mae: 27.0909 - mse: 1212.0795\n",
            "Epoch 244/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0011 - mae: 27.0011 - mse: 1199.0874\n",
            "Epoch 245/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9485 - mae: 26.9485 - mse: 1199.8586\n",
            "Epoch 246/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.1586 - mae: 27.1586 - mse: 1225.1458\n",
            "Epoch 247/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2428 - mae: 27.2428 - mse: 1220.1021\n",
            "Epoch 248/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1752 - mae: 27.1752 - mse: 1211.6687\n",
            "Epoch 249/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0439 - mae: 27.0439 - mse: 1207.5850\n",
            "Epoch 250/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0695 - mae: 27.0695 - mse: 1212.8674\n",
            "Epoch 251/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7769 - mae: 26.7769 - mse: 1190.6403\n",
            "Epoch 252/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9533 - mae: 26.9533 - mse: 1192.9156\n",
            "Epoch 253/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2636 - mae: 27.2636 - mse: 1226.8766\n",
            "Epoch 254/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.3284 - mae: 27.3284 - mse: 1229.9553\n",
            "Epoch 255/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9368 - mae: 26.9368 - mse: 1197.7595\n",
            "Epoch 256/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1721 - mae: 27.1721 - mse: 1214.9764\n",
            "Epoch 257/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.9094 - mae: 26.9094 - mse: 1200.1091\n",
            "Epoch 258/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.9838 - mae: 26.9838 - mse: 1210.2886\n",
            "Epoch 259/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.8046 - mae: 26.8046 - mse: 1199.5793\n",
            "Epoch 260/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.0709 - mae: 27.0709 - mse: 1216.1320\n",
            "Epoch 261/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.7929 - mae: 26.7929 - mse: 1190.0326\n",
            "Epoch 262/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.0282 - mae: 27.0282 - mse: 1208.8765\n",
            "Epoch 263/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.0167 - mae: 27.0167 - mse: 1205.5966\n",
            "Epoch 264/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.9729 - mae: 26.9729 - mse: 1203.2922\n",
            "Epoch 265/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 26.9614 - mae: 26.9614 - mse: 1196.5543\n",
            "Epoch 266/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 26.9013 - mae: 26.9013 - mse: 1201.2904\n",
            "Epoch 267/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8079 - mae: 26.8079 - mse: 1191.1210\n",
            "Epoch 268/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9223 - mae: 26.9223 - mse: 1203.0234\n",
            "Epoch 269/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0033 - mae: 27.0033 - mse: 1211.9308\n",
            "Epoch 270/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7125 - mae: 26.7125 - mse: 1192.4689\n",
            "Epoch 271/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0686 - mae: 27.0686 - mse: 1216.1383\n",
            "Epoch 272/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0555 - mae: 27.0555 - mse: 1208.6685\n",
            "Epoch 273/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1431 - mae: 27.1431 - mse: 1225.5566\n",
            "Epoch 274/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1326 - mae: 27.1326 - mse: 1218.5935\n",
            "Epoch 275/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9253 - mae: 26.9253 - mse: 1201.1167\n",
            "Epoch 276/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0380 - mae: 27.0380 - mse: 1203.0126\n",
            "Epoch 277/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9193 - mae: 26.9193 - mse: 1206.9225\n",
            "Epoch 278/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7631 - mae: 26.7631 - mse: 1187.7667\n",
            "Epoch 279/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9386 - mae: 26.9386 - mse: 1201.6040\n",
            "Epoch 280/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9157 - mae: 26.9157 - mse: 1204.6357\n",
            "Epoch 281/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9318 - mae: 26.9318 - mse: 1199.3606\n",
            "Epoch 282/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1410 - mae: 27.1410 - mse: 1220.5936\n",
            "Epoch 283/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8312 - mae: 26.8312 - mse: 1200.6672\n",
            "Epoch 284/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.2870 - mae: 27.2870 - mse: 1225.2159\n",
            "Epoch 285/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6304 - mae: 26.6304 - mse: 1185.9272\n",
            "Epoch 286/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0163 - mae: 27.0163 - mse: 1210.8141\n",
            "Epoch 287/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9481 - mae: 26.9481 - mse: 1213.0260\n",
            "Epoch 288/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0053 - mae: 27.0053 - mse: 1209.6277\n",
            "Epoch 289/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6709 - mae: 26.6709 - mse: 1187.7573\n",
            "Epoch 290/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9162 - mae: 26.9162 - mse: 1198.0681\n",
            "Epoch 291/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7083 - mae: 26.7083 - mse: 1192.1377\n",
            "Epoch 292/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8549 - mae: 26.8549 - mse: 1209.5366\n",
            "Epoch 293/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0228 - mae: 27.0228 - mse: 1215.5339\n",
            "Epoch 294/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9009 - mae: 26.9009 - mse: 1206.6899\n",
            "Epoch 295/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7291 - mae: 26.7291 - mse: 1187.1709\n",
            "Epoch 296/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9741 - mae: 26.9741 - mse: 1217.2567\n",
            "Epoch 297/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6983 - mae: 26.6983 - mse: 1186.2289\n",
            "Epoch 298/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8467 - mae: 26.8467 - mse: 1206.4696\n",
            "Epoch 299/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9454 - mae: 26.9454 - mse: 1207.7748\n",
            "Epoch 300/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1284 - mae: 27.1284 - mse: 1229.0818\n",
            "Epoch 301/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.4385 - mae: 26.4385 - mse: 1170.7458\n",
            "Epoch 302/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8486 - mae: 26.8486 - mse: 1202.7852\n",
            "Epoch 303/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8846 - mae: 26.8846 - mse: 1197.1433\n",
            "Epoch 304/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.5795 - mae: 26.5795 - mse: 1173.7557\n",
            "Epoch 305/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.7302 - mae: 26.7302 - mse: 1192.2191\n",
            "Epoch 306/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 26.7639 - mae: 26.7639 - mse: 1198.8381\n",
            "Epoch 307/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.8522 - mae: 26.8522 - mse: 1201.1290\n",
            "Epoch 308/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 27.1202 - mae: 27.1202 - mse: 1218.3463\n",
            "Epoch 309/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.0119 - mae: 27.0119 - mse: 1215.7188\n",
            "Epoch 310/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.0750 - mae: 27.0750 - mse: 1214.5455\n",
            "Epoch 311/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 26.6408 - mae: 26.6408 - mse: 1182.8439\n",
            "Epoch 312/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1646 - mae: 27.1646 - mse: 1231.7878\n",
            "Epoch 313/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6588 - mae: 26.6588 - mse: 1179.5979\n",
            "Epoch 314/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7217 - mae: 26.7217 - mse: 1191.3757\n",
            "Epoch 315/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7896 - mae: 26.7896 - mse: 1192.5830\n",
            "Epoch 316/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5348 - mae: 26.5348 - mse: 1172.6198\n",
            "Epoch 317/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6728 - mae: 26.6728 - mse: 1189.8066\n",
            "Epoch 318/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7267 - mae: 26.7267 - mse: 1195.7181\n",
            "Epoch 319/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5299 - mae: 26.5299 - mse: 1174.2506\n",
            "Epoch 320/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0116 - mae: 27.0116 - mse: 1211.9150\n",
            "Epoch 321/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6420 - mae: 26.6420 - mse: 1187.8788\n",
            "Epoch 322/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6856 - mae: 26.6856 - mse: 1183.5599\n",
            "Epoch 323/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9507 - mae: 26.9507 - mse: 1208.1576\n",
            "Epoch 324/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6385 - mae: 26.6385 - mse: 1185.8346\n",
            "Epoch 325/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6166 - mae: 26.6166 - mse: 1181.3828\n",
            "Epoch 326/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2061 - mae: 27.2061 - mse: 1230.9325\n",
            "Epoch 327/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7881 - mae: 26.7881 - mse: 1196.2329\n",
            "Epoch 328/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.9762 - mae: 26.9762 - mse: 1213.0516\n",
            "Epoch 329/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7750 - mae: 26.7750 - mse: 1196.0624\n",
            "Epoch 330/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5657 - mae: 26.5657 - mse: 1183.4780\n",
            "Epoch 331/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8833 - mae: 26.8833 - mse: 1204.3293\n",
            "Epoch 332/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7954 - mae: 26.7954 - mse: 1200.0178\n",
            "Epoch 333/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6580 - mae: 26.6580 - mse: 1183.1826\n",
            "Epoch 334/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6578 - mae: 26.6578 - mse: 1192.9727\n",
            "Epoch 335/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7138 - mae: 26.7138 - mse: 1193.7754\n",
            "Epoch 336/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6051 - mae: 26.6051 - mse: 1184.6273\n",
            "Epoch 337/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6522 - mae: 26.6522 - mse: 1189.2141\n",
            "Epoch 338/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6187 - mae: 26.6187 - mse: 1181.8163\n",
            "Epoch 339/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5841 - mae: 26.5841 - mse: 1178.9342\n",
            "Epoch 340/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.0722 - mae: 27.0722 - mse: 1205.5474\n",
            "Epoch 341/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6820 - mae: 26.6820 - mse: 1193.2104\n",
            "Epoch 342/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7329 - mae: 26.7329 - mse: 1194.1150\n",
            "Epoch 343/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9326 - mae: 26.9326 - mse: 1200.0281\n",
            "Epoch 344/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.3735 - mae: 26.3735 - mse: 1166.1782\n",
            "Epoch 345/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8395 - mae: 26.8395 - mse: 1195.0447\n",
            "Epoch 346/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.4894 - mae: 26.4894 - mse: 1185.9666\n",
            "Epoch 347/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6442 - mae: 26.6442 - mse: 1188.8521\n",
            "Epoch 348/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7350 - mae: 26.7350 - mse: 1197.6591\n",
            "Epoch 349/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6714 - mae: 26.6714 - mse: 1191.8198\n",
            "Epoch 350/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.8820 - mae: 26.8820 - mse: 1203.6205\n",
            "Epoch 351/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.7821 - mae: 26.7821 - mse: 1197.7301\n",
            "Epoch 352/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.7308 - mae: 26.7308 - mse: 1189.5189\n",
            "Epoch 353/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.6530 - mae: 26.6530 - mse: 1189.9535\n",
            "Epoch 354/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.3766 - mae: 26.3766 - mse: 1167.0375\n",
            "Epoch 355/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.8087 - mae: 26.8087 - mse: 1208.2975\n",
            "Epoch 356/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.5844 - mae: 26.5844 - mse: 1182.3127\n",
            "Epoch 357/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.6465 - mae: 26.6465 - mse: 1190.2614\n",
            "Epoch 358/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.9285 - mae: 26.9285 - mse: 1206.6865\n",
            "Epoch 359/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 26.8442 - mae: 26.8442 - mse: 1209.7063\n",
            "Epoch 360/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.4923 - mae: 26.4923 - mse: 1169.7811\n",
            "Epoch 361/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5175 - mae: 26.5175 - mse: 1177.8665\n",
            "Epoch 362/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6353 - mae: 26.6353 - mse: 1188.6442\n",
            "Epoch 363/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8226 - mae: 26.8226 - mse: 1204.1667\n",
            "Epoch 364/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.8197 - mae: 26.8197 - mse: 1206.2910\n",
            "Epoch 365/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5653 - mae: 26.5653 - mse: 1184.8306\n",
            "Epoch 366/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5406 - mae: 26.5406 - mse: 1185.9698\n",
            "Epoch 367/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7396 - mae: 26.7396 - mse: 1201.7595\n",
            "Epoch 368/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6796 - mae: 26.6796 - mse: 1191.8199\n",
            "Epoch 369/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.7698 - mae: 26.7698 - mse: 1212.0437\n",
            "Epoch 370/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.3294 - mae: 26.3294 - mse: 1167.3838\n",
            "Epoch 371/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7300 - mae: 26.7300 - mse: 1198.1307\n",
            "Epoch 372/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5144 - mae: 26.5144 - mse: 1188.2126\n",
            "Epoch 373/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.1253 - mae: 27.1253 - mse: 1224.6038\n",
            "Epoch 374/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7156 - mae: 26.7156 - mse: 1192.2031\n",
            "Epoch 375/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.3286 - mae: 26.3286 - mse: 1169.0187\n",
            "Epoch 376/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.2489 - mae: 26.2489 - mse: 1164.6864\n",
            "Epoch 377/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7052 - mae: 26.7052 - mse: 1198.2454\n",
            "Epoch 378/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7518 - mae: 26.7518 - mse: 1200.6479\n",
            "Epoch 379/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6909 - mae: 26.6909 - mse: 1186.9172\n",
            "Epoch 380/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.4521 - mae: 26.4521 - mse: 1173.3103\n",
            "Epoch 381/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6461 - mae: 26.6461 - mse: 1190.4978\n",
            "Epoch 382/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.4786 - mae: 26.4786 - mse: 1174.6526\n",
            "Epoch 383/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.4849 - mae: 26.4849 - mse: 1181.6378\n",
            "Epoch 384/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.3989 - mae: 26.3989 - mse: 1171.3949\n",
            "Epoch 385/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6087 - mae: 26.6087 - mse: 1195.6865\n",
            "Epoch 386/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8936 - mae: 26.8936 - mse: 1208.6490\n",
            "Epoch 387/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5524 - mae: 26.5524 - mse: 1190.1252\n",
            "Epoch 388/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6691 - mae: 26.6691 - mse: 1194.3359\n",
            "Epoch 389/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5931 - mae: 26.5931 - mse: 1193.1256\n",
            "Epoch 390/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.5054 - mae: 26.5054 - mse: 1178.8744\n",
            "Epoch 391/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.8972 - mae: 26.8972 - mse: 1213.2609\n",
            "Epoch 392/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6945 - mae: 26.6945 - mse: 1197.8339\n",
            "Epoch 393/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.4890 - mae: 26.4890 - mse: 1181.5487\n",
            "Epoch 394/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6129 - mae: 26.6129 - mse: 1192.3285\n",
            "Epoch 395/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6487 - mae: 26.6487 - mse: 1197.9839\n",
            "Epoch 396/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6279 - mae: 26.6279 - mse: 1184.9564\n",
            "Epoch 397/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.6253 - mae: 26.6253 - mse: 1190.0082\n",
            "Epoch 398/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.7016 - mae: 26.7016 - mse: 1192.7032\n",
            "Epoch 399/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.8975 - mae: 26.8975 - mse: 1204.2941\n",
            "Epoch 400/400\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.4601 - mae: 26.4601 - mse: 1178.5768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3b9c42150>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_C['(0.01, 500, 400)'] = loss"
      ],
      "metadata": {
        "id": "wObAtbCtJu7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95cb810-2822-4ed6-8d05-ec791d7d2f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 29.5365 - mae: 29.5365 - mse: 1375.1532\n",
            "Loss: [29.598207473754883, 29.598207473754883, 1376.0191650390625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you find any improvement compared to the model in Question A2?**\n",
        "\n",
        "* **Your answer:** From the comparison below, after changing the combination of learning rate, batch size, and epochs, we can see that the combination of (0.001, 1000, 400) returned the lowest mse value and, considering that loss and mae are close among all 4, the lowest mse becomes the deciding factor. Thus, (0.001, 1000, 400) is the best performing model.\n",
        "\n",
        "**(In the question C2, I changed the combination to (0.001, 500, 300), which returned a mse of mere 1261, becoming the best performing model)"
      ],
      "metadata": {
        "id": "qtsoYBrSJ9F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "performance_A"
      ],
      "metadata": {
        "id": "6EGpXA-AKEHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c55ac0-76e7-428a-9c1d-0496c7776ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(20 x 1)': [32.059452056884766, 32.059452056884766, 1678.92333984375],\n",
              " '(30 x 3)': [28.562971115112305, 28.562971115112305, 1281.6761474609375]}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section C\n",
        "print(performance_C['(0.001, 1000, 400)'])\n",
        "print(performance_C['(0.01, 1000, 200)'])\n",
        "print(performance_C['(0.01, 1000, 400)'])\n",
        "print(performance_C['(0.01, 500, 400)'])"
      ],
      "metadata": {
        "id": "kzNhdFo3Lzav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a15602-134e-4358-c37f-b22e8575addd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[28.607107162475586, 28.607107162475586, 1280.333984375]\n",
            "[28.880550384521484, 28.880550384521484, 1300.154541015625]\n",
            "[28.883014678955078, 28.883014678955078, 1301.1168212890625]\n",
            "[29.598207473754883, 29.598207473754883, 1376.0191650390625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question C2. Find any model that performs better than all the models in Question A2 and Question C1 by chainging (learning_rates, batch_size, epochs) combination only.**"
      ],
      "metadata": {
        "id": "7Ba8-ch1KmvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### [One Example for Students] ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=500, epochs=300, verbose=1)"
      ],
      "metadata": {
        "id": "SOnMD_9HMoth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc00de6-cfc8-4005-dab9-c5df8f7c0eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 65.7770 - mae: 65.7770 - mse: 6935.0376\n",
            "Epoch 2/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.6482 - mae: 62.6482 - mse: 6389.0435\n",
            "Epoch 3/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.1923 - mae: 54.1923 - mse: 4844.1606\n",
            "Epoch 4/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.8040 - mae: 49.8040 - mse: 4073.0830\n",
            "Epoch 5/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 47.1292 - mae: 47.1292 - mse: 3609.6509\n",
            "Epoch 6/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45.0039 - mae: 45.0039 - mse: 3260.9558\n",
            "Epoch 7/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.7430 - mae: 43.7430 - mse: 3070.0986\n",
            "Epoch 8/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.3433 - mae: 42.3433 - mse: 2862.2507\n",
            "Epoch 9/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.5648 - mae: 40.5648 - mse: 2658.1133\n",
            "Epoch 10/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.1579 - mae: 37.1579 - mse: 2222.5417\n",
            "Epoch 11/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.2294 - mae: 34.2294 - mse: 1918.4592\n",
            "Epoch 12/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.2992 - mae: 32.2992 - mse: 1737.1487\n",
            "Epoch 13/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.8808 - mae: 31.8808 - mse: 1676.0278\n",
            "Epoch 14/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.5408 - mae: 31.5408 - mse: 1633.5184\n",
            "Epoch 15/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.5138 - mae: 31.5138 - mse: 1640.4419\n",
            "Epoch 16/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.1421 - mae: 31.1421 - mse: 1592.8507\n",
            "Epoch 17/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.3067 - mae: 31.3067 - mse: 1598.0439\n",
            "Epoch 18/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1324 - mae: 31.1324 - mse: 1592.5507\n",
            "Epoch 19/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.1172 - mae: 31.1172 - mse: 1600.9644\n",
            "Epoch 20/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.0230 - mae: 31.0230 - mse: 1571.8529\n",
            "Epoch 21/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.6738 - mae: 30.6738 - mse: 1562.7313\n",
            "Epoch 22/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5256 - mae: 30.5256 - mse: 1564.0796\n",
            "Epoch 23/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5564 - mae: 30.5564 - mse: 1542.9382\n",
            "Epoch 24/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.3510 - mae: 30.3510 - mse: 1555.5503\n",
            "Epoch 25/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.2553 - mae: 30.2553 - mse: 1513.1891\n",
            "Epoch 26/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.3977 - mae: 30.3977 - mse: 1538.8698\n",
            "Epoch 27/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.2972 - mae: 30.2972 - mse: 1524.6763\n",
            "Epoch 28/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.7870 - mae: 29.7870 - mse: 1448.7576\n",
            "Epoch 29/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.9085 - mae: 29.9085 - mse: 1457.3368\n",
            "Epoch 30/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.8172 - mae: 29.8172 - mse: 1440.3888\n",
            "Epoch 31/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.6082 - mae: 29.6082 - mse: 1444.1859\n",
            "Epoch 32/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.6305 - mae: 29.6305 - mse: 1421.8883\n",
            "Epoch 33/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.2457 - mae: 29.2457 - mse: 1382.6490\n",
            "Epoch 34/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.3439 - mae: 29.3439 - mse: 1396.1803\n",
            "Epoch 35/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4876 - mae: 29.4876 - mse: 1399.2889\n",
            "Epoch 36/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 29.3864 - mae: 29.3864 - mse: 1413.4976\n",
            "Epoch 37/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2037 - mae: 29.2037 - mse: 1370.7087\n",
            "Epoch 38/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1987 - mae: 29.1987 - mse: 1392.5631\n",
            "Epoch 39/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8929 - mae: 28.8929 - mse: 1357.2131\n",
            "Epoch 40/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1699 - mae: 29.1699 - mse: 1379.2244\n",
            "Epoch 41/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3829 - mae: 29.3829 - mse: 1419.0632\n",
            "Epoch 42/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0655 - mae: 29.0655 - mse: 1353.7803\n",
            "Epoch 43/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2126 - mae: 29.2126 - mse: 1375.6298\n",
            "Epoch 44/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0748 - mae: 29.0748 - mse: 1380.5660\n",
            "Epoch 45/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9539 - mae: 28.9539 - mse: 1349.8649\n",
            "Epoch 46/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9884 - mae: 28.9884 - mse: 1348.0989\n",
            "Epoch 47/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.8744 - mae: 28.8744 - mse: 1349.2421\n",
            "Epoch 48/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9749 - mae: 28.9749 - mse: 1353.3455\n",
            "Epoch 49/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9972 - mae: 28.9972 - mse: 1352.0361\n",
            "Epoch 50/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.2748 - mae: 29.2748 - mse: 1390.0602\n",
            "Epoch 51/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.0269 - mae: 29.0269 - mse: 1354.8206\n",
            "Epoch 52/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9627 - mae: 28.9627 - mse: 1352.4619\n",
            "Epoch 53/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.7609 - mae: 28.7609 - mse: 1316.9261\n",
            "Epoch 54/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9430 - mae: 28.9430 - mse: 1356.9198\n",
            "Epoch 55/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0379 - mae: 29.0379 - mse: 1380.9348\n",
            "Epoch 56/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.1528 - mae: 29.1528 - mse: 1367.9412\n",
            "Epoch 57/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6987 - mae: 28.6987 - mse: 1333.6295\n",
            "Epoch 58/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.0601 - mae: 29.0601 - mse: 1357.1844\n",
            "Epoch 59/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8012 - mae: 28.8012 - mse: 1335.8082\n",
            "Epoch 60/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9153 - mae: 28.9153 - mse: 1341.2975\n",
            "Epoch 61/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6850 - mae: 28.6850 - mse: 1323.9338\n",
            "Epoch 62/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9199 - mae: 28.9199 - mse: 1343.1061\n",
            "Epoch 63/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8997 - mae: 28.8997 - mse: 1337.4899\n",
            "Epoch 64/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9060 - mae: 28.9060 - mse: 1338.2552\n",
            "Epoch 65/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5369 - mae: 28.5369 - mse: 1301.8745\n",
            "Epoch 66/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9143 - mae: 28.9143 - mse: 1350.1163\n",
            "Epoch 67/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.8766 - mae: 28.8766 - mse: 1355.7622\n",
            "Epoch 68/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.7823 - mae: 28.7823 - mse: 1327.5929\n",
            "Epoch 69/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5803 - mae: 28.5803 - mse: 1315.9208\n",
            "Epoch 70/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9917 - mae: 28.9917 - mse: 1348.9033\n",
            "Epoch 71/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9368 - mae: 28.9368 - mse: 1353.4585\n",
            "Epoch 72/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3320 - mae: 28.3320 - mse: 1290.2681\n",
            "Epoch 73/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4180 - mae: 28.4180 - mse: 1293.5669\n",
            "Epoch 74/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9931 - mae: 28.9931 - mse: 1361.3931\n",
            "Epoch 75/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7040 - mae: 28.7040 - mse: 1326.0724\n",
            "Epoch 76/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5562 - mae: 28.5562 - mse: 1317.6783\n",
            "Epoch 77/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4301 - mae: 28.4301 - mse: 1299.4862\n",
            "Epoch 78/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.9443 - mae: 28.9443 - mse: 1373.3501\n",
            "Epoch 79/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6745 - mae: 28.6745 - mse: 1327.3794\n",
            "Epoch 80/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4951 - mae: 28.4951 - mse: 1313.3984\n",
            "Epoch 81/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6760 - mae: 28.6760 - mse: 1319.0792\n",
            "Epoch 82/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.7232 - mae: 28.7232 - mse: 1327.7937\n",
            "Epoch 83/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6517 - mae: 28.6517 - mse: 1305.9596\n",
            "Epoch 84/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5631 - mae: 28.5631 - mse: 1322.3121\n",
            "Epoch 85/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4040 - mae: 28.4040 - mse: 1299.1600\n",
            "Epoch 86/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6996 - mae: 28.6996 - mse: 1332.6490\n",
            "Epoch 87/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6702 - mae: 28.6702 - mse: 1311.9346\n",
            "Epoch 88/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5405 - mae: 28.5405 - mse: 1301.1016\n",
            "Epoch 89/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9717 - mae: 28.9717 - mse: 1352.3773\n",
            "Epoch 90/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.5197 - mae: 28.5197 - mse: 1308.3409\n",
            "Epoch 91/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.6414 - mae: 28.6414 - mse: 1311.5801\n",
            "Epoch 92/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.8351 - mae: 28.8351 - mse: 1334.8425\n",
            "Epoch 93/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 28.3189 - mae: 28.3189 - mse: 1293.4839\n",
            "Epoch 94/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4887 - mae: 28.4887 - mse: 1296.6718\n",
            "Epoch 95/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6514 - mae: 28.6514 - mse: 1314.5962\n",
            "Epoch 96/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3895 - mae: 28.3895 - mse: 1297.1354\n",
            "Epoch 97/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5482 - mae: 28.5482 - mse: 1317.0192\n",
            "Epoch 98/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6253 - mae: 28.6253 - mse: 1314.4147\n",
            "Epoch 99/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3897 - mae: 28.3897 - mse: 1293.2805\n",
            "Epoch 100/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4272 - mae: 28.4272 - mse: 1298.2102\n",
            "Epoch 101/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4132 - mae: 28.4132 - mse: 1295.4258\n",
            "Epoch 102/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5232 - mae: 28.5232 - mse: 1308.2642\n",
            "Epoch 103/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3771 - mae: 28.3771 - mse: 1287.0741\n",
            "Epoch 104/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2081 - mae: 28.2081 - mse: 1275.1663\n",
            "Epoch 105/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6346 - mae: 28.6346 - mse: 1326.1313\n",
            "Epoch 106/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4247 - mae: 28.4247 - mse: 1301.0465\n",
            "Epoch 107/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3719 - mae: 28.3719 - mse: 1289.2594\n",
            "Epoch 108/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2899 - mae: 28.2899 - mse: 1295.2766\n",
            "Epoch 109/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0754 - mae: 28.0754 - mse: 1269.9646\n",
            "Epoch 110/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.8421 - mae: 28.8421 - mse: 1356.1218\n",
            "Epoch 111/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5558 - mae: 28.5558 - mse: 1306.6643\n",
            "Epoch 112/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4138 - mae: 28.4138 - mse: 1287.0383\n",
            "Epoch 113/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4426 - mae: 28.4426 - mse: 1317.8381\n",
            "Epoch 114/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6129 - mae: 28.6129 - mse: 1321.0121\n",
            "Epoch 115/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4168 - mae: 28.4168 - mse: 1292.2102\n",
            "Epoch 116/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3211 - mae: 28.3211 - mse: 1293.6597\n",
            "Epoch 117/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5279 - mae: 28.5279 - mse: 1305.7903\n",
            "Epoch 118/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1868 - mae: 28.1868 - mse: 1264.5033\n",
            "Epoch 119/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4755 - mae: 28.4755 - mse: 1301.4752\n",
            "Epoch 120/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5261 - mae: 28.5261 - mse: 1302.8168\n",
            "Epoch 121/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4711 - mae: 28.4711 - mse: 1301.4844\n",
            "Epoch 122/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1447 - mae: 28.1447 - mse: 1270.1484\n",
            "Epoch 123/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4974 - mae: 28.4974 - mse: 1311.6454\n",
            "Epoch 124/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2509 - mae: 28.2509 - mse: 1282.1981\n",
            "Epoch 125/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4955 - mae: 28.4955 - mse: 1294.8206\n",
            "Epoch 126/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3922 - mae: 28.3922 - mse: 1295.0408\n",
            "Epoch 127/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4273 - mae: 28.4273 - mse: 1299.8575\n",
            "Epoch 128/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.7925 - mae: 28.7925 - mse: 1338.5862\n",
            "Epoch 129/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4734 - mae: 28.4734 - mse: 1306.9469\n",
            "Epoch 130/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5438 - mae: 28.5438 - mse: 1326.3777\n",
            "Epoch 131/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3461 - mae: 28.3461 - mse: 1282.9816\n",
            "Epoch 132/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3325 - mae: 28.3325 - mse: 1293.8129\n",
            "Epoch 133/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.3552 - mae: 28.3552 - mse: 1290.2410\n",
            "Epoch 134/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.2376 - mae: 28.2376 - mse: 1279.2660\n",
            "Epoch 135/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.4990 - mae: 28.4990 - mse: 1294.8362\n",
            "Epoch 136/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3731 - mae: 28.3731 - mse: 1290.2167\n",
            "Epoch 137/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.4069 - mae: 28.4069 - mse: 1282.0240\n",
            "Epoch 138/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3465 - mae: 28.3465 - mse: 1284.6420\n",
            "Epoch 139/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3118 - mae: 28.3118 - mse: 1285.8372\n",
            "Epoch 140/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.4370 - mae: 28.4370 - mse: 1299.4391\n",
            "Epoch 141/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5330 - mae: 28.5330 - mse: 1302.7726\n",
            "Epoch 142/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5078 - mae: 28.5078 - mse: 1305.1106\n",
            "Epoch 143/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3588 - mae: 28.3588 - mse: 1285.9475\n",
            "Epoch 144/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2283 - mae: 28.2283 - mse: 1276.8615\n",
            "Epoch 145/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4624 - mae: 28.4624 - mse: 1304.3796\n",
            "Epoch 146/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3969 - mae: 28.3969 - mse: 1294.0719\n",
            "Epoch 147/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2537 - mae: 28.2537 - mse: 1285.9972\n",
            "Epoch 148/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2381 - mae: 28.2381 - mse: 1276.5875\n",
            "Epoch 149/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5273 - mae: 28.5273 - mse: 1290.2452\n",
            "Epoch 150/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3418 - mae: 28.3418 - mse: 1298.3839\n",
            "Epoch 151/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3723 - mae: 28.3723 - mse: 1299.1957\n",
            "Epoch 152/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2804 - mae: 28.2804 - mse: 1294.1982\n",
            "Epoch 153/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.5213 - mae: 28.5213 - mse: 1311.6066\n",
            "Epoch 154/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2516 - mae: 28.2516 - mse: 1277.0914\n",
            "Epoch 155/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4674 - mae: 28.4674 - mse: 1306.4697\n",
            "Epoch 156/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8158 - mae: 27.8158 - mse: 1250.4404\n",
            "Epoch 157/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5893 - mae: 28.5893 - mse: 1307.9274\n",
            "Epoch 158/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3172 - mae: 28.3172 - mse: 1286.6030\n",
            "Epoch 159/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3117 - mae: 28.3117 - mse: 1296.9026\n",
            "Epoch 160/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3450 - mae: 28.3450 - mse: 1288.4669\n",
            "Epoch 161/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2454 - mae: 28.2454 - mse: 1279.9235\n",
            "Epoch 162/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4461 - mae: 28.4461 - mse: 1300.7694\n",
            "Epoch 163/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1156 - mae: 28.1156 - mse: 1271.2355\n",
            "Epoch 164/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2125 - mae: 28.2125 - mse: 1272.8196\n",
            "Epoch 165/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3535 - mae: 28.3535 - mse: 1295.0660\n",
            "Epoch 166/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1433 - mae: 28.1433 - mse: 1268.3173\n",
            "Epoch 167/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3737 - mae: 28.3737 - mse: 1297.6667\n",
            "Epoch 168/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3582 - mae: 28.3582 - mse: 1281.2753\n",
            "Epoch 169/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3058 - mae: 28.3058 - mse: 1283.3131\n",
            "Epoch 170/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5836 - mae: 28.5836 - mse: 1306.8702\n",
            "Epoch 171/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3578 - mae: 28.3578 - mse: 1291.4165\n",
            "Epoch 172/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0300 - mae: 28.0300 - mse: 1268.2334\n",
            "Epoch 173/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3335 - mae: 28.3335 - mse: 1287.5775\n",
            "Epoch 174/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5265 - mae: 28.5265 - mse: 1300.7665\n",
            "Epoch 175/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4468 - mae: 28.4468 - mse: 1295.0641\n",
            "Epoch 176/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0835 - mae: 28.0835 - mse: 1271.3755\n",
            "Epoch 177/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3433 - mae: 28.3433 - mse: 1296.4075\n",
            "Epoch 178/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3253 - mae: 28.3253 - mse: 1286.8750\n",
            "Epoch 179/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4529 - mae: 28.4529 - mse: 1301.4908\n",
            "Epoch 180/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1255 - mae: 28.1255 - mse: 1264.0073\n",
            "Epoch 181/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2954 - mae: 28.2954 - mse: 1282.8599\n",
            "Epoch 182/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.5122 - mae: 28.5122 - mse: 1303.9528\n",
            "Epoch 183/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.2523 - mae: 28.2523 - mse: 1296.8647\n",
            "Epoch 184/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2178 - mae: 28.2178 - mse: 1290.1500\n",
            "Epoch 185/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 28.3631 - mae: 28.3631 - mse: 1290.5261\n",
            "Epoch 186/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.4679 - mae: 28.4679 - mse: 1306.1897\n",
            "Epoch 187/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3607 - mae: 28.3607 - mse: 1291.3977\n",
            "Epoch 188/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2967 - mae: 28.2967 - mse: 1292.5822\n",
            "Epoch 189/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3522 - mae: 28.3522 - mse: 1287.1207\n",
            "Epoch 190/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1306 - mae: 28.1306 - mse: 1267.7213\n",
            "Epoch 191/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1399 - mae: 28.1399 - mse: 1275.2332\n",
            "Epoch 192/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3333 - mae: 28.3333 - mse: 1287.9882\n",
            "Epoch 193/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0825 - mae: 28.0825 - mse: 1268.2993\n",
            "Epoch 194/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1667 - mae: 28.1667 - mse: 1262.3473\n",
            "Epoch 195/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2806 - mae: 28.2806 - mse: 1285.5226\n",
            "Epoch 196/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3180 - mae: 28.3180 - mse: 1281.4171\n",
            "Epoch 197/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5360 - mae: 28.5360 - mse: 1306.0691\n",
            "Epoch 198/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2114 - mae: 28.2114 - mse: 1277.5200\n",
            "Epoch 199/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4278 - mae: 28.4278 - mse: 1288.9380\n",
            "Epoch 200/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2524 - mae: 28.2524 - mse: 1282.1093\n",
            "Epoch 201/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2814 - mae: 28.2814 - mse: 1282.1149\n",
            "Epoch 202/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3153 - mae: 28.3153 - mse: 1295.3889\n",
            "Epoch 203/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1321 - mae: 28.1321 - mse: 1266.9146\n",
            "Epoch 204/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3700 - mae: 28.3700 - mse: 1283.8665\n",
            "Epoch 205/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3763 - mae: 28.3763 - mse: 1293.3175\n",
            "Epoch 206/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3632 - mae: 28.3632 - mse: 1288.5090\n",
            "Epoch 207/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2336 - mae: 28.2336 - mse: 1281.6779\n",
            "Epoch 208/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3206 - mae: 28.3206 - mse: 1277.3204\n",
            "Epoch 209/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0369 - mae: 28.0369 - mse: 1265.0494\n",
            "Epoch 210/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2754 - mae: 28.2754 - mse: 1284.6776\n",
            "Epoch 211/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3510 - mae: 28.3510 - mse: 1294.9751\n",
            "Epoch 212/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1207 - mae: 28.1207 - mse: 1270.0914\n",
            "Epoch 213/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9136 - mae: 27.9136 - mse: 1254.3127\n",
            "Epoch 214/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3872 - mae: 28.3872 - mse: 1284.2429\n",
            "Epoch 215/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1871 - mae: 28.1871 - mse: 1271.5385\n",
            "Epoch 216/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1149 - mae: 28.1149 - mse: 1268.9688\n",
            "Epoch 217/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3978 - mae: 28.3978 - mse: 1295.2000\n",
            "Epoch 218/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1993 - mae: 28.1993 - mse: 1280.5911\n",
            "Epoch 219/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2595 - mae: 28.2595 - mse: 1278.0939\n",
            "Epoch 220/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0005 - mae: 28.0005 - mse: 1265.6356\n",
            "Epoch 221/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3169 - mae: 28.3169 - mse: 1291.4584\n",
            "Epoch 222/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4188 - mae: 28.4188 - mse: 1283.3212\n",
            "Epoch 223/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3900 - mae: 28.3900 - mse: 1290.1012\n",
            "Epoch 224/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.2226 - mae: 28.2226 - mse: 1282.4886\n",
            "Epoch 225/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9517 - mae: 27.9517 - mse: 1264.4896\n",
            "Epoch 226/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2969 - mae: 28.2969 - mse: 1278.7565\n",
            "Epoch 227/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 28.0125 - mae: 28.0125 - mse: 1254.1552\n",
            "Epoch 228/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.2386 - mae: 28.2386 - mse: 1282.8057\n",
            "Epoch 229/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.0778 - mae: 28.0778 - mse: 1269.6998\n",
            "Epoch 230/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0410 - mae: 28.0410 - mse: 1250.0679\n",
            "Epoch 231/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1192 - mae: 28.1192 - mse: 1264.2927\n",
            "Epoch 232/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.1658 - mae: 28.1658 - mse: 1275.9803\n",
            "Epoch 233/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.0096 - mae: 28.0096 - mse: 1262.4110\n",
            "Epoch 234/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2365 - mae: 28.2365 - mse: 1280.3927\n",
            "Epoch 235/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1322 - mae: 28.1322 - mse: 1260.3237\n",
            "Epoch 236/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3051 - mae: 28.3051 - mse: 1273.3306\n",
            "Epoch 237/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2251 - mae: 28.2251 - mse: 1279.3602\n",
            "Epoch 238/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1620 - mae: 28.1620 - mse: 1272.1958\n",
            "Epoch 239/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2889 - mae: 28.2889 - mse: 1273.9122\n",
            "Epoch 240/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2568 - mae: 28.2568 - mse: 1282.5668\n",
            "Epoch 241/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0815 - mae: 28.0815 - mse: 1267.1044\n",
            "Epoch 242/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2038 - mae: 28.2038 - mse: 1271.2317\n",
            "Epoch 243/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1818 - mae: 28.1818 - mse: 1272.0605\n",
            "Epoch 244/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1242 - mae: 28.1242 - mse: 1268.3184\n",
            "Epoch 245/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1709 - mae: 28.1709 - mse: 1276.5486\n",
            "Epoch 246/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.4051 - mae: 28.4051 - mse: 1289.7837\n",
            "Epoch 247/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3074 - mae: 28.3074 - mse: 1280.1376\n",
            "Epoch 248/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8795 - mae: 27.8795 - mse: 1239.1385\n",
            "Epoch 249/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2132 - mae: 28.2132 - mse: 1275.7971\n",
            "Epoch 250/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1824 - mae: 28.1824 - mse: 1270.2227\n",
            "Epoch 251/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2755 - mae: 28.2755 - mse: 1284.2678\n",
            "Epoch 252/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0909 - mae: 28.0909 - mse: 1267.8685\n",
            "Epoch 253/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2720 - mae: 28.2720 - mse: 1271.4327\n",
            "Epoch 254/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2464 - mae: 28.2464 - mse: 1263.4519\n",
            "Epoch 255/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2327 - mae: 28.2327 - mse: 1276.6008\n",
            "Epoch 256/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1341 - mae: 28.1341 - mse: 1269.7960\n",
            "Epoch 257/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2113 - mae: 28.2113 - mse: 1284.5752\n",
            "Epoch 258/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3783 - mae: 28.3783 - mse: 1296.9225\n",
            "Epoch 259/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1696 - mae: 28.1696 - mse: 1274.1982\n",
            "Epoch 260/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1986 - mae: 28.1986 - mse: 1274.6459\n",
            "Epoch 261/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2476 - mae: 28.2476 - mse: 1274.8822\n",
            "Epoch 262/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.4625 - mae: 28.4625 - mse: 1299.4227\n",
            "Epoch 263/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0871 - mae: 28.0871 - mse: 1269.8079\n",
            "Epoch 264/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0843 - mae: 28.0843 - mse: 1260.1560\n",
            "Epoch 265/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0996 - mae: 28.0996 - mse: 1265.0781\n",
            "Epoch 266/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9673 - mae: 27.9673 - mse: 1254.4060\n",
            "Epoch 267/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.3809 - mae: 28.3809 - mse: 1287.8619\n",
            "Epoch 268/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0684 - mae: 28.0684 - mse: 1267.4528\n",
            "Epoch 269/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1157 - mae: 28.1157 - mse: 1269.9528\n",
            "Epoch 270/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2534 - mae: 28.2534 - mse: 1272.4600\n",
            "Epoch 271/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2435 - mae: 28.2435 - mse: 1274.2614\n",
            "Epoch 272/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2960 - mae: 28.2960 - mse: 1276.4517\n",
            "Epoch 273/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1254 - mae: 28.1254 - mse: 1269.9291\n",
            "Epoch 274/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2624 - mae: 28.2624 - mse: 1276.7373\n",
            "Epoch 275/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.8578 - mae: 27.8578 - mse: 1241.1145\n",
            "Epoch 276/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.8066 - mae: 27.8066 - mse: 1243.2188\n",
            "Epoch 277/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3996 - mae: 28.3996 - mse: 1302.4922\n",
            "Epoch 278/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3245 - mae: 28.3245 - mse: 1282.7010\n",
            "Epoch 279/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.2452 - mae: 28.2452 - mse: 1286.2537\n",
            "Epoch 280/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 28.2409 - mae: 28.2409 - mse: 1283.7637\n",
            "Epoch 281/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.0993 - mae: 28.0993 - mse: 1270.8181\n",
            "Epoch 282/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 27.9308 - mae: 27.9308 - mse: 1262.2145\n",
            "Epoch 283/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.9245 - mae: 27.9245 - mse: 1259.3146\n",
            "Epoch 284/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.0370 - mae: 28.0370 - mse: 1262.6477\n",
            "Epoch 285/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1972 - mae: 28.1972 - mse: 1282.4290\n",
            "Epoch 286/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8807 - mae: 27.8807 - mse: 1243.2731\n",
            "Epoch 287/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0927 - mae: 28.0927 - mse: 1264.7239\n",
            "Epoch 288/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1117 - mae: 28.1117 - mse: 1271.5710\n",
            "Epoch 289/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.2323 - mae: 28.2323 - mse: 1283.0199\n",
            "Epoch 290/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7975 - mae: 27.7975 - mse: 1242.2717\n",
            "Epoch 291/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1141 - mae: 28.1141 - mse: 1263.4427\n",
            "Epoch 292/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1745 - mae: 28.1745 - mse: 1266.8536\n",
            "Epoch 293/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2470 - mae: 28.2470 - mse: 1277.3053\n",
            "Epoch 294/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.1421 - mae: 28.1421 - mse: 1273.1305\n",
            "Epoch 295/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1231 - mae: 28.1231 - mse: 1276.0947\n",
            "Epoch 296/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9424 - mae: 27.9424 - mse: 1247.2188\n",
            "Epoch 297/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7702 - mae: 27.7702 - mse: 1241.2885\n",
            "Epoch 298/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.9670 - mae: 27.9670 - mse: 1256.6399\n",
            "Epoch 299/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.3941 - mae: 28.3941 - mse: 1283.4695\n",
            "Epoch 300/300\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.8997 - mae: 27.8997 - mse: 1247.9180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3aded75d0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_C['(0.001, 500, 300)'] = loss"
      ],
      "metadata": {
        "id": "wZqqvOPYMmDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84ced62-5449-4e3e-ec81-7ddc64744787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.3161 - mae: 28.3161 - mse: 1261.6375\n",
            "Loss: [28.4807071685791, 28.4807071685791, 1269.1785888671875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "performance_A"
      ],
      "metadata": {
        "id": "3z2pX6VUMhFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc188a57-9156-4480-c51a-c4b5c5e6fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(20 x 1)': [32.059452056884766, 32.059452056884766, 1678.92333984375],\n",
              " '(30 x 3)': [28.562971115112305, 28.562971115112305, 1281.6761474609375]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section C\n",
        "performance_C"
      ],
      "metadata": {
        "id": "9nNAIXSCMkwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6dcc07-852d-4b6c-8458-43ea826393eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(0.01, 1000, 200)': [28.880550384521484,\n",
              "  28.880550384521484,\n",
              "  1300.154541015625],\n",
              " '(0.001, 1000, 400)': [28.607107162475586,\n",
              "  28.607107162475586,\n",
              "  1280.333984375],\n",
              " '(0.01, 1000, 400)': [28.883014678955078,\n",
              "  28.883014678955078,\n",
              "  1301.1168212890625],\n",
              " '(0.01, 500, 400)': [29.598207473754883,\n",
              "  29.598207473754883,\n",
              "  1376.0191650390625],\n",
              " '(0.001, 500, 400)': [28.600372314453125,\n",
              "  28.600372314453125,\n",
              "  1281.93505859375],\n",
              " '(0.001, 500, 300)': [28.4807071685791, 28.4807071685791, 1269.1785888671875]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **D. Dropout Rates (25 pts)**"
      ],
      "metadata": {
        "id": "gOhSgCx48Xhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question D1. You're going to make only one change to the model in Question A2. Please include dropout rates of 10% for each hidden layer. Do you find any improvement compared to the model in Question A2?**"
      ],
      "metadata": {
        "id": "9vecduImSmlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.1),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.1),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.1),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "bdOnJn2H8joZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d01893d-cdf1-4cef-93fc-45e31f9c5034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 65.3223 - mae: 65.3224 - mse: 6827.4106\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 65.0090 - mae: 65.0090 - mse: 6801.2148\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 63.2987 - mae: 63.2987 - mse: 6471.9336\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 58.0690 - mae: 58.0690 - mse: 5535.9028\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.6868 - mae: 52.6868 - mse: 4566.3818\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 50.4209 - mae: 50.4209 - mse: 4175.5791\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 48.9200 - mae: 48.9200 - mse: 3937.6699\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 47.3397 - mae: 47.3397 - mse: 3704.9316\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 46.1858 - mae: 46.1858 - mse: 3458.8660\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 46.0897 - mae: 46.0897 - mse: 3451.7944\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 45.7000 - mae: 45.7000 - mse: 3392.3181\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 44.4854 - mae: 44.4854 - mse: 3152.2549\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 44.2807 - mae: 44.2807 - mse: 3121.5659\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 43.5031 - mae: 43.5031 - mse: 3025.0833\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 42.3999 - mae: 42.3999 - mse: 2920.5854\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 40.8773 - mae: 40.8773 - mse: 2693.9915\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 39.3383 - mae: 39.3383 - mse: 2539.5967\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 37.8220 - mae: 37.8220 - mse: 2380.8726\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 36.1914 - mae: 36.1914 - mse: 2164.3889\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 35.5426 - mae: 35.5426 - mse: 2092.6521\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.9521 - mae: 34.9521 - mse: 2027.3444\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 34.6554 - mae: 34.6554 - mse: 1980.1096\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 34.4400 - mae: 34.4400 - mse: 1966.0663\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.0171 - mae: 34.0171 - mse: 1907.5449\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.2006 - mae: 34.2006 - mse: 1976.9092\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.0490 - mae: 34.0490 - mse: 1908.6937\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.5047 - mae: 33.5047 - mse: 1889.0498\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.6676 - mae: 33.6676 - mse: 1859.8396\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.7126 - mae: 33.7126 - mse: 1868.4990\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.0552 - mae: 34.0552 - mse: 1931.6644\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.4445 - mae: 33.4445 - mse: 1862.3774\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.6409 - mae: 33.6409 - mse: 1849.3064\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.6432 - mae: 33.6432 - mse: 1866.8643\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.4204 - mae: 33.4204 - mse: 1853.8210\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.2249 - mae: 33.2249 - mse: 1812.6215\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.3911 - mae: 33.3911 - mse: 1832.7721\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.0463 - mae: 33.0463 - mse: 1793.7020\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.1437 - mae: 33.1437 - mse: 1812.4365\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.9515 - mae: 32.9515 - mse: 1818.4697\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.9692 - mae: 32.9692 - mse: 1786.6848\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.8065 - mae: 32.8065 - mse: 1768.1091\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.1208 - mae: 33.1208 - mse: 1784.2987\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.9112 - mae: 32.9112 - mse: 1771.8352\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.7022 - mae: 32.7022 - mse: 1747.4307\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.7889 - mae: 32.7889 - mse: 1765.8073\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.7766 - mae: 32.7766 - mse: 1738.7832\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.4181 - mae: 32.4181 - mse: 1688.3787\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.8711 - mae: 32.8711 - mse: 1778.4576\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.5451 - mae: 32.5451 - mse: 1737.0914\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2340 - mae: 32.2340 - mse: 1694.0625\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.4199 - mae: 32.4199 - mse: 1714.4777\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.3924 - mae: 32.3924 - mse: 1694.5574\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0244 - mae: 32.0244 - mse: 1669.2314\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2123 - mae: 32.2123 - mse: 1684.7639\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 32.0515 - mae: 32.0515 - mse: 1655.3228\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.0267 - mae: 32.0267 - mse: 1669.2489\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8830 - mae: 31.8830 - mse: 1638.2863\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8225 - mae: 31.8225 - mse: 1637.0640\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.1624 - mae: 32.1624 - mse: 1669.4071\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8045 - mae: 31.8045 - mse: 1634.1779\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9129 - mae: 31.9129 - mse: 1645.6705\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6732 - mae: 31.6732 - mse: 1627.5371\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0285 - mae: 32.0285 - mse: 1653.0746\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.5610 - mae: 31.5610 - mse: 1605.9900\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8723 - mae: 31.8723 - mse: 1631.8254\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.8725 - mae: 31.8725 - mse: 1630.3605\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6554 - mae: 31.6554 - mse: 1605.5702\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.7514 - mae: 31.7514 - mse: 1649.8204\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.7475 - mae: 31.7475 - mse: 1632.4281\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.4825 - mae: 31.4825 - mse: 1601.0914\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.5153 - mae: 31.5153 - mse: 1601.8730\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.6577 - mae: 31.6577 - mse: 1638.7017\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.5468 - mae: 31.5468 - mse: 1607.7622\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.7498 - mae: 31.7498 - mse: 1628.4606\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.8443 - mae: 31.8443 - mse: 1641.7628\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.4724 - mae: 31.4724 - mse: 1594.9354\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.5557 - mae: 31.5557 - mse: 1621.6016\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 31.3894 - mae: 31.3894 - mse: 1601.6398\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 31.4099 - mae: 31.4099 - mse: 1595.3728\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.7709 - mae: 31.7709 - mse: 1623.5447\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2164 - mae: 31.2164 - mse: 1562.9426\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.4640 - mae: 31.4640 - mse: 1603.4698\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.5822 - mae: 31.5822 - mse: 1614.2455\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4105 - mae: 31.4105 - mse: 1590.9810\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3056 - mae: 31.3056 - mse: 1589.8337\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3881 - mae: 31.3881 - mse: 1583.2040\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.4809 - mae: 31.4809 - mse: 1573.8147\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1211 - mae: 31.1211 - mse: 1556.5034\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4564 - mae: 31.4564 - mse: 1583.4583\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4141 - mae: 31.4141 - mse: 1595.4600\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0867 - mae: 31.0867 - mse: 1543.5537\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2320 - mae: 31.2320 - mse: 1571.5519\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.6828 - mae: 31.6828 - mse: 1611.2266\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2921 - mae: 31.2921 - mse: 1592.3787\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1970 - mae: 31.1970 - mse: 1579.9264\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2356 - mae: 31.2356 - mse: 1572.4634\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3385 - mae: 31.3385 - mse: 1585.1174\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3406 - mae: 31.3406 - mse: 1595.9587\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.2260 - mae: 31.2260 - mse: 1574.6475\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.3225 - mae: 31.3225 - mse: 1573.8027\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4127 - mae: 31.4127 - mse: 1600.7606\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2010 - mae: 31.2010 - mse: 1552.1985\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0369 - mae: 31.0369 - mse: 1551.1946\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9863 - mae: 30.9863 - mse: 1549.5537\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3535 - mae: 31.3535 - mse: 1581.2689\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0818 - mae: 31.0818 - mse: 1558.9769\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1213 - mae: 31.1213 - mse: 1578.2683\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8559 - mae: 30.8559 - mse: 1533.0592\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9081 - mae: 30.9081 - mse: 1555.7231\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2039 - mae: 31.2039 - mse: 1567.4581\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3874 - mae: 31.3874 - mse: 1603.3590\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0276 - mae: 31.0276 - mse: 1563.9764\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2184 - mae: 31.2184 - mse: 1578.5880\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.9391 - mae: 30.9391 - mse: 1529.7218\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0626 - mae: 31.0626 - mse: 1566.6292\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.1053 - mae: 31.1053 - mse: 1556.3785\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.0165 - mae: 31.0165 - mse: 1556.6486\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.2326 - mae: 31.2326 - mse: 1554.4991\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.1102 - mae: 31.1102 - mse: 1554.4574\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.9002 - mae: 30.9002 - mse: 1533.5826\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.0390 - mae: 31.0390 - mse: 1559.5028\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 30.8559 - mae: 30.8559 - mse: 1537.8055\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 30.6839 - mae: 30.6839 - mse: 1516.8826\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 31.0456 - mae: 31.0456 - mse: 1541.9531\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.8991 - mae: 30.8991 - mse: 1543.0485\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 31.0987 - mae: 31.0987 - mse: 1558.9602\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 30.8735 - mae: 30.8735 - mse: 1537.0199\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.7572 - mae: 30.7572 - mse: 1539.0950\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.7543 - mae: 30.7543 - mse: 1520.3428\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.9761 - mae: 30.9761 - mse: 1564.5039\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.9868 - mae: 30.9868 - mse: 1534.3483\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.9594 - mae: 30.9594 - mse: 1555.6125\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.8491 - mae: 30.8491 - mse: 1523.5356\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.1106 - mae: 31.1106 - mse: 1557.1213\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.0171 - mae: 31.0171 - mse: 1548.0579\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7900 - mae: 30.7900 - mse: 1530.3461\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8989 - mae: 30.8989 - mse: 1532.8116\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.8027 - mae: 30.8027 - mse: 1531.4983\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.8322 - mae: 30.8322 - mse: 1544.9207\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6400 - mae: 30.6400 - mse: 1520.3485\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7700 - mae: 30.7700 - mse: 1544.5903\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7417 - mae: 30.7417 - mse: 1520.0490\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.8105 - mae: 30.8105 - mse: 1536.9246\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.9957 - mae: 30.9957 - mse: 1561.6172\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8536 - mae: 30.8536 - mse: 1527.6558\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7135 - mae: 30.7135 - mse: 1535.1028\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7035 - mae: 30.7035 - mse: 1531.1801\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.8009 - mae: 30.8009 - mse: 1530.4349\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0944 - mae: 31.0944 - mse: 1568.0646\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.6529 - mae: 30.6529 - mse: 1506.9835\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7936 - mae: 30.7936 - mse: 1534.8917\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5715 - mae: 30.5715 - mse: 1499.2260\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.4886 - mae: 30.4886 - mse: 1499.3265\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7607 - mae: 30.7607 - mse: 1519.9498\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7547 - mae: 30.7547 - mse: 1520.8629\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9494 - mae: 30.9494 - mse: 1532.2021\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5251 - mae: 30.5251 - mse: 1500.9481\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5700 - mae: 30.5700 - mse: 1517.8311\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7763 - mae: 30.7763 - mse: 1550.2760\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.4628 - mae: 30.4628 - mse: 1496.6289\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8339 - mae: 30.8339 - mse: 1533.1659\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7261 - mae: 30.7261 - mse: 1520.2633\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8239 - mae: 30.8239 - mse: 1533.7292\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.5131 - mae: 30.5131 - mse: 1495.9423\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0025 - mae: 31.0025 - mse: 1541.1840\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8627 - mae: 30.8627 - mse: 1528.4438\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8467 - mae: 30.8467 - mse: 1539.4628\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4901 - mae: 30.4901 - mse: 1493.0415\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7561 - mae: 30.7561 - mse: 1531.5714\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4767 - mae: 30.4767 - mse: 1508.5872\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7106 - mae: 30.7106 - mse: 1529.7740\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.5640 - mae: 30.5640 - mse: 1507.8640\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.5861 - mae: 30.5861 - mse: 1504.7592\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.6536 - mae: 30.6536 - mse: 1520.7198\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.6206 - mae: 30.6206 - mse: 1516.5706\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.6156 - mae: 30.6156 - mse: 1503.4132\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.4084 - mae: 30.4084 - mse: 1504.6353\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.8608 - mae: 30.8608 - mse: 1518.8213\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.5299 - mae: 30.5299 - mse: 1496.6067\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 30.7179 - mae: 30.7179 - mse: 1509.3245\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.7122 - mae: 30.7122 - mse: 1523.5206\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 30.7426 - mae: 30.7426 - mse: 1510.2854\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7528 - mae: 30.7528 - mse: 1522.7905\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.4606 - mae: 30.4606 - mse: 1485.5516\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.7941 - mae: 30.7941 - mse: 1543.3687\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6102 - mae: 30.6102 - mse: 1497.9763\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.0979 - mae: 30.0979 - mse: 1477.1217\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.6463 - mae: 30.6463 - mse: 1490.9906\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5474 - mae: 30.5474 - mse: 1494.4155\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5937 - mae: 30.5937 - mse: 1518.4912\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.6171 - mae: 30.6171 - mse: 1515.4633\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.4597 - mae: 30.4597 - mse: 1506.3835\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6330 - mae: 30.6330 - mse: 1511.1331\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.7297 - mae: 30.7297 - mse: 1518.6255\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.6028 - mae: 30.6028 - mse: 1498.2214\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.9440 - mae: 30.9440 - mse: 1542.0999\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4304 - mae: 30.4304 - mse: 1509.3839\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6536 - mae: 30.6536 - mse: 1510.6866\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5339 - mae: 30.5339 - mse: 1501.9336\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.5363 - mae: 30.5363 - mse: 1505.5760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3c350fb50>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_D = {}\n",
        "performance_D['10%/10%/10%'] = loss"
      ],
      "metadata": {
        "id": "HiQiQcoHTP5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74f3a71-1a0d-4c6a-b9bd-194668d2747b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.9474 - mae: 28.9474 - mse: 1342.6803\n",
            "Loss: [29.063486099243164, 29.063486099243164, 1334.5682373046875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "print(performance_A['(30 x 3)'])\n",
        "print(performance_D['10%/10%/10%'])"
      ],
      "metadata": {
        "id": "S5a-4CKJSnzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1e634a-bf12-4446-ed2c-e59fdabefd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[28.562971115112305, 28.562971115112305, 1281.6761474609375]\n",
            "[29.063486099243164, 29.063486099243164, 1334.5682373046875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you find any improvement compared to the model in Question A2?**\n",
        "\n",
        "* **Your answer:** [To be updated]"
      ],
      "metadata": {
        "id": "LRbGYhDcSnJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question D2. Try different combinations of dropout rates for hidden layers: (0%, 10%, 0%), (5%, 5%, 5%), (0%, 5%, 0%). Do you find any improvement compared to the models in Question A2 and Question D1?**"
      ],
      "metadata": {
        "id": "XAjooLTjTo_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) (0%, 10%, 0%)"
      ],
      "metadata": {
        "id": "tO1nvkvqUFw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.1),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "yzY8_B7FTol9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33aa7c5-aec4-4c07-c3e6-866bbc827960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 65.7564 - mae: 65.7564 - mse: 6922.7852\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 65.7010 - mae: 65.7010 - mse: 6926.1621\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 64.6354 - mae: 64.6354 - mse: 6726.7544\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.2646 - mae: 61.2646 - mse: 6091.3638\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 55.1359 - mae: 55.1359 - mse: 4985.9121\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.0472 - mae: 52.0472 - mse: 4489.1016\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.0626 - mae: 51.0626 - mse: 4360.7749\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.7752 - mae: 48.7752 - mse: 3967.6477\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.7639 - mae: 46.7639 - mse: 3611.3540\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.3527 - mae: 45.3527 - mse: 3329.4429\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.9720 - mae: 44.9720 - mse: 3261.8340\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.1521 - mae: 44.1521 - mse: 3107.1736\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.9425 - mae: 43.9425 - mse: 3102.4373\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.2841 - mae: 43.2841 - mse: 3004.5701\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.3446 - mae: 42.3446 - mse: 2864.2961\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.9079 - mae: 40.9079 - mse: 2638.0430\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.8046 - mae: 39.8046 - mse: 2550.1160\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 38.4765 - mae: 38.4765 - mse: 2381.7366\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 37.2386 - mae: 37.2386 - mse: 2243.1621\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35.3317 - mae: 35.3317 - mse: 2054.7422\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.8547 - mae: 34.8547 - mse: 1988.5095\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.1335 - mae: 34.1335 - mse: 1920.2936\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 33.1274 - mae: 33.1274 - mse: 1793.6228\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.0247 - mae: 33.0247 - mse: 1795.3544\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 32.8721 - mae: 32.8721 - mse: 1779.4451\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.6912 - mae: 32.6912 - mse: 1778.7107\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.1057 - mae: 32.1057 - mse: 1709.5952\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.3409 - mae: 32.3409 - mse: 1717.5426\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.2206 - mae: 32.2206 - mse: 1700.1877\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0044 - mae: 32.0044 - mse: 1715.8251\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1153 - mae: 32.1153 - mse: 1712.5891\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6013 - mae: 31.6013 - mse: 1674.1949\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6648 - mae: 31.6648 - mse: 1628.1986\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8244 - mae: 31.8244 - mse: 1672.6367\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7508 - mae: 31.7508 - mse: 1638.1543\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4242 - mae: 31.4242 - mse: 1629.6084\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0479 - mae: 31.0479 - mse: 1564.4971\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.3065 - mae: 31.3065 - mse: 1576.3896\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3589 - mae: 31.3589 - mse: 1611.5737\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4456 - mae: 31.4456 - mse: 1619.9519\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2202 - mae: 31.2202 - mse: 1596.3853\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8080 - mae: 30.8080 - mse: 1533.1782\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.8617 - mae: 30.8617 - mse: 1556.6411\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7452 - mae: 30.7452 - mse: 1523.2555\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7896 - mae: 30.7896 - mse: 1534.3486\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.5995 - mae: 30.5995 - mse: 1519.9475\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8037 - mae: 30.8037 - mse: 1532.8967\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6146 - mae: 30.6146 - mse: 1513.6932\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.2681 - mae: 30.2681 - mse: 1471.6543\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5181 - mae: 30.5181 - mse: 1510.7035\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.5189 - mae: 30.5189 - mse: 1499.4156\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1061 - mae: 30.1061 - mse: 1468.4474\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1517 - mae: 30.1517 - mse: 1462.4451\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0676 - mae: 30.0676 - mse: 1464.6355\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.2470 - mae: 30.2470 - mse: 1505.6763\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3118 - mae: 30.3118 - mse: 1473.9395\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.4315 - mae: 30.4315 - mse: 1490.9514\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0550 - mae: 30.0550 - mse: 1450.0896\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1458 - mae: 30.1458 - mse: 1459.9286\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0384 - mae: 30.0384 - mse: 1446.9039\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1168 - mae: 30.1168 - mse: 1449.1901\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0485 - mae: 30.0485 - mse: 1448.7561\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1989 - mae: 30.1989 - mse: 1458.6031\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9247 - mae: 29.9247 - mse: 1450.2374\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0081 - mae: 30.0081 - mse: 1442.9210\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9320 - mae: 29.9320 - mse: 1434.8075\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9699 - mae: 29.9699 - mse: 1443.2017\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9804 - mae: 29.9804 - mse: 1450.0059\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9004 - mae: 29.9004 - mse: 1433.1550\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8015 - mae: 29.8015 - mse: 1429.0537\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9033 - mae: 29.9033 - mse: 1425.6016\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9707 - mae: 29.9707 - mse: 1429.5067\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6132 - mae: 29.6132 - mse: 1401.7888\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8598 - mae: 29.8598 - mse: 1428.7104\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7015 - mae: 29.7015 - mse: 1420.2563\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8419 - mae: 29.8419 - mse: 1426.2600\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7502 - mae: 29.7502 - mse: 1424.2954\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6997 - mae: 29.6997 - mse: 1409.8556\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6442 - mae: 29.6442 - mse: 1412.9418\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6235 - mae: 29.6235 - mse: 1403.6858\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8539 - mae: 29.8539 - mse: 1435.8319\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5590 - mae: 29.5590 - mse: 1401.3420\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.8037 - mae: 29.8037 - mse: 1417.9111\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.6804 - mae: 29.6804 - mse: 1405.3202\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4322 - mae: 29.4322 - mse: 1387.7281\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1184 - mae: 30.1184 - mse: 1456.8464\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.5873 - mae: 29.5873 - mse: 1412.1001\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.5135 - mae: 29.5135 - mse: 1398.2660\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.5485 - mae: 29.5485 - mse: 1405.7733\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.6701 - mae: 29.6701 - mse: 1417.4607\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.6981 - mae: 29.6981 - mse: 1416.1302\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.6857 - mae: 29.6857 - mse: 1409.4949\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.4892 - mae: 29.4892 - mse: 1377.5100\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.6854 - mae: 29.6854 - mse: 1399.1677\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.5052 - mae: 29.5052 - mse: 1397.0521\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4782 - mae: 29.4782 - mse: 1388.7527\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5111 - mae: 29.5111 - mse: 1392.0166\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4623 - mae: 29.4623 - mse: 1383.5803\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3249 - mae: 29.3249 - mse: 1387.6554\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4132 - mae: 29.4132 - mse: 1387.1030\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3165 - mae: 29.3165 - mse: 1376.0354\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5946 - mae: 29.5946 - mse: 1408.6938\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5510 - mae: 29.5510 - mse: 1394.6289\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6223 - mae: 29.6223 - mse: 1395.2731\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2977 - mae: 29.2977 - mse: 1369.8917\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7697 - mae: 29.7697 - mse: 1406.5570\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5398 - mae: 29.5398 - mse: 1394.0693\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5282 - mae: 29.5282 - mse: 1394.9293\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7613 - mae: 29.7613 - mse: 1406.7356\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3840 - mae: 29.3840 - mse: 1375.8665\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2837 - mae: 29.2837 - mse: 1378.7946\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2200 - mae: 29.2200 - mse: 1366.6951\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5110 - mae: 29.5110 - mse: 1402.9943\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4145 - mae: 29.4145 - mse: 1370.3835\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3373 - mae: 29.3373 - mse: 1373.9371\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3240 - mae: 29.3240 - mse: 1389.0859\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5657 - mae: 29.5657 - mse: 1394.6591\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5021 - mae: 29.5021 - mse: 1394.4595\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5197 - mae: 29.5197 - mse: 1411.9922\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1816 - mae: 29.1816 - mse: 1378.6536\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4973 - mae: 29.4973 - mse: 1390.3917\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1978 - mae: 29.1978 - mse: 1362.9260\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3881 - mae: 29.3881 - mse: 1400.4915\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2825 - mae: 29.2825 - mse: 1384.8895\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4547 - mae: 29.4547 - mse: 1410.2242\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3746 - mae: 29.3746 - mse: 1378.3074\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0348 - mae: 29.0348 - mse: 1350.9613\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1910 - mae: 29.1910 - mse: 1367.7472\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1776 - mae: 29.1776 - mse: 1371.3306\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2638 - mae: 29.2638 - mse: 1375.4211\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1547 - mae: 29.1547 - mse: 1368.4092\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4956 - mae: 29.4956 - mse: 1399.0648\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4436 - mae: 29.4436 - mse: 1407.0334\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3451 - mae: 29.3451 - mse: 1381.6060\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3313 - mae: 29.3313 - mse: 1385.8014\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3479 - mae: 29.3479 - mse: 1377.3743\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4261 - mae: 29.4261 - mse: 1371.5529\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.9859 - mae: 28.9859 - mse: 1346.9148\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3461 - mae: 29.3461 - mse: 1392.0084\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0276 - mae: 29.0276 - mse: 1342.4110\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0331 - mae: 29.0331 - mse: 1350.0807\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2520 - mae: 29.2520 - mse: 1367.3385\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1940 - mae: 29.1940 - mse: 1373.3882\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9118 - mae: 28.9118 - mse: 1338.8152\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0435 - mae: 29.0435 - mse: 1361.0701\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3318 - mae: 29.3318 - mse: 1378.9021\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1876 - mae: 29.1876 - mse: 1375.1733\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1915 - mae: 29.1915 - mse: 1360.9852\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0642 - mae: 29.0642 - mse: 1365.8319\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3564 - mae: 29.3564 - mse: 1372.6027\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3385 - mae: 29.3385 - mse: 1395.3287\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0798 - mae: 29.0798 - mse: 1354.1858\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1055 - mae: 29.1055 - mse: 1371.8129\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.1915 - mae: 29.1915 - mse: 1358.8512\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9330 - mae: 28.9330 - mse: 1354.4382\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.0901 - mae: 29.0901 - mse: 1389.7135\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4105 - mae: 29.4105 - mse: 1382.8961\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.0125 - mae: 29.0125 - mse: 1347.0128\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9316 - mae: 28.9316 - mse: 1346.5310\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.1788 - mae: 29.1788 - mse: 1369.0413\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.0929 - mae: 29.0929 - mse: 1359.1078\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.2884 - mae: 29.2884 - mse: 1374.4929\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9545 - mae: 28.9545 - mse: 1353.7670\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.2532 - mae: 29.2532 - mse: 1367.1992\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.1416 - mae: 29.1416 - mse: 1375.5597\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9711 - mae: 28.9711 - mse: 1352.4800\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.0306 - mae: 29.0306 - mse: 1357.7866\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9570 - mae: 28.9570 - mse: 1342.3657\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0786 - mae: 29.0786 - mse: 1355.9121\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8684 - mae: 28.8684 - mse: 1334.7499\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1545 - mae: 29.1545 - mse: 1353.8529\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0971 - mae: 29.0971 - mse: 1351.9757\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1922 - mae: 29.1922 - mse: 1369.1240\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0739 - mae: 29.0739 - mse: 1358.6263\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1701 - mae: 29.1701 - mse: 1365.6234\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1387 - mae: 29.1387 - mse: 1351.3774\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0554 - mae: 29.0554 - mse: 1362.6171\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1013 - mae: 29.1013 - mse: 1362.4119\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9264 - mae: 28.9264 - mse: 1344.0121\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0988 - mae: 29.0988 - mse: 1353.7528\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0930 - mae: 29.0930 - mse: 1362.1960\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1188 - mae: 29.1188 - mse: 1367.7220\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0675 - mae: 29.0675 - mse: 1362.9141\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0716 - mae: 29.0716 - mse: 1367.9026\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0936 - mae: 29.0936 - mse: 1352.6881\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0060 - mae: 29.0060 - mse: 1350.8414\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8822 - mae: 28.8822 - mse: 1345.6377\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8370 - mae: 28.8370 - mse: 1336.8569\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9710 - mae: 28.9710 - mse: 1351.8318\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.1068 - mae: 29.1068 - mse: 1360.5382\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28.8466 - mae: 28.8466 - mse: 1335.6583\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0760 - mae: 29.0760 - mse: 1351.9635\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9753 - mae: 28.9753 - mse: 1349.6182\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.3032 - mae: 29.3032 - mse: 1382.5908\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 29.0003 - mae: 29.0003 - mse: 1342.6003\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 28.9002 - mae: 28.9002 - mse: 1334.2172\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 28.8676 - mae: 28.8676 - mse: 1343.1227\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.0342 - mae: 29.0342 - mse: 1350.1139\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 28.7215 - mae: 28.7215 - mse: 1313.3292\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 29.0651 - mae: 29.0651 - mse: 1352.3503\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3c34f04d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_D['0%/10%/0%'] = loss"
      ],
      "metadata": {
        "id": "GKtlkIxoSnaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62145470-f959-4ecb-8dc7-3523a79b8ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 28.5629 - mae: 28.5629 - mse: 1288.4950\n",
            "Loss: [28.683971405029297, 28.683971405029297, 1288.48583984375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) (5%, 5%, 5%)"
      ],
      "metadata": {
        "id": "JfEk1RyCUaBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.05),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.05),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.05),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "RAznmvpGUM0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34371e8e-2e77-4d94-fda2-1c8ccb4236dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 65.5105 - mae: 65.5105 - mse: 6914.4204\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 64.7957 - mae: 64.7957 - mse: 6741.3169\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 62.7421 - mae: 62.7421 - mse: 6315.2354\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 58.7692 - mae: 58.7692 - mse: 5657.3071\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.5579 - mae: 52.5579 - mse: 4554.3906\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 50.5613 - mae: 50.5613 - mse: 4185.0430\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 48.4272 - mae: 48.4272 - mse: 3852.4194\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 47.1395 - mae: 47.1395 - mse: 3626.6345\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 46.2663 - mae: 46.2663 - mse: 3481.6445\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 45.3487 - mae: 45.3487 - mse: 3298.3840\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.7697 - mae: 44.7697 - mse: 3227.4814\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.8681 - mae: 43.8681 - mse: 3069.3650\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.5989 - mae: 43.5989 - mse: 3055.8796\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.2433 - mae: 42.2433 - mse: 2879.2483\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.3240 - mae: 41.3240 - mse: 2739.8550\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.9177 - mae: 39.9177 - mse: 2598.7852\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 38.4858 - mae: 38.4858 - mse: 2407.1501\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.7962 - mae: 36.7962 - mse: 2225.1228\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 35.6470 - mae: 35.6470 - mse: 2077.7854\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.5731 - mae: 34.5731 - mse: 1958.8103\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.9881 - mae: 33.9881 - mse: 1899.4567\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.6506 - mae: 33.6506 - mse: 1877.8083\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.5398 - mae: 33.5398 - mse: 1827.4644\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.3146 - mae: 33.3146 - mse: 1821.5333\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.3300 - mae: 33.3300 - mse: 1825.1588\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.8929 - mae: 32.8929 - mse: 1800.0953\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.5971 - mae: 32.5971 - mse: 1762.1953\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.6119 - mae: 32.6119 - mse: 1736.7153\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.2974 - mae: 32.2974 - mse: 1731.2838\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.6990 - mae: 32.6990 - mse: 1774.8101\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 32.6550 - mae: 32.6550 - mse: 1758.6975\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.5284 - mae: 32.5284 - mse: 1749.4911\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.2832 - mae: 32.2832 - mse: 1701.4988\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 32.2829 - mae: 32.2829 - mse: 1704.6614\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 32.1318 - mae: 32.1318 - mse: 1675.7321\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 32.1213 - mae: 32.1213 - mse: 1692.0773\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.9319 - mae: 31.9319 - mse: 1692.2371\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31.6568 - mae: 31.6568 - mse: 1645.6741\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.6378 - mae: 31.6378 - mse: 1626.0474\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.8639 - mae: 31.8639 - mse: 1680.0498\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.8558 - mae: 31.8558 - mse: 1664.9318\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.5868 - mae: 31.5868 - mse: 1626.7031\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.0510 - mae: 32.0510 - mse: 1677.2286\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6793 - mae: 31.6793 - mse: 1652.6077\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7454 - mae: 31.7454 - mse: 1664.6715\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5437 - mae: 31.5437 - mse: 1627.6564\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.5413 - mae: 31.5413 - mse: 1622.4688\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.2340 - mae: 31.2340 - mse: 1577.5848\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0450 - mae: 31.0450 - mse: 1585.2153\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4042 - mae: 31.4042 - mse: 1604.6063\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1501 - mae: 31.1501 - mse: 1567.6383\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.2033 - mae: 31.2033 - mse: 1578.6973\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9903 - mae: 30.9903 - mse: 1564.9587\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0078 - mae: 31.0078 - mse: 1568.6012\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7327 - mae: 30.7327 - mse: 1525.6420\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4883 - mae: 31.4883 - mse: 1633.5818\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.1238 - mae: 31.1238 - mse: 1557.6185\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.0158 - mae: 31.0158 - mse: 1568.6472\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8932 - mae: 30.8932 - mse: 1541.1230\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8399 - mae: 30.8399 - mse: 1545.1586\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8901 - mae: 30.8901 - mse: 1540.0168\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.8207 - mae: 30.8207 - mse: 1535.3646\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.8144 - mae: 30.8144 - mse: 1529.7062\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6384 - mae: 30.6384 - mse: 1504.9216\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6884 - mae: 30.6884 - mse: 1524.6578\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8784 - mae: 30.8784 - mse: 1511.0977\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1465 - mae: 31.1465 - mse: 1587.3563\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.9213 - mae: 30.9213 - mse: 1551.7225\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5981 - mae: 30.5981 - mse: 1506.8975\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6770 - mae: 30.6770 - mse: 1537.1263\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7795 - mae: 30.7795 - mse: 1507.3148\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7999 - mae: 30.7999 - mse: 1528.9084\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7067 - mae: 30.7067 - mse: 1537.1873\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.4180 - mae: 30.4180 - mse: 1486.1071\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5438 - mae: 30.5438 - mse: 1519.3562\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6068 - mae: 30.6068 - mse: 1522.4512\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5584 - mae: 30.5584 - mse: 1509.4352\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3472 - mae: 30.3472 - mse: 1480.8390\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5399 - mae: 30.5399 - mse: 1509.3215\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5004 - mae: 30.5004 - mse: 1485.4467\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3229 - mae: 30.3229 - mse: 1474.1002\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3149 - mae: 30.3149 - mse: 1471.8132\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6402 - mae: 30.6402 - mse: 1511.3591\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2788 - mae: 30.2788 - mse: 1481.6332\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6233 - mae: 30.6233 - mse: 1502.3291\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4734 - mae: 30.4734 - mse: 1510.3630\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.4981 - mae: 30.4981 - mse: 1501.1420\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.2119 - mae: 30.2119 - mse: 1483.0438\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.4482 - mae: 30.4482 - mse: 1480.0610\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.4020 - mae: 30.4020 - mse: 1486.6249\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.3536 - mae: 30.3536 - mse: 1487.1749\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.5342 - mae: 30.5342 - mse: 1498.5293\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.2230 - mae: 30.2230 - mse: 1456.1414\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.3355 - mae: 30.3355 - mse: 1472.7745\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.1998 - mae: 30.1998 - mse: 1496.2500\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.0541 - mae: 30.0541 - mse: 1452.3521\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.1339 - mae: 30.1339 - mse: 1464.4629\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.2198 - mae: 30.2198 - mse: 1468.0400\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.1525 - mae: 30.1525 - mse: 1462.3784\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.1807 - mae: 30.1807 - mse: 1464.4503\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.9607 - mae: 29.9607 - mse: 1452.5276\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0974 - mae: 30.0974 - mse: 1463.3958\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9930 - mae: 29.9930 - mse: 1448.6719\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2806 - mae: 30.2806 - mse: 1469.3295\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.1791 - mae: 30.1791 - mse: 1468.4344\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9583 - mae: 29.9583 - mse: 1444.9688\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2930 - mae: 30.2930 - mse: 1482.6676\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.0398 - mae: 30.0398 - mse: 1446.5670\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.4223 - mae: 30.4223 - mse: 1479.6450\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9575 - mae: 29.9575 - mse: 1450.2675\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.1308 - mae: 30.1308 - mse: 1461.3790\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2800 - mae: 30.2800 - mse: 1484.9659\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1430 - mae: 30.1430 - mse: 1457.3033\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0973 - mae: 30.0973 - mse: 1447.2830\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0847 - mae: 30.0847 - mse: 1453.8994\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2556 - mae: 30.2556 - mse: 1468.8025\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9696 - mae: 29.9696 - mse: 1450.0986\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1440 - mae: 30.1440 - mse: 1474.7925\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8715 - mae: 29.8715 - mse: 1421.5203\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9941 - mae: 29.9941 - mse: 1443.8915\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8942 - mae: 29.8942 - mse: 1433.7084\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8403 - mae: 29.8403 - mse: 1432.5360\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0781 - mae: 30.0781 - mse: 1461.6844\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.1827 - mae: 30.1827 - mse: 1460.1221\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8568 - mae: 29.8568 - mse: 1422.1862\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9634 - mae: 29.9634 - mse: 1431.3766\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.2580 - mae: 30.2580 - mse: 1475.5696\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9736 - mae: 29.9736 - mse: 1448.4088\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9246 - mae: 29.9246 - mse: 1440.9409\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9705 - mae: 29.9705 - mse: 1435.8822\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9137 - mae: 29.9137 - mse: 1439.0070\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0692 - mae: 30.0692 - mse: 1462.9785\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8355 - mae: 29.8355 - mse: 1432.5475\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9097 - mae: 29.9097 - mse: 1421.6863\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9699 - mae: 29.9699 - mse: 1454.0125\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.8343 - mae: 29.8343 - mse: 1430.3461\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.0953 - mae: 30.0953 - mse: 1454.7476\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.8085 - mae: 29.8085 - mse: 1421.4164\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8218 - mae: 29.8218 - mse: 1431.2448\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8948 - mae: 29.8948 - mse: 1436.6425\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.9184 - mae: 29.9184 - mse: 1438.9786\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3176 - mae: 30.3176 - mse: 1492.8306\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8049 - mae: 29.8049 - mse: 1432.5560\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.8747 - mae: 29.8747 - mse: 1421.9126\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9243 - mae: 29.9243 - mse: 1440.2323\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.8284 - mae: 29.8284 - mse: 1430.5356\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.9254 - mae: 29.9254 - mse: 1435.3633\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.0628 - mae: 30.0628 - mse: 1457.7631\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.7306 - mae: 29.7306 - mse: 1425.0239\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.7812 - mae: 29.7812 - mse: 1423.6283\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.9560 - mae: 29.9560 - mse: 1434.7605\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.8485 - mae: 29.8485 - mse: 1427.9365\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.7344 - mae: 29.7344 - mse: 1423.0375\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.9520 - mae: 29.9520 - mse: 1437.5895\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.3166 - mae: 30.3166 - mse: 1479.2205\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.8927 - mae: 29.8927 - mse: 1425.5891\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.0660 - mae: 30.0660 - mse: 1455.4565\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.9995 - mae: 29.9995 - mse: 1441.5474\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.5945 - mae: 29.5945 - mse: 1409.2073\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.6334 - mae: 29.6334 - mse: 1395.8972\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.8744 - mae: 29.8744 - mse: 1452.6447\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0470 - mae: 30.0470 - mse: 1461.6345\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7672 - mae: 29.7672 - mse: 1407.8215\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7206 - mae: 29.7206 - mse: 1412.1622\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9419 - mae: 29.9419 - mse: 1440.4631\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8872 - mae: 29.8872 - mse: 1437.6288\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7924 - mae: 29.7924 - mse: 1432.7095\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.5732 - mae: 29.5732 - mse: 1402.4899\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.6952 - mae: 29.6952 - mse: 1411.2480\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4331 - mae: 29.4331 - mse: 1402.2717\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5033 - mae: 29.5033 - mse: 1389.7612\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7888 - mae: 29.7888 - mse: 1437.9041\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9307 - mae: 29.9307 - mse: 1439.4220\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7923 - mae: 29.7923 - mse: 1424.3351\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.0400 - mae: 30.0400 - mse: 1445.4711\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9980 - mae: 29.9980 - mse: 1444.9011\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4469 - mae: 29.4469 - mse: 1399.5619\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6092 - mae: 29.6092 - mse: 1413.8741\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7269 - mae: 29.7269 - mse: 1416.2251\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.6262 - mae: 29.6262 - mse: 1414.2018\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.5309 - mae: 29.5309 - mse: 1395.3868\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6726 - mae: 29.6726 - mse: 1412.3041\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9627 - mae: 29.9627 - mse: 1437.3110\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6629 - mae: 29.6629 - mse: 1397.3398\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6283 - mae: 29.6283 - mse: 1403.4747\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6491 - mae: 29.6491 - mse: 1412.4458\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9755 - mae: 29.9755 - mse: 1438.0543\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7809 - mae: 29.7809 - mse: 1435.5808\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7163 - mae: 29.7163 - mse: 1409.6106\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.0477 - mae: 30.0477 - mse: 1446.8856\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.6603 - mae: 29.6603 - mse: 1406.0276\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.7616 - mae: 29.7616 - mse: 1413.8850\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9823 - mae: 29.9823 - mse: 1436.1199\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0688 - mae: 30.0688 - mse: 1454.4875\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.7978 - mae: 29.7978 - mse: 1420.4001\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4278 - mae: 29.4278 - mse: 1394.3501\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9219 - mae: 29.9219 - mse: 1433.1073\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.8749 - mae: 29.8749 - mse: 1431.9221\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4438 - mae: 29.4438 - mse: 1386.9988\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.9045 - mae: 29.9045 - mse: 1435.5177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3b973d210>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_D['5%/5%/5%'] = loss"
      ],
      "metadata": {
        "id": "ahZOOmoLUMuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01350f0-04f9-4f88-a4e6-04f74e4802fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 28.7987 - mae: 28.7987 - mse: 1320.7804\n",
            "Loss: [28.88221549987793, 28.88221549987793, 1313.008056640625]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) (0%, 5%, 0%)"
      ],
      "metadata": {
        "id": "vnquh7QaUcgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### To be coded by students ###\n",
        "random.seed(1234) # For replicability\n",
        "model = keras.Sequential([\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.05),\n",
        "    Dense(30, activation=tf.nn.relu, input_shape=(X_train.shape[1],)),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "model.fit(X_train, Y_train, batch_size=1000, epochs=200, verbose=1)"
      ],
      "metadata": {
        "id": "WSZ_4ke7UMmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ef551c-298b-41e2-e926-a4bfd5c85ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 65.5276 - mae: 65.5276 - mse: 6927.1704\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 65.1707 - mae: 65.1707 - mse: 6832.8848\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 63.9853 - mae: 63.9853 - mse: 6625.1201\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.5950 - mae: 61.5950 - mse: 6142.0889\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 55.8859 - mae: 55.8859 - mse: 5137.6963\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.8955 - mae: 51.8955 - mse: 4437.0508\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 50.1788 - mae: 50.1788 - mse: 4168.3594\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.0524 - mae: 49.0524 - mse: 3973.6641\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 47.3529 - mae: 47.3529 - mse: 3672.4258\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.9716 - mae: 45.9716 - mse: 3421.9072\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.2056 - mae: 44.2056 - mse: 3164.8254\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.4066 - mae: 44.4066 - mse: 3196.9116\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.5973 - mae: 43.5973 - mse: 3023.8708\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.5928 - mae: 42.5928 - mse: 2907.1731\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.0552 - mae: 42.0552 - mse: 2792.6331\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.9368 - mae: 40.9368 - mse: 2676.4617\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.3110 - mae: 39.3110 - mse: 2465.8599\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.1730 - mae: 38.1730 - mse: 2332.6831\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.2043 - mae: 36.2043 - mse: 2116.7507\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.2560 - mae: 35.2560 - mse: 2046.2942\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.6006 - mae: 34.6006 - mse: 1962.4961\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.3425 - mae: 33.3425 - mse: 1802.5013\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.6672 - mae: 32.6672 - mse: 1745.7844\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.6580 - mae: 32.6580 - mse: 1767.0592\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.1352 - mae: 32.1352 - mse: 1693.2408\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.8298 - mae: 31.8298 - mse: 1669.6212\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.7499 - mae: 31.7499 - mse: 1669.2733\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9177 - mae: 31.9177 - mse: 1673.2734\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6804 - mae: 31.6804 - mse: 1666.3444\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6016 - mae: 31.6016 - mse: 1648.3683\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.3576 - mae: 31.3576 - mse: 1599.5571\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0395 - mae: 31.0395 - mse: 1576.4576\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2270 - mae: 31.2270 - mse: 1610.4697\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.0129 - mae: 31.0129 - mse: 1574.2540\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.0305 - mae: 31.0305 - mse: 1585.1559\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.7895 - mae: 30.7895 - mse: 1537.8949\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.7475 - mae: 30.7475 - mse: 1541.5208\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6390 - mae: 30.6390 - mse: 1530.9078\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.5994 - mae: 30.5994 - mse: 1516.6105\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6210 - mae: 30.6210 - mse: 1522.5071\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.6575 - mae: 30.6575 - mse: 1523.2235\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3892 - mae: 30.3892 - mse: 1502.4355\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.6242 - mae: 30.6242 - mse: 1522.3477\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1442 - mae: 30.1442 - mse: 1474.0955\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3090 - mae: 30.3090 - mse: 1482.3519\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1948 - mae: 30.1948 - mse: 1476.3956\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0640 - mae: 30.0640 - mse: 1462.7892\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0996 - mae: 30.0996 - mse: 1469.3807\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.1437 - mae: 30.1437 - mse: 1489.5060\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9781 - mae: 29.9781 - mse: 1475.7499\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9287 - mae: 29.9287 - mse: 1446.1528\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.1338 - mae: 30.1338 - mse: 1456.4846\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.8243 - mae: 29.8243 - mse: 1439.3835\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6935 - mae: 29.6935 - mse: 1420.3434\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9384 - mae: 29.9384 - mse: 1450.5138\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.7814 - mae: 29.7814 - mse: 1420.9594\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7531 - mae: 29.7531 - mse: 1447.7913\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6144 - mae: 29.6144 - mse: 1424.1222\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7938 - mae: 29.7938 - mse: 1424.3005\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.6602 - mae: 29.6602 - mse: 1414.5580\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9779 - mae: 29.9779 - mse: 1453.9355\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4535 - mae: 29.4535 - mse: 1400.5758\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.6782 - mae: 29.6782 - mse: 1420.5144\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.4072 - mae: 29.4072 - mse: 1384.4847\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.5199 - mae: 29.5199 - mse: 1422.5035\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.7418 - mae: 29.7418 - mse: 1402.5398\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.3811 - mae: 29.3811 - mse: 1396.5327\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.5268 - mae: 29.5268 - mse: 1393.3981\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.6364 - mae: 29.6364 - mse: 1406.4620\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.4600 - mae: 29.4600 - mse: 1405.5024\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.4569 - mae: 29.4569 - mse: 1393.1362\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.4737 - mae: 29.4737 - mse: 1410.3301\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.2936 - mae: 29.2936 - mse: 1374.1449\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.3118 - mae: 29.3118 - mse: 1379.1439\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.6466 - mae: 29.6466 - mse: 1404.9984\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.6662 - mae: 29.6662 - mse: 1401.7466\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.2851 - mae: 29.2851 - mse: 1386.6072\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4282 - mae: 29.4282 - mse: 1378.7572\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1630 - mae: 29.1630 - mse: 1363.7949\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4054 - mae: 29.4054 - mse: 1381.9298\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1331 - mae: 29.1331 - mse: 1365.9253\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3223 - mae: 29.3223 - mse: 1381.3441\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.4140 - mae: 29.4140 - mse: 1399.0170\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.4484 - mae: 29.4484 - mse: 1387.0848\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5369 - mae: 29.5369 - mse: 1411.0546\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3174 - mae: 29.3174 - mse: 1375.3390\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1896 - mae: 29.1896 - mse: 1362.2406\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2600 - mae: 29.2600 - mse: 1364.5403\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2438 - mae: 29.2438 - mse: 1361.6388\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1180 - mae: 29.1180 - mse: 1355.9846\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2602 - mae: 29.2602 - mse: 1371.5500\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3120 - mae: 29.3120 - mse: 1372.9556\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3230 - mae: 29.3230 - mse: 1380.6440\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1445 - mae: 29.1445 - mse: 1365.2378\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1516 - mae: 29.1516 - mse: 1363.2103\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1904 - mae: 29.1904 - mse: 1357.6909\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2127 - mae: 29.2127 - mse: 1363.8197\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2523 - mae: 29.2523 - mse: 1384.5015\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2242 - mae: 29.2242 - mse: 1367.3660\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0247 - mae: 29.0247 - mse: 1364.5566\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0305 - mae: 29.0305 - mse: 1355.5824\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4914 - mae: 29.4914 - mse: 1385.5121\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2549 - mae: 29.2549 - mse: 1355.1028\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2558 - mae: 29.2558 - mse: 1357.0128\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1762 - mae: 29.1762 - mse: 1357.3420\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1441 - mae: 29.1441 - mse: 1359.8872\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2032 - mae: 29.2032 - mse: 1371.9976\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9210 - mae: 28.9210 - mse: 1342.7592\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1743 - mae: 29.1743 - mse: 1361.0098\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1801 - mae: 29.1801 - mse: 1362.4801\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0148 - mae: 29.0148 - mse: 1356.2595\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.0609 - mae: 29.0609 - mse: 1372.3888\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.4262 - mae: 29.4262 - mse: 1378.7810\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2118 - mae: 29.2118 - mse: 1358.5531\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2645 - mae: 29.2645 - mse: 1373.8132\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8161 - mae: 28.8161 - mse: 1338.4827\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1817 - mae: 29.1817 - mse: 1363.8218\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0205 - mae: 29.0205 - mse: 1343.4529\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2291 - mae: 29.2291 - mse: 1366.0510\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8673 - mae: 28.8673 - mse: 1336.3407\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9556 - mae: 28.9556 - mse: 1336.0249\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1515 - mae: 29.1515 - mse: 1370.5781\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9272 - mae: 28.9272 - mse: 1350.6986\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0036 - mae: 29.0036 - mse: 1348.1929\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0083 - mae: 29.0083 - mse: 1342.2340\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8747 - mae: 28.8747 - mse: 1335.5980\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0277 - mae: 29.0277 - mse: 1351.3447\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9169 - mae: 28.9169 - mse: 1335.0405\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1207 - mae: 29.1207 - mse: 1349.9357\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1778 - mae: 29.1778 - mse: 1369.5695\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8525 - mae: 28.8525 - mse: 1339.2671\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7994 - mae: 28.7994 - mse: 1332.2389\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8608 - mae: 28.8608 - mse: 1333.5422\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1436 - mae: 29.1436 - mse: 1364.6086\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9963 - mae: 28.9963 - mse: 1339.1814\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0844 - mae: 29.0844 - mse: 1359.1465\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 28.9665 - mae: 28.9665 - mse: 1337.3604\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0807 - mae: 29.0807 - mse: 1357.1669\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.6879 - mae: 28.6879 - mse: 1324.4341\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.1785 - mae: 29.1785 - mse: 1370.9215\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.1048 - mae: 29.1048 - mse: 1351.3021\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.8084 - mae: 28.8084 - mse: 1339.0009\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.0779 - mae: 29.0779 - mse: 1352.8523\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9636 - mae: 28.9636 - mse: 1346.3953\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9439 - mae: 28.9439 - mse: 1335.5334\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.2381 - mae: 29.2381 - mse: 1378.4803\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.9213 - mae: 28.9213 - mse: 1333.2090\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.9568 - mae: 28.9568 - mse: 1346.2214\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.0994 - mae: 29.0994 - mse: 1349.3301\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 28.8242 - mae: 28.8242 - mse: 1325.5558\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 28.9870 - mae: 28.9870 - mse: 1346.7217\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8136 - mae: 28.8136 - mse: 1323.9008\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8211 - mae: 28.8211 - mse: 1337.9917\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.1999 - mae: 29.1999 - mse: 1357.7166\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8848 - mae: 28.8848 - mse: 1337.1022\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.9951 - mae: 28.9951 - mse: 1354.3765\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8384 - mae: 28.8384 - mse: 1336.9204\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7197 - mae: 28.7197 - mse: 1308.3452\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0316 - mae: 29.0316 - mse: 1345.2166\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8539 - mae: 28.8539 - mse: 1335.1914\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8407 - mae: 28.8407 - mse: 1329.5409\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.0837 - mae: 29.0837 - mse: 1345.6514\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8259 - mae: 28.8259 - mse: 1328.9874\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9830 - mae: 28.9830 - mse: 1342.8247\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1159 - mae: 29.1159 - mse: 1359.5973\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8885 - mae: 28.8885 - mse: 1340.1731\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9165 - mae: 28.9165 - mse: 1327.9155\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.9949 - mae: 28.9949 - mse: 1340.0558\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7317 - mae: 28.7317 - mse: 1319.9138\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6345 - mae: 28.6345 - mse: 1314.2766\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2063 - mae: 29.2063 - mse: 1366.6073\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8795 - mae: 28.8795 - mse: 1337.8455\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7374 - mae: 28.7374 - mse: 1321.7540\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.8413 - mae: 28.8413 - mse: 1326.8129\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9113 - mae: 28.9113 - mse: 1328.1132\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7409 - mae: 28.7409 - mse: 1323.6844\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9796 - mae: 28.9796 - mse: 1350.2761\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7803 - mae: 28.7803 - mse: 1328.3477\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7777 - mae: 28.7777 - mse: 1325.1240\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8448 - mae: 28.8448 - mse: 1329.4863\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8367 - mae: 28.8367 - mse: 1333.3763\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8847 - mae: 28.8847 - mse: 1337.4672\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8755 - mae: 28.8755 - mse: 1343.2179\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7998 - mae: 28.7998 - mse: 1332.0499\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7807 - mae: 28.7807 - mse: 1320.7073\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9292 - mae: 28.9292 - mse: 1330.6848\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6194 - mae: 28.6194 - mse: 1313.7828\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9919 - mae: 28.9919 - mse: 1344.8110\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9922 - mae: 28.9922 - mse: 1340.6439\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8076 - mae: 28.8076 - mse: 1343.0017\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7153 - mae: 28.7153 - mse: 1320.9298\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7245 - mae: 28.7245 - mse: 1328.1163\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9438 - mae: 28.9438 - mse: 1343.0031\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.9269 - mae: 28.9269 - mse: 1333.1973\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8646 - mae: 28.8646 - mse: 1331.0767\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.6160 - mae: 28.6160 - mse: 1318.5656\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7040 - mae: 28.7040 - mse: 1332.4192\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8471 - mae: 28.8471 - mse: 1329.9191\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7646 - mae: 28.7646 - mse: 1330.5947\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.7195 - mae: 28.7195 - mse: 1315.1086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa3b833ef10>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this code after training your model ###\n",
        "\n",
        "# Evaluate the model with standardized features\n",
        "loss = model.evaluate(X_test, Y_test) # You might change the model's name\n",
        "print('Loss:', loss)\n",
        "\n",
        "# To save the performance\n",
        "performance_D['0%/5%/0%'] = loss"
      ],
      "metadata": {
        "id": "aL8HTO-jUMco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ab0419-fcd9-4295-f6f7-9f39411ecdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m282/282\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28.4385 - mae: 28.4385 - mse: 1280.7993\n",
            "Loss: [28.600372314453125, 28.600372314453125, 1281.93505859375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you find any improvement compared to the models in Question A2 and Question D1?**\n",
        "\n",
        "* **Your answer:**\n",
        "From the below comparison with the A2 model, we can find that [0%/5%/0%] model has the lowest value for mse. Given that the loss and mae are relatively close among all 4 groups of models, mse can be used as the deciding factor to determine the relatively best performing model. In this case, [0%/5%/0%] model is the best performing model."
      ],
      "metadata": {
        "id": "rN-9h950URkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section A\n",
        "performance_A"
      ],
      "metadata": {
        "id": "Xkhc9Zu9UVIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb8e9f0-725d-471c-c2e4-2023c7f33d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(20 x 1)': [32.059452056884766, 32.059452056884766, 1678.92333984375],\n",
              " '(30 x 3)': [28.562971115112305, 28.562971115112305, 1281.6761474609375]}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: Model Performances in Section D\n",
        "print(performance_D['10%/10%/10%'])\n",
        "print(performance_D['0%/10%/0%'])\n",
        "print(performance_D['5%/5%/5%'])\n",
        "print(performance_D['0%/5%/0%'])"
      ],
      "metadata": {
        "id": "2c865NvWUVoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c62afdd-ae1c-4699-db2c-edf4032194f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29.063486099243164, 29.063486099243164, 1334.5682373046875]\n",
            "[28.683971405029297, 28.683971405029297, 1288.48583984375]\n",
            "[28.88221549987793, 28.88221549987793, 1313.008056640625]\n",
            "[28.600372314453125, 28.600372314453125, 1281.93505859375]\n"
          ]
        }
      ]
    }
  ]
}